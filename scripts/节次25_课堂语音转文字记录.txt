00:04接这个行，对，是嗯嗯嗯你装了火腿了，不是我听你最多给这是一二，啥都放对。对，
03:30就装这两，我在看七六八对呀。但是上面这一条应该是过去的问题，最常的这要是可以的，我找一装效果没好在高级别，意思是美国有个装柜也行，
04:32 configure 规准不？所有的很多的人嗯非常悉五十七为什么会？你说嗯怎么样一款手机？对，那我们开始今天上课好吧？那今天上课的话，
05:37我们会呃沿着上节课的这个内容啊，我们会继续讲一些这个这个计算机网呃在系统方面的这样一个网络的话题，以及啊最近的这样的一个这个系统的这样的一个计计算机系统游戏布布系统对吧开怎怎么呃它临面临的这个网络环境和之前传统的计算机不大一样。现在我们大家可能会经常听到一些像这种 smart i ick 对吧？或者 GPU 对吧？这样的一个概念，
06:03它到底什么西为什么会出现？以及它到底这个这个使用起来有什么问题啊，我们这节课会做一个这个这个啊比较全的这样的一个介绍操作不行。那么我们先回顾一下上节课所说的啊上节课。我们说这个对于一个分布式的或者说一种 skill 的这种系统来说的话，这个网络式这些系统最为至关重要的一个方面。
06:24因为我们说什么叫分布系统呢？就是我有很多个机器对吧？它的协同去完成一项计算任务。那如果这个任务的话，它机器之间不需要通信。那这个任务其实本质上来说的话，
06:35是个非常非常吹弱的这样的任务。那么复杂任务的话，其实一台机器它一般来说并不能独立完成。所有的这个是比如说有些机器负责计算的，有些机器负责这样的一个存储。那我这个存储的数据对吧？
06:47我去你拿 application 去去拿到，那么这个其实就需要通过网络 OK。但是我们说这个在计算机里面，你比如说你要把两台机器通过通果点对点网络连接的话，这个其实是个比较简单的事情。那如果你是一个成规模的，
07:02比如说几千台机器的这样的系统对吧，你这个你你一台机器怎么去找到另一台机器，你不可能说我一台机器差了一万根网线连的其他机器，这个是是的。那所以说我们需要这个网络的路由。然后当你的规模一大以后呢，
07:15你就会出现我的这个网络会很容易丢包，对吧？或者说我很容易在这个网网络的这个管道里堵塞，对吧？大家可以想象一下，我们机器之间通信，
07:23它其实本质上跟管道其实有点像，对吧？就我把一个数据给从管道扔出去，然后后面从从这个数据管道里抽出来数据。那如果这个这个这个一方面抽啊，一方面它这个压的太快了怎么办？
07:35它会会会反压，对吧？这个事情其实啊就不大好处理。所以说啊我们说这个计算机网络本身它是一个非常大的这样的一个 topic 啊，我们做出来那种经典的有这个基层的这种网啊 layer 啊，不同 layer 会去负责这个不同的这样的一个网络中出现各种情况这样的事情 OK。
07:53那这样一种雷月音的这样的一种设计，在这个在这个功能上，其实是能够实现人们的这样的一个这个各种各样的网各种网络环境下的这样一个需求。但是它有一个很大的问题，就是啊我如果要实现那么多的 layer，它的这个性能开销是非常大的对吧？
08:10系统啊，或者说计算机里面有两个经典的经典的这个谚语吧。第一个谚语就是说任何计算机问题都可以通过加一层去解决。但是与之相对的另一个应用，就是说任何计算机系统当你加了一层之后，对吧？
08:23你的性能其实就会受到一定的这样的一个损失。那么传统的范围和我们是看到的，当你把所有的这些网络协议站，你放到这个 linux 的这个内核里啊去实现的时候，它本身给应用带来的这个开票实际上是非常大的。所以呢这边就引入了一个。
08:38所以现在的现在数数中心网络其实和呃大部分的呃尤其是面面向这种 AI 的这种比较快的这种网络，它基本上采用的是一种这个这个我们叫做 konle by pasthy 对吧？或者说以黑化叫这个内核旁骛啊，或者说很多手说法。但本质核心很简单，就是说我这个这个我我的这个所有网络操作，
08:58它不应该由一个我看不见的这样的一个黑盒的这个内核啊去管理。而且应该是本来应该是我这个 application 自己管自己管。那么它的核心技术就是我把网网络的这样的一个这个硬件资源直接暴露给这个这个这个这个用户态啊方法，可能就是 memmalip p 啊这样的一些一些一些操作系统这样的样的一个机制。那这样的话，我应用就可以选择，
09:20就是说我到底啊哪些要做复杂的七层网络，对吧？哪些不需要啊，我直接丢个裸包啊就可以。比如说我们在数据中心里面做哈币，对吧？
09:28其实完全没必要走这个七层的这样的一个网站。那这样的话相比较前面我们这种传统的这种网络的话，其实就能看到它的这个性能上其实是很好的。因为你得去掉一层抽象，基本上来说你就有有有有种潜能去提升一定的这样的一个性能 OK。那么最早去实现这样一套这个或者说呃一种经典的实现内核防务的方案，
09:49我们就说叫 PPTK 啊，他刚才的事情就是说把网卡的这个这个物理的队列啊给这个暴露给用户，然后用户就可以直接去往这个网卡，物理里列塞包。网卡收到这个包之后，他基本上就会把这个包裸的发出去，
10:03他基本上不大会做一些操作。而 k 这样的话它性能其实是非常非常好。那这种 GBDK 会有一个问题，就是传统的一些网卡，对于他网卡它的能力其实相对来说比较弱。他只能干什么事呢？
10:15就是说他只能只能把这个包啊很快的速率发取啊，然后做一些校验什么的。然后呢，他其实并没有提供像我们传统的，像这种 TCBIP 里面的这种云云色控制啊，对吧？
10:26这种啊这个丢包重传啊，这些都都没有啊，这样导致一个结果。就是很多时候我们用户态啊，他为了弥补这些能力还得去重新实现一遍。那你如果在用户态重新实现实现一遍的话，
10:36那那你这种绕过内核的这个带来的性能收益，其实相对来说就会小很多。为什么呢？因为啊这个这个原本你的东西是内核实现的，你现在用户态其实你要重新实现一遍。其实从职觉上来说，
10:48它并不会啊比你在内核实现好很多 OK。因此呢就是说我们就就就就就就计算机里面还有一个经典的，就叫我叫 specialization。就是说如果有一个东西对吧，它非常常见啊。我如果就把它硬化在了这个硬件里面，
11:02那它的执行效率是一定比你这做做做软件高的啊，要前提是你有你有你有足够的这样的硬件资源 OK。好，那么其实大家想这个网络的话，这个这个这个这个通信啊，这种各种的一个路由啊，
11:15还有运测共享的。大家想想，这其实是一些非常啊常见的这样的一个功能。那么这些功能能不能啊我们就不不需要呃用户太实现我们直接放法人的网卡实验啊，这个其实就是啊这个这个这个这个我们上节课主要介绍的这个 RDA，对吧？
11:29 RDA，那么它其实有比较好的这个因为因为它所有的东西全都硬化在了这个网卡里，所以它比较好的呃特点就是说它的带宽啊可以做到非常高。那它的延迟可以做到非常地图，它的这个 CPU 利用率是非常高的。因为啊从站在 CPU 角度来说，
11:43它其实不需要浪费更多的这个计算资源，去处理这个网络协议 OK。然后我们上节课这个这个最后介绍呃，我们上节课还介绍了一下，就是怎么去用 RDMA，对吧？
11:55我们会发现它的这个这个编程的这种 abstrution，其实是和这个呃这个这个传统 TCPIP 不大一样的 TCPIP。它是一个 stream 为为和 sockeit 为核心的这样的一个编程接口。但是 RDMA 其实会更加简单一点啊，它就是一个 direct m acaccess， like 的就是直接内存访问的这样一个接口。
12:15这接接口。因为我们上节课其实剖析了一些 RDMA 内部的这个细节，对吧？我们只有发现他做设计是有道理。因为我本身我硬件啊，它这个提供的能力就是这个 direct ct memory access，
12:26那么你把它扩展到一个 remote direct access，就是跨境。我们相对来说是啊比较直观的去用这样的一个硬件硬件实现的那基于这样的话， RDA 其实就提供了两套能力啊，我们说一种是和传统 TCPIP 一样类似，对吧？
12:39就是触发消息啊，还有一套就是说我可以 RDA 可以甚至可以绕过你的这个这个网卡的 CPU 啊，去做一些计算的卸载。比如说它可以做啊 rewrite 这样一个操作啊，当然其实 RDV 它更复杂的一些玩法的话，它有一些这个这个基于事件触发的这样的一个这个它其实是 RDV 是图一完备，
12:58就这个玩法是可以可以用来做这个这个这个可编程的。当然这个这块就比较复杂啊，我们就先暂时不去考虑么复杂杂这样的一个这个一个啊事情 OK。好，那么有了这样一个我们介绍一个 RDV 之后，我们其实就我们今天上节课最后的一个结尾，
13:14对吧？我们给大家介绍了怎么用 RDV 去 build 一个这个系统啊，我们会我们我们会说这个东西没有那么简单，为什么呢？因为本身这个这个 RDV 这个东西它很快，对吧？
13:23你一个现有性的，比如的，但把你的这个原本的网络通信用 RDV 重写遍，确实是能够获得一定的这样的一个提升的。但是这些提升其实它并没有达到一个最优的情况。因为你本身你的这个软件站，
13:37它是假设这个网络比较慢啊，这样一个 setup 去设计。但是一旦你的网络网速快的一个数量级，甚至它超过你的这个 CPU 的速度之后之后，你要完完全完完完美的这个利用这网速。其实我们是啊需要这样的一个这个这个系统这样一个 VV 三 OK。
13:54然后上上节课我们讲的这样一个例子是这个 QI store 啊 QS store。为什么我们说这个例子是是 QI store 呢？因为 QI store 相对来说是一个比较复杂的啊，第一台比较重要的应用。然后第二它它是个比较复杂的应用。因为其实我们后下节节或者下一节课，
14:09我们会看到对于一些相对简单的应用啊，比如说你是大模型里面，对吧？你用 RDMA 去传这个数据，对吧？不管你是传拆模型的，
14:17拆换的也好，你去传 KV cash 也好，这些东西实际上是非常非常 triue 的。因为它是一个大的这个的这样的一个访问。它。对，
14:24对于这呃呃你基本上直接用 sequentir DA 重写一下，就能获得比较高级的那对于 QQS ore 啊这种应用它稍微复杂一点啊复杂一点导致结果就是你如果简单的啊把你的这个通信啊接口这个这个换成这个 RDV 的话，其实它并并并没有办法能把这个网速啊啊完全用满 OK。好，那我们再来回顾一下 QS store，对吧？
14:43这个实际上是一个应该是做计算机，大家可能都听说过的这样的一个抽象，对吧？它这个本质上是一个数据的这样的个存储，存储的这样一个系统。那它的数据可以是比如说用户的这个账单啊也好，
14:56用户的个人信息也好。那么对每个数据来说，我怎么去知道我用户需要哪个数据呢？那这个我我们每每数数据除除了的的数的内容 value 以外，还有一个有个 key，就唯一的这样的 key。
15:07然后我们通过这个 key 它可以去索引到这样的一个这个数据，这个这个这个具体的这样一个数据。好，然后我们说那这样一个 QS store，对吧？对于传统的系统来说，
15:18它其实非常简单的。那么比如说我们以 memory cash d 对吧？你一个经典的系统为例，它其实无非就是我有一堆这个前端的这个和服务器。然后呢，他如果通过网络去访问一个这个后端的这样的一个这个 memory cash 的 server。
15:31这个 server 呢它会存一个就是本地的一个 QS store 啊，会把存存款色的数据，然后我们又发一次。如果他要访问这个 QS door，它是把就先发一个网络请求，求 server ver server 收到请求做完，
15:43哎就返回。好，就这样一套非常简单的这个系统啊，非常简单，但是非常经典，非常用了非常多的这样的系统。
15:49我们上节课带大家回顾下来，我们说一个非重要要点，就是这个系统啊这个系统统你光光把你的这个这个这个这个这个所有的网络就里光把你的这个网络请求啊全部换成 RDMA。其实是并不能完全把这个 RDMA 用满了。它其实这的 ball nep。其实其实当你的 RDA 变得很快的时候，
16:09你的 ball nep 其不不 RDMA，而是在 server 的这样的一个修了，为什么呢？为什么呢？其实这个问题的话，我们其实可以用一个啊很经典的叫做 system 这个 model 的这个方法，
16:19把这个问题给建模出来。什么什么叫 system model 呢？就说我不需要去跑实验啊，我只要在我的脑海中把这个这个系统里面面到底有哪些基本的这个组件，你这个组件之间它们是怎么通信的，然后呢呃去去勾勾勒勒出来。
16:33那这样的话其实我可以用一些这个 analotic model，对吧？我就可以直接把这个系统的这样的一个性能去去做一些这个这个系统的这个这析。那析分析的话，大概率是跟你的这个大大概率啊，实际上是是是是比较准确的那如果不准确说明什么？
16:48说明你的这个 model 是不准的对吧？就是我们就需要去迭代我们这样的一个 model。那么本身你发现那个新的 model 其实就是这做 system research 一个非常啊重要的这样的一个内容。当当，你把一个现有的 model describe 清楚，其实本质上来说也是非常啊重要的。
17:03 OK。那我们说在我们的这个 PS 座下，对吧？它的 model 其实就可以啊更更进一步的去细化成一个 diagram，一个 CPU，一个 PCIE，
17:12一个 switch 这样的一个系统。然后 clite 和 switch 间，它是有这个一百 GBPS 的这个网络带宽啊啊不不是网络带宽，是一百二十八 GPSPCIE 带宽。然后啊啊不对，网络带宽。
17:23对对，然后然后和和网卡之间是一百二十八 cllig PSPCIE，然后 switch 和这个所有网卡间大概是一百 GBPS 的这样网络带。所以我们可以知道这个 model 里面它的数据流量大概是每秒是这个一百一百 g 个 PS 这样的一个一个数据。然后我们说有了这个数据之后呢，我们就可以去估算，
17:39对吧？我的这个系统里面，它的瓶颈到底是数据啊传传不过来，还是说你的这个这个 system 啊，它这个 CPU 啊来不及处理啊。我们上节课其实提到说我们这样的一个这个这个这个 QSSP 啊这样一个请求，
17:54它其实本质上是吧它其实本质上可以直可以抽象成一个这个这个这个啊 hash table。对，什么叫 hash table 呢？就是说我的一个 key 对吧？就是因为很简单，我们一个 cash p 我们得根据一个 key，
18:04找到一个数据对应值。那这个我怎么找到呢？那传统的经典就是一个 hash ketable，就是我先哈希一下，找到 bucket，然后 bucket 里面有这个所有的这个 hash 到同一个 bucket 这样一 t 的这样一个数据，
18:16对吧？然后我们通过这个遍历这个 bucket 的这个链表，我们就可以找到我们对应的这样的一个值 OK。那这套方法有了这套方法之后，我们其实就可以去定量的分析。我们甚至不用不用跑，
18:28我们直接在纸上，我们就可以分析出你一个 server，对吧？它它每秒到底能处理多少多少的请求，这个其实非常非常重要。因为我们在啊也也有些老师会称之为叫做 mc ten lenis，
18:38对吧？其实就是说我们在啊不不去真正的跑这个系统之前，我们就就尝试的去去猜，对吧？就是我们的这个系统到底会有什么样的一个问题，到底这个这这个这个这个我的提升空间在哪？
18:49因为这个东西的话，它比你自己去实际跑一遍要快很多啊。你如果自己实际去跑跑的话，它它有两个局限。第一个是说你跑跑一个系统本身是搭一个系统，是需要花一定时间的。
19:00第二个就是说你这个跑的数据，它只能表示的是一种这个 assumption 下的这样的一个情况。但是你的这个真实的这个系统呢，它其实有非常多的这种不同各种各样的这样的一种 case。你怎么你其实很难保证就是说哎我在一种 assumption 下跑出来的数据，其实是能严格这个啊这个符合所有的呃情况。
19:18这不是。但是如果我们有一个 system model 的话啊，其实是我们是可以这个这个这个呃这个能把各种情况模拟出来。因为大家想想像不同的这个 elevation，对吧？它本质上就是你的这个 sytusystem model 的这个参数是就不一样 OK。
19:31那么对于我们这样一套这个这个 hash table 的这这样的一参参数的话，其实我们我们其实最重要什么？就是说我们去计算这个 hash 的这个时间，以及我们去读这个 hash table 的这样的时间。这些其实我们都可以定量出来。比如说在一般的这个系统里面，
19:45对吧？我算一个 hash function，大家 CPU 上可以测一下，对吧？大概一一大秒基本上就算了。因为这些这些这个这个啊呃呃计算是非常简单的那我对于读 bucket 的话，
19:55这个事情它其实本质上就等于什么？就是等于这个呃 memory 的这个 random access。那么 memory acaccess 在现代的计算机上大概是两百到四百纳的这个延迟，目前来看也是比较难降低的啊，这个是个比较确定值。然后最后的话就是说我需要去收发 RDMA 的请求。
20:10那么收 RDMA 请求这个东西的话，我们上节课讲过过，它本质上就相当于是一个 random access 的读啊，我只需要去读这个网卡，有没有把这个数据推到我这边就结束了。那对发这个消息情况相对复杂一点。
20:21因为我们需要去通知网卡这个这个事儿啊，这个消息发出去。所以我们说这边会有个涉及到一个叫 memory mapped IOIMMIO，这个的开相相对说大一点啊。一般来说在啊我测下来大概应该是在两百到八百大的，当然也可以去调整 OK。
20:35那么有了这样一个 nelest model，我们就会发现一个事情，就是这个这个这个这个这个在我们现在这个阿里 MPS store 下，它的瓶颈是在 CPU 核上啊，不仅是在网卡上，为什么呢？
20:46因为我们刚刚那个 model 算下来，就是你的这个一个 CPU call，它大概每秒钟最多只能处理一个每 lion 的这样一个 PPS store 的这样一个查找的这样的一个请求 OK。那么一般现在的这个数据中心服务器，大概也就是二十到三十个这样的一个 call，这样的容量级啊，
21:01二十到三十个这样的容级。那么啊当然我呃我指的二十三 core 的这样的 nect 啊，就是每个每个网卡大概会对应啊这个二十到三好的。因为因为其实现在的像那些 GPU 机器，对吧？它其实确实是有几百个 CPU 核，
21:14但是它这些几百个 GPU 核，它其实不只有一张网卡。它其实是有一般来说是有八张网卡，甚至更多啊这样的网卡。所以说它一般来说你平均下来每个网卡会对应到二十三十个核。所以我们会发现这个数这个 CPU 核我们一个壳一个框啊，
21:27就是只能没必要去处理一个令。然后后有二十个框的话，它最上上限也就是只能处理二十个 milmin 一个请求。这个数据跟你的这个网卡的性能这些 gap 啊是非常非常大的。比如说我们最简单的例，这个像我现我们我们直接找一个网卡测下下，
21:42对吧？它大概就是有一百个个 millic 这个这样的一个这个 IOPS 的这样一个这样的一个数据。而这个数据其实现在网卡是更高的，大家可以简单的去除一下，对吧？假设我一个 TY 六，
21:52它的这个请求和 reply 大概加起来是一百个 y 的。就有只有很多工作去统计过。就是说在数据中心里面，大部分的这个 TY 六都是一个比较小的，大概六十六十到一百个 y 的这样的值。那么我们可以拿带宽处理一下，
22:04就会发现它的这个这个速速率其实就是几百个 millic 这样的一个这样的一个数据。我会发现一个事情，就是说当你的这个这个这个我们有一个简单的这样的一个，比如说现有的这样一个用网络通信的这样的一个系统对吧。然后我们如果啊把它的这个这个里边通信觉得就简单简简单单。按这 RD 杯啊，
22:25我们即使是 RD 杯这个底下实现已经优化过了啊，但是它其实瓶颈仍然不会在这样的一个啊这个这个这个这个 RDV 上啊，它瓶颈其实在另外的地方，那意味着什么呢？就是我们就需要这时候大家想这个从说难听一点的吧，就是我们有有水培特的这个机遇了，
22:40对吧？就我们可以去去去去做一些额外的设计啊，或者做一些非常简单的事情啊， OK。好，那么再讲这个具体我们怎么去进一步演进，
22:48做一些额外的设计的时候呢，我们先强调一点，就是我们刚刚这个这个结论啊，它其实是并并不是一个完全解，就并并不是说 SCPU 一定是这个包装带。因为比如说你把 CPU 换成 GPU，
22:59对吧？它的包带可能又意味着在啊网络这边来。那么其实我们想要传达的一个核心的这个思思想。比如说你给给任任意一个这样的一个系统，其实我们都可以用这样的一种 system model 的这种这种 ararticiation model 的这种方式啊，对这种 system 进行一个啊非常详细的这样的一个建模。
23:16然后 OK 建模出来之后，我们就可以去分析这个系统的瓶颈在哪，它的新瓶颈在哪，以及它的各种各样的问题在哪。好吧，行，
23:25那我们怎么去优化它呢？我们现在其实说了这个 server 的这个 CPU 对吧？是一个这这样一个瓶颈。那么那果 CPUU 是瓶颈话，意味味着么么味着说你你你总不能换 CPU。因为其实我们去看现在的 CPU，
23:35它的这个增速啊其实也是非常非常有限的啊，所以说这个时候怎么办呢？我们只能用一些 CPU 之外的这个方式对它进行加速，对吧？对我们之间这样一个 QSO 进行加速。那么我们有什么 QY 呃呃这个这个 CPU 之外的方式，
23:48它不记得这个这个这个做 PS 的请求，它又能呃不不借助这个 CPU 了，因为它 CPU 本身已经饱和了，对吧？你在技术它不是给它加更大的压力嘛。啊那我们上节课只介绍过一个经典的这个这个 RDV 的另一个非常重要的这个 feature，
24:04对吧？叫做这个啊文塞类的 RDV 啊，一般来说叫做 RDMA 这个啊单边操作啊。大家回想一下，我们说 RDV 单边操作是网卡提供的一种额外的能力。它能够什么呢？
24:14就是我这个网卡，它可以绕过你的这个 CPU 去对这个内存做一些这个这个 read 和 right。还有这个这个就 automatic 就是原子操作，原子操作 OK。那么大家想想，其实我对一个 QS store 来说的话，
24:27它的核心操作什么？它的核心操作其实就是去查找一个索引，对吧？要么就是一个哈希索要么，就是一个移数的这样的索引。那么你这些查找操作本质上是吧，
24:35都是一个这个内存的读操作的话，本质上就是一些内存读读操作。那么我们如果我们去把这个这个原本的这个哈希哈的操作对吧？替换成这个 RD 杯，那我们就是文摘类的 RDV 单边 RD 杯。那我们不就是能够绕过这个 CPU 的这个瓶颈去做这样一个处理嘛。
24:53那这个这个看上去这个很可行的事情，为什么呢？因为因为 RD 杯本身它这个网卡它能做非常多的单边操作。它单边操作的这个性能通常是比它的这个发消息的速度要快一点。因为第一它不受制于这个 CPU 的保质量的。第二就是说我的这个呃单边的这个操作，
25:08它语义更简单一点。大家想想我双边的操作的话，我这个网卡对吧？他要把消息插到指定的这个队列队队列上。那对单边操作来说的话，我只需要把这个内存内存内存存数读读读回来就行了。
25:19所以它一般来说这个性能其实会比啊这个这个你直接做双边的会更好一点。当然有一些比呃这个具体的这个分析会涉及到这个底层的这个实线稍微复杂一点，我们就啊先跳吧。那我们其实这边有个结论，就是说你用单边 RDV 实际上是啊可行的，就是我们可以通过 logo CPU 的方式去实现这样一个 PS store。
25:38那么具体怎么做呢？我们其实上节课也也最会简单的提到一点，我们可以再回顾一下，对吧？本质上就是什么？本质上就是我原本 ver 端端成一个这这个 sh table 啊，
25:48就比如说有这个我们假设以最简单的这个 bucket 为啊那个 list 为例，对吧？就是说我这个有有不同的 bucket 啊，然后有这个 list。然后呢我们第一步就先把这个 bucket 这些东西啊全放在一个 RDV 能访问的这个区域里。我们上来就是呃我们上一课，
26:04大家回想我们说，你 RDV 其实不能够随意去访问这个 server 的内存，那对吧？因为加会完全所所，我们们要把这个内存放到 RDV 能访问的域。好，
26:11我明白是要通过内存注册 OK。有了这个东西之后呢，我们只需要什么？我们只需要把 bucket 的这些地址告诉 cent 告诉我，就是我们每个人要查找的客户端。然后这个时候如果我的 cent 它需要去做这个 QS go 的这样一个查找，
26:26对吧？那它其实就是先一样，它本地先去算一个 hash 方式，这个 hush 方式非常快，就非常小。算完了之后呢，
26:32我就去用对应的 RDMA 把这个操作，把所端端的内存数据给读回来。比比如说我们第一个发现哎，我的这个八 KT 应该是一百五十三。好，那我就去用一个 DMA，
26:42把这个一百五十三这个八 k 读回来。读回来之后呢，我就可以去遍历这个链表，对吧？我可以先把它链表的低项，比如说夏老师的这个安全给拿回来。
26:51 OK 拿回来发现唉他跟我要的这个 t 啊，那我怎么办？我再去变用 RDMA 去便利这样一个列表。因为我们说这个内存全都存在一个 RDMA 可访问的这样一个区域。一直找一直找知道怎么找，找到一个我找到这个这个是 match ch，
27:05是说找到这个这个这个我的这样的一个一个 value。那最后我再用一个 RDMA 把它读回来就可以了。 OK 那这个其实是一个非常直观的这样一个用 RDMA 去绕过这个 CPU，去实现这样 QS door 的这样一个设计。但这个设计的话，大家可以很明显的看到，
27:19它性能其实是非常非常低的。为什么呢？因为我们说你原本你这这个这个这个在这个模型下，它其实的 borneneg 就跟之前的这个分析 CPU 不一样。我们说之前分析 CPU 它的 ort nect CPU 的原因是因为什么？是因为它这个网络发消息只发一个，
27:35对吧？我就就发一个消息，我看了发一个消息， service 就是发一个消息，我就做完 QRSQQSS 的请求了。大家想想，
27:41在我们用这个文三 g 的 RDV 的时候，我要做一个 QIS 的请求啊，我得发的是吧？在我们这个地址里，他至少要发四次这个这个 RDV 请求。那么其实你发一他虽然不用这个所有的 CPU，
27:52对吧？但是本身你这个发这个请求数越多，对吧？你的这个整个性能会会越差的。我们可以做一个非常非常简单的推断的。比如说我们的这个呃 server，
28:01它吧，它每秒能做一百个每点的这个 RDV 请求。那如果说我的这个一个请求需要呃一一个 PPS 请求需要四个 RDV 的请求。那我其实我的一个呃性性能，就上帝其实嘛就一百除以四，就是二二十五个每点。
28:14那它其实就跟你的这个 CPU 白 pass 的这个速率实际上差不多的，它并没有获得这样一个非常大的提升。那这个其实也是在你用 RDV 去做一些花里胡哨的这个事情，对吧？一般来说都要解决的这个问题，就是说你怎么去解决这个 natural amvocation，
28:29就是我要做一个我的应用的请求啊，我理想情况下，我肯定是希望能用一个这个这个这个网络请求，把这个东西做完。那实际过程中，因为这个网络这个语义受限的，
28:38比如说 RDA，它只能够去读写远端的内存。所以我我得什么得花好多个这样的一个这个请求请求去去去去把这个事情给给给解决。那这个事情是实际上是划不来的。 OK 因此的话就在在最近几年，对吧？
28:54最近几年其实也是一个比较新鲜的操作，就有很多的这样的一个学术界的这种工作，包括工业界的工作要去探索的一个事情。就是说我们有没有一些这种数据结构啊，它能够比较适合用这种 RDMA 的这种单边的这种啊操作去访问。这样的话我既能够享受这个单边啊，
29:11它这个操作绕过 CPU 的这个瓶颈的这样的一个呃好处，又又能够什么样，又能够呃最大化的对 RDMA 这个单边的一个利用最最理想情况达是什么？就是说我一次单边的 RDV 请求就能够读读回这样的一个啊这个这个这个这个这个这个 q 拉 s ore 的这样的一个值，至少在 q 拉 s ore 这个场景。好，
29:30那么这个时候大家想想我们那我们能不能设计这样一个集形，大家想这个问题本质是什么？本质就是说我一个这个 hatch table 对吧？它的这个这个访问的这个内存的随机访问次数要少。就为大家我们前面说的这样的一个所有的问题，其实都在于说我这个为了便利这个为了做这个始 htable，
29:47对吧？我得去搞这个，我得去用这个 RDV 去便利这个这个这个内存啊，便利这个内存。那么这个东西在本地，它可能还好，
29:54在在在 CPU 在侧可能还好。但如果你把它一旦拉远了，你用你用这个 serr DV 去访问，那这个开销就是会成倍的这样一个增长。那我们有没有啊这样的一些呃好的这样的一个数据结构，对吧？
30:06我能够使用比较少的这样的一个这个 r 呃随机的内存访问，去把这个数据读回来。这个其实是有的。这个时候其实人们就会借鉴一些经典的这样的一个啊 hagetable 的这样的一个结构。比如说一个比较经典的结构，就叫做这个 pochision，
30:22对吧？就是一种比较精巧的这样的一个 catch table 啊，它能保证什么呢？就是它不能保证说我一次 ren 访问问能够啊读到我的 r 的数据，这个其实有点难。但它能保证什么呢？
30:32就是我所有的这个这个这个对每每个 QS 的 get 请求就是查找这个请求啊，我一定能在两个这个这个两个操作的返返回。然后大概率是能在百分之五十能在一个访问。那这样的话，它就比我们前面继续链表的这样的一个这个这个 hah table 说而且没访问啊，效率要高很多了。
30:49 OK 那么 coogle hihion 它怎么去实现这样一个这个这个这个这个 o 一的这样的一个访问呢？ o 一的访问呢，它其实它就对 hash 结构的这个结构做一个修改。我们说之前的你的这个 link list 啊，它的这个问点特就在于什么？它的这个 hash colalition，
31:04这个就是你 hash 冲突的时候，对吧？它你得把这个这个这个冲突的这个 care 全都嵌在一起。那你其实冲突的这个这个这个这个这个 care 可能是会比较多的。所以我得去遍历这样一个列表。那么 coogle hihion 呢，
31:16它他有点像他的，在他的这个这个 idea 来自于这个这个布谷鸟，对吧？他的名字叫 cooo，就是说我是那那我他的意思说如果我有 hatclession，那我的做法并不是说把你们圈起来，
31:27因为这样会引入额外的访问，而什么呢？而是说我去把你 t 到一个另外的这样一个位置。然后呢我保证什么？保证说我大概率啊你的我的，我这个 t 啊能够永远找到一个合适的这样一个 t 的位置。
31:39这样的话我的这个这个查找就不用去做便利了。那具体来说的话呢， coogle lession 它其实就会不像自己之前的一些 hash 结 ver，它会维护两个这样一个 hash bucket。然后每个 hash bucket 呢，它有一个这样的一个呃自己的这样一个 hash function OK。
31:57然后 coogle hish 呢它唯维保持一个 environment。你什么 enviuntion 呢？就是说对于任意一个 key 啊，它要么就在这个 bucket 零对应的 hash function。零。就他先算一下 hash function，
32:08 buket ting 对应的 hash function，然后找到它这个在呃这个 bucket 零的这样一个位置。如果它在这 bucket ting 啊，我事大吉，如果他没有在 bucket 里怎么怎么怎么办？它要么就不存在，
32:18要么什么要么它就在八 k id 一啊，在八 k id 一的话，它就会用这个八 KT 一对应的这个汉双线一啊，算一个 hash，然后把它给啊存下来。 OK。
32:28那这个就是 cool heaching 的这样的一个经经典思想。我们可以来举个例子，比如说我们要我们这个这个表图里边啊，这个每一项数字代表的是一个 key。那比如说我要找到这个七十三这个 key 所在的这个 bucket，我怎么找呢？
32:42我们在这个 cool hiaching 对吧？我先去用 hash 方式零去 hash 一比如说我发现七十三在 bucket 零，它的位置是二。那我们去找了一下 basket 里，发现它不存在不存在怎么办呢？没事，
32:51我们再去看一下这个这个 bucket 一用啊，有 buket ket 一，这这个 hicket 零还是方式一去算一下 OK。算完之后，我们发现哎这个时候存在好这个东西就好了啊，这个我们就找到发规了 OK，
33:03然后 put 的话其实是跟 get 一样，就是 in place 的这样一个修改。好，那么这一套方案其实大家想就是在没有你如果是个纯静态的话，它它的这个 environment 它的保证对吧？其实非常非常完美的。
33:15但是这套方法有个最大的问题，就是说你怎么保证这个在这个色和 environindelete 下，成成 delete 当然比较简单。我删除一个 t 它其实不影响这个 vironment，那关键是我插入的时候怎么办？我插的时候，
33:27如果我这个两个 bucket 都有这个这个这个这个它对应的 buket 都都占满了 t 怎么办呢？这个事不就是很很很缺体吗？那么其实在这个这个这个在那个 coco hition 啊，它的这个这个一个核心思想就是是我们什么说它是布谷鸟，对吧？就是说布布布布谷鸟的一个一个一个一个习性，
33:46就是什么纠战。雀巢就是说如果我有一个插的 key，他发现两个这个这个这个 bucket 都被占满，怎么办呢？他就把当前的这个 bucket 上的这个 key 可以踢到啊另一个这样的一个地方去，然后一直踢一直到什么，
33:58直到所有的人都踢踢到为止。比如说我们可以来举一个这样的一个例子。假设啊我想要去啊插入一个 key 为二的这样的 key。然后呢这个 key 它在零和零和 k 置的这个 hish 位置啊，分别都是零啊，都是零。
34:11这个时候呢，我们先去看一下这个这个这个这个这个八 k 的零，这个能不能能不能能不能插入啊，发现不行不行，怎么办呢？我们再去看一下八八 k 的能不不能插入啊？
34:21正 k 如如果发现唉八 k 一是空的啊，我们就先插入了 OK，这个没问题。但是如果这个有我想插入九啊，插入一个九。这个九呢它这个也非常非常我们就特地构造的一个 case，
34:33只是说它正好这个九啊在这个八 k 的零和八 k 的一，它正好都也是要在零这个位置。这个时候大家想想，我们就会发现一个问题，就是这个我们这个时候没有办法插入，对吧？
34:43因为我不仅不管是零也好，还是这个一也好，它们都有这个现成的这个这个数据啊，那这个时候的话，我们就需要这个在扩开 tion 里面就需要去做一个纠战。介介雀巢的操作。
34:56就是说我们会先把这个啊零里面的这样一个战着这个人给踢掉给踢掉。比如说我们要先把这个三十二踢掉，那我们踢哪里呢？大家想我们符务开序的话，其实不能随意踢的，对不对？
35:08因为我们符开开序有一个是说什么？是不说我一替，它要么就在八 environk 的零的始零的这个方程中，要么在八 hak 列这个开始方向意味着所以说我们要 t 三十二的时候，我们得去看一下，对吧？
35:18它在这个八 k 的一里面的这个位置空空。所以啊我们先去看一下三十一的这样的一个这个这个个是方向是二。这个时候我们发现非常好，这个八 KT 正好这个对应三十二的这个位置是空的。所以呢我们就会先把这个三十二去踢到这样的一个这个八 k 的一中 OK，然后再去把这个九插入到家，
35:36这样我九九这个 key 对吧？它位置就空下来 OK，我就能够就就能够插入的。所以说它是这样的一个呃比较复杂的这样的一个过程。就是说后 i 它本质上什么？它是对于这个 read 啊特别友好。
35:47但是它对于这个 right 或哦对 insert 啊来说，它的这个这个这个这个是比较复杂的。它有这样的一个引流程。但是这个时候会有一个问题，就是如果我们前面这套人 work 的机制是假什么？假设就是我要 t 三十二的时候，
36:01三十二这个八 k 的一它正好有个地方可以插入，对吧？因为它的 high 方程一是二，那这个时候如果我这个这个这个三十二它插不了是吧？插不了怎么办？比如说它如果 hish 方程是三啊三意味着什么？
36:13因为说它要插到八这个这个八四这个问题。但问题是这个八十四它仍然会有，这个时候，我们不就没有办法没有办法插入吗？这个其实就是说这个呃这个 coohition 它一个比较 tricky 的这样的这样的一个地方。如果我这个这个第一 t 它替不成功怎么办呢？
36:31它就需要做一个 recursive 的 t 什么意思啊？就就是要把比如说啊 bucket 一的这个这个二啊，就是说另一个 bucket 的这个值去去提啊去提。然后啊然后八 k 二如果不行，么么啊， bucket 不行呢，
36:43它就还得还得这个这个这个这个这个一直提一直提一直递归的这样的一个 t 啊。它其实是是会有一个有个超参数去控制这个递归的。然后在一些比较差的情况下呢， t 二也踢不了，对吧？比如说二它的两个位置也也都占住了，
36:57这个时候怎么办呢？这个时候怎么办呢？其实这种时候其实在 cool action 里面，它是是会比较容易出现的这样一个问题。所以这个时候的话就是 coohision 啊，一般它会设置一个超三十五，
37:07什么意思呢？就是说当我的这个一个 insert 啊，它插入啊它的它这个 t 的这个次数超过了一定上界之后啊，它都没有找到这样一个合适的。这样 sort 的话，那么它会做一次叫 rehition。
37:18所谓的 rehition 呢，就是说它会把这个 bucket 的这样的一个这个大每个 bucket 大给给给提升一倍啊，提升一倍。那提升完一倍之后呢，其实他会把这些所有的 k 重新插一点。那大概率的话啊，
37:30从理论上分析的话，其实说这个冲突的概率就非常少了。但但但是听上去这一套这个这个音色，它听上去比较复杂，对吧？它也不一定成功。
37:38但实际上大家有兴趣可以看，它配短的配备其实是是有些理论保障的。就是说啊我实际过程中要提这个次数不会不会特别多，对吧？不会特别多。所以说它在实际过程中在于，
37:48其实在一些这个对于 IDA 的这个这个这个访问下，它其实其实是非常好的 OK。行，我们来总结一下，就是说 pocahision 对吧？是是一种比较这个这个也不能叫比较新吧。
38:00但是是个比较巧妙的这样的一个数据结构。它的跟之前的这个 hash 结构的最大的一个区别。就是说这个这个这个这个它有两个这样的一 bubuket OK 两个这样的一个 bucket 啊，它保证就是说我的一个呃这个任何一个 PD 一定是在这两个的这个 buchash 的这个空间内。对于一个 get 来说，那这样它的好处就是说我对于每一次这个查找它是不量，
38:22保证它最多啊就是就是两次这个 random access 就能够找到了当家，对它的音色非常复杂，但是音色的话我们大家先背 OK 行。那么大家想想，我们是为什么要提哭哈 sh 呢？因为我们说这样一个 coocle 信达，
38:36它的这个这个这个这个特点实际上是非常非常适合我们说 hir DA 的。为什么？因为我们说 RDM 这个 QS 的话，它的这如果你要用单边去访问的话，它唯一决定性能因素是什么？就是说它或者它决定百分之九性能的百分之九十九性能一个因素因素是什么？
38:53操作？就是说你我一次这个查找的这个操作是吧？到底是要触发啊多少次啊这样的一个 RDA 请求。我说如果我们用 cco high 信的话，我们说它其实最多是需要多少次内存访问就能给我找到这个数据。但是最多只需要三次，
39:08为什么？因为他查找一个 key，最最需要两次。然后我们找到这个 key 之后，我们们最多只需要一个 RDM 去把它的这个这个这个 value 给读回来起来。当然如果你这个 value 直接把它存在 key 里，
39:20当然其实也是一个比较常见的这个操作啊，其实我们都不需要三次，对吧？我们最多两次就访问了这个呢这个性能其实就非常非常高效。 OK。我们来举一个举一个例子啊，
39:29假设我没有过过 hition，对吧？对，这个时候啊，我们其实的这个整个结构啊，就跟之前的这个 link place 完全不一样啊。
39:37我们没有啊所谓的这样的一个这个这个这个 link list 啊，我们其实就只有两个这个 bucket。然后每个 bucket 这个现在假设有两个位置啊，每个位置的话它零零零比如说存了一个一个一个 key，然后 value 啊，然后一五二六三存了一个 t 一个这样的一个 value。
39:52然后比如说我要找像之前啊一样去去去做的话呢，那我怎么做呢？我就先去比如说我先去这个 hash 一下这个第第零个 bucket 啊，发现第一个巴巴特的这个没有啊，没有我我就去找第一个巴巴特那。如果有的话是吧，
40:06我就直接最多两次这个 RD 面就把这个这个这个数据给反馈回来了，这样的话整体的性能是非常高的。 OK 好，那么这边的话我们就会发现有一些这个这个这个这个这个这个这个这个这个这个这个这个 ccoohition 的这样的一个这个这个啊这这这这就是讲完了，把它把它。那我们会发现对于这个 RD 妹来说啊，
40:29它实际上是一个性能这个这个性能非常高效的这样的这样的一个啊一个一个一个一个查找 OK。那么这个时候其实我们会发现有一个这样的一个呃，其实就其实他不发开信的这个方法，它其实目前来看还并没有完，它其实有两个比较大的问题。第一个问题就是说我们会发现就是说假设我们这个哎就是说我们现在对吧？
40:54我们说假设啊我第一次哭，还是比如说我就一五三啊，假设我就假设这个是第一个把定一个 bucket，然后我就命中了。好，命中了之后，
41:02我其实还需要花一次这个 RDV 去把这个 value 给它的数据的这个值给读过来，对吧？那是需需要两 overlong 选，它其实其实就是有一倍额外的这样的一个 overhead。当然如果你是没找到它会它呃它的这个 overhead 更多。那我们有没有办法把这两个这个 overhead 全都上传。
41:20比如说我们能不能用一次 RD，因为既把这个 key 和这个 value 都读回来了。大家想到，如果我一次 RDV 既把这个 key 和基本呃同时把这个 value 读回来。它的问题是什么？它的问题其实是说它会有额外的这个网络放大的这样的一个效应，
41:34对吧？就是原本我只要读十个 bag。好，我现在要读二十个 back，那就听上去来说性能不不是会更差吗？那这个问题其实对于这个 RDA 来说，
41:45这个这个这个这个这个并不并不是并不是特别大啊，并是特合。因为 RDA 啊，或者说现在的网络，它其实有一个有个特性，就是说它当你的这个就是你增加这个发送网络这个消息的大小啊，
41:57就是说你只要不超过一个 thresh hold 啊啊，比如说你不超过四 k 啊，它的这个性能就是读一个四 k 的包啊，和跟读一个一 k 的包的性能其实差不多的。这个原理其实也很简单，就是说现在的这个网卡它本身它有一个叫做 maximum 啊，
42:12 transmit 这个 unit u 啊，对吧？它一般 MTU 它不能设置太小，因为你一旦太小的话，它这个啊拆包的这样的一个 overhead 会比较大。它一般 MGMTU 可以设的，
42:22应该是啊从二五六到五幺二到四 k 其实都能设 OK。那所以说当你去设一个比较较大的一个 MTU，比如说五四 k 的时候，对吧？其实你就会发现你去发一个五百一十二的这个呃包啊和一个四 k 的包，其实它性能差不多了。
42:36那这种时候的话，其实我们又回到前面运动。我们说你对于这个 TY store 的这个请求来说，对吧？它的这个这个 t 和 y 的般都是比较小的。之前 facebook 统计过大概呃百分之八十以上的 KK 和 value 加起来都都会超过两一百到两百的这样一个 bit。
42:51那意味什么？意味着说我们对于我们这始的这个例子里面，我们全可把把 ccoohikekey 和这个 value，对吧？放在同一个这样的一个这个连续的空间里，然后我用 RDM，
43:01我直接就去把这个 key 和 value 都读回来。那这样的话我们上面这样一个例子中啊，它其实就是可以把这个 RDMA 的这个 RGT 从两个进一步的减少到一个啊这个性能就会比较简单。那这个其实比较区略了。当然基于这个的话，我们其实还能做一些额外的。
43:15比如说我们说 coogle hision 对吧？之前的它这个 rehession 一个很复杂的点，其实在于是有一共有 hash collection 啊， hash collession。原因其实就是因为我们只有两个这样的一个 bucket，对吧？
43:26两个 bucket。那么我们能不能就比如说我我我进一步的去避免这个这个这个这个用 collection 带来这样一个冲冲突的啊一种方式是说我可以把 bucket 增加更多。那这样的话你的整整体的这个算法复杂度会非常高啊非常高。所以通常的一般里面的一个一个工程上的这个取舍，就是说我不去啊再加 bucket。但是呢我会把一个 bucket 啊去加呃去去去去预留一些事。
43:51我们叫做 overflog，是不是我一个 bucket，它可以存啊多个这样的一个 key value 啊。这样的话我每次查找我其实可以读多个这样的一个 key 啊，这样的话也可以就是说降低这个还是 collection，同时它其实也不会影响性能。
44:03因为本身啊对于 RDV 来说，你读两个这个啊八 k 的，其实跟读一个啊，其实差不多的 OK。好，那么到这边为止的话，
44:12到这边为止的话，这个这个这个这个我们直接介介绍了一下第一步，对吧？就是我们我们在那简单的看一下，对吧？我们先说第一啊，
44:19你简单把 QS 做的这个通信换成 RDV 是不行的。因为 CPU 是成为包塞。那怎么去绕过 CPU 包段？但是呢我们就要用文塞内的 RDV 啊去做这个那呃 CPU 旁务的这样的一个操作。但就用文塞的 RDV 做了。有个问题就是说你会有一个这个网络框大的这样的产。
44:34所以说我们介绍了一种方法叫做这个 cool hehision，对吧？它其实是能有效的应对的这样一个网络放大项的这样一个一个一个一一一，一个是 hatable 了。当然这个 cool hision 它其实只是一个这个某一些具体呃某一个 speciic 的这样例子啊，其实在这个呃这个例呃这个这个这个最近几年对吧？
44:52其实人们提出过啊一系列的这样的一个这样的一个这个这个这个这个这个这个这个方法来结来来提升这个单边 RD 边去访问数据结构的这样一个效率。那么他里面用到的方法去无外乎就是我们前面讲到的两个。第一个什么呢？就是我去找一些啊具体来说就是说他的呃我们找一些这个这个对于这个读访问比较友好的。比如说啊我们前面介绍的 techniqup y lou f 这个 ATCE 一三年这个工作，对吧？
45:17他用的就是 bll hation，然后这个这个这个这个 farm 的微软的这个这个这个工作，他用的是 house stostoch aging 啊，它的原理其实和呃它其实是一定的这个 probe 的一个特例啊，但是它的这个读的读的数据也是比较少的。当然第二个思路就是说我能不能去搞一些 overfloor 的这个 bucket，
45:35就比如说原本我一个列表的始结构，对吧？我一个链只能存一个啊，那我能不能一个列去存多个这个 hap 来流啊，那这个对应的其 form 也用了对应的技术，包括像我们之前的这个这个底下 TM 的工作啊，
45:47也有类似的这样一个技术。那么这些技术本它去加持到一起的话，其实我们就会发现对于读啊读来说单边啊 d 边去读一个始词 structure 来说的话，它的这个性能其实就能够做到也好了。 OK。但是我们说这个系统里面对吧？
46:02有有有得必有失，对吧？这个这个这个这个这个这个这个数据库里面，甚至会有一个叫做 wrong congestion，就 RUM congestion。他说什么呢？
46:10就是说你一个 index，所以对吧？很很难同时达到一个高 read efficiency，就是它然后高 update efficiency，比如和一个高 maand efficiency m 不要意味什么呢？就是一旦你的这个这个读优化的很好的话，
46:25其实你的写其实就会有一些有一些有一些问题啊，有一些问题。那这个问题怎么解决呢？怎么解决？比如说我们举前面的一个例子，就前面我们说 coogle hision 对吧？
46:35它的这个写本身 insert 本质上也是一种写操作的。我们会发现你的这个 cool 啊，你要做这个啊 hihiinsert 这个这个事情其实是非常非常啊非常非常非常常难的那这个时候怎么做呢？其实我们的思路很简单，就是说我们就把这个 rewrite 啊这个这个这个这个这个操作啊可以放到 CPU 上，就 CPU 来做 right 操作，
46:57然后 read 操作，就让 RDV 单边的 RDV 来做。那这样的话有什么好处呢？大家就会其实想到大家会，其实你以前不是说你 CPU 去做，它是会成为瓶颈嘛。
47:06那其实你如果只把 right 放到这个 CPU 上，一般来说是不会成瓶顶，为什么呢？因为啊历史上有很多有一个二八定律，对吧？其实就是百分之八十的请求大都是 read，
47:15甚至是其实不甚至更多啊，比如说这边这边背后的统计说百分之九十九点八的这个请求都注意的。也就是说什么意思呢？你这个系统就个 right，你支持的慢一点没有关系，没有关系。
47:26然后你只要把是吧，只需要把这个 read 这个这个东西做的做很好就行了。所以呢现在其实 RD minitatr 四是有一些很经典的做法，就是说我能不能哦就是我是把这些 insert 啊 date 这种啊操作全放到这这个这个这个这个这个这个这个这个这个这个 CPU 上。然后呢，我这个 read 操作就是单面的操作，
47:45当然也有一些很很极端的这个这个系统啊，它做什么呢？就是说他们叫做 disagerate memory 啊，就是说我这个 read 啊，我这不仅是这个的，我所有的 reinsert 也要放到这个这个这个这个 RDV 的单边操作啊。
47:59我个人认为这这这这个系统是在凭空凭空造问题啊。因为你基本上你有 RDMA 的这个网卡的机器是是不可能没有 CPU 的。所以你直接用 CPU 做那些复杂的操作，其实会比这个啊的要要高效多。当然这是我个人个人的观点啊，不应对啊，
48:14这个其实在现在的学术线，最近一两年还是啊大家讨论的这个比较多的话题。 reo k 好，那不管你这个这个 update 操作，你是放 CPU 做还是放 RDV 做。其实这时候就会遇到一个一个很很很很很的一个一个一个挑战。
48:30这个挑战其实我们大家应该可能比较熟就是 recognition。所以带大家想想，我们说前面说对吧？我们说 update 你要放到这个 CPU 上做。然后与此同时呢我们要用网卡去读这样的一个这个这个 value。好，
48:43这个时候这时候我们下来想想，我们是我们怎么定 rase contasion 啊，就是有两个人对吧？他在做两个 concluder 这个操作，那他们会操作的这个 object 的话，至少有一个是 right，
48:52对吧？那么它其实就会有 rstcondition。那么其实在我们 RDMA 这样的一个例子里面，这个 race condition 显然是存在的。因为我的这个 CPU 它在做写操作，写这个 KRR store，
49:02然后这个 RDMT 在读这个 collestore。那么这个本身不就是有会有 rease conlesion 嘛。所以说我们对于做 RDMI 这样的一个系统里面，它其实啊都需要做一些这种 concurt c 啊，常常是求如果你不做的话，其实就会有一些这个这个吸引性啊正确性的这样一个问题。
49:18比如说我们可以来啊举个最简单的例子。好，假设我们还是以我们之前说的这样一个 contq s store OK。然后这个 QS store 呢，它是啊这个用这个这个单边 RDV 加这个双边的这个操作，去做一个混合的啊这样的一个实现。
49:32然后我们说这个这个查找的这个操作呢，还是 follow 一个 coocation tion，就是我先用一个 d 零，还是不还双击去找到对应的 bucket。比如说在我们这个例子里是一五三 OK。然后我找到之后，
49:43我是说我们发现这个这个 key match，这个时候我去读这个 key 所对应的 value 啊，这时候我们采用了一个分开的操作。因为我们这个 value 比如说可能说很大，对吧？我可能是几几几几招。
49:54那这个时候你其实没有办法。有一次 RD 维度啊，这个时候我们在想象的是一个事情，就是当我在用这个 RDV 对吧？去做这个操作的时候，我这个 server 啊这个 CPU 它同时收到了一个破损的这样的一个需求。
50:06这个破损呢就是说把我这个数据的这个值啊去做一个这个这个这个修改啊去修改。好，那那这时候呢我们大家可以想一想，对吧？会出现啊什么样的一个问题场景，我们今天休息吧，
50:21我是嗯怎没办法不要你打电话，你好，恶心一个，基本上不是他律所欲流机器人。对，然后你们是谁？
51:23你知道搞都可以，别刚才提醒我现在气死我真的多。那第四个现在好了，我继续一直这样子。然后我知道我的看看，但是嗯就是 PCC，
51:59你愿意我这条命命，我们有请什么东西。行，我去，他就是第一后，谁知道。
52:25对，我知道你给我找他这个锅，好像是长子一生。这个有些是鞋子呢，喂在呀，就是不是隔壁的，
53:14你看不成，刚才是我这个是其他人，你看看你从一分省一点点，其实我找不到原因，满意思，环境销量的话，
54:04几乎上有机不准的。没有，你好是有的。