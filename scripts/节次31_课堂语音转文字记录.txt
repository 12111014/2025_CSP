00:11听到是嗯你过来搞什么什么一天，你得嗯自己。对，嗯嗯，好行好，我们开始今天的上课。
05:41好啊，今天我们可能来讲一点，这个这个呃今天包括课个节奏，我们讲一点稍微呃跟现在的的这主主流较较切的话题题，对吧？就是比如说计算，
05:52因为尤其大家可以看到现在这个 AI 红红火火的。那么 AI 的这个应用，它其实和之前的这样的一个这个这个传统的这个应用，我们之前讲过的这样的一个数据库啊也好，就 call service 也好，它其实最大的一个区别就是它的这个计算需求实际上是非常非常大。
06:09它的这个以每个 request，它需要计算这个浮点数，其实数十倍啊是不少不少，应该是好几个数量级的。相比较传统的做做一个小淘宝订单这样的一个操作。那么当你的这个的就是你的计算场景变成对这个算算有那么大的需求之后，
06:25我们传统的以 worprloc PU 为公心的这样的一个呃 cloud 啊也好，分布系统也好，它的计算方式其实就相对来说啊不大适宜的，或者说它的这个性价比会非常低。所以说人们就开始会去演化出各种的这样的一个为这种巨巨大算力需求所需要的这个这个所需的这样一个系统。这个系统现在反正有个更更加大家熟悉名字，
06:47对吧？叫 AAI info，对吧？ AI infrastructure。但实际上它本质上还是是在于就是这个它它它本质上其实还是一个这个并行或者说分布式的这样一个技术。因为只有你通过并行和分布式 OK，
07:00才才才能够将你的这个硬件或者说你的这个软系统所提供的这个算力，能够啊非常提提供到一个非常高的啊这样一个数量级别 OK。好，那么我们再简单看一下之之间关系，就说其实我个人认为对吧？是从从过程中从这个这个那这计算机角度来说，
07:18对吧？计算机本身其实就无非就三块嘛，就是一个是计算的单元，一部分是这个啊存储数据的单元。最后就是说你计算你要用数据，对吧？
07:26你得在呃计算啊，你在计算任务之间去迁读读写数据。那么就我们就需要啊这样的一个网络。那么这个之前的课的话，我们其实是讲了呃有花很多时间去讲存储，而且存储确实很重要的。
07:38因为你数据存的不对，对吧？你的这个系统其实是没法算的。然后我们也花了时间讲了一下现在现在的网络 RDV，对吧？就是我怎么在呃我 RDV 到底是什么东西，
07:47对吧？这现在那么火，然后它为什么能提供非常快的网速？那么接下接下来的话，今天我们就就着重去讲一下这个 conpute，就是我们在系统层面，
07:57包括体系结构层面啊，怎么去提供一个非常强的算力。以及在我去提供这样的一个非常强的这个算力过程中，它到底有什么样的一个啊吹豆腐。好吧，行好。
08:09那么我们的例子的话，相信大家可能都比较熟悉的吧。就是我们假设啊我们有一个这种模型，比如叉 GPP，比如说你的这个像各种的这种 agent 这样一个 APP，对吧？
08:19不管啊你的这种 APP，它是啊一个 chat service 也好，它是个各种 code der 也好的，或者是 AGT 也好。其实在现在的这个云服务器场上来说，它其实就是一个这个这个 LM service，
08:31就是它会收到不同的 LM 的 prompt 啊，它会去执行这样的一个请求。它的这个范式其实是和传统的这个抛可能性是非常像的，非常像的。但是它不唯一的不同的点在什么呢？其实我们就是我们在一开讲，
08:45不是时候就提到过，就是啊我每计算一个请求，它需要的这个算意啊，我们说我们怎么跟它算，就是说我完成一个操作，对吧？
08:52我要计算多少个浮点数，浮点数啊，它是远高于这样的应用的。好，那么这边就会带来一个啊非常关键的一个问题。就比如说我我 AI 算法工程师对吧？
09:04它叫训一个模型也好，或者说它服服务一个模型也好，然后它有一定的这样的一个性能的指标。比如说他告诉你我这个模型，对吧？得在一天内去完，
09:13或者说他告诉你说我这推理理服务对吧？我的这个延迟 OK 要在这个几十毫秒内啊做完。那么我们大家就想了一个问题，就是说那我的硬件设备也好，我的现有有系统也好，能不能去支撑这样一个需求呢？
09:26比如说我这个算法公程告诉你，就 OK 我要训一个多少多少 b 的模型。好，我给你一个 APU，你到底能不能在一天内帮他训完当当然这东西是一种简单的思路，对吧？
09:37很简单，就是说啊我先去跑一跑跑一跑跑一跑，结果发现什么呢？发现啊这个东西跑了两天，那这东西它到底究竟需不需要能跑两天呢？大家想一想想想，
09:47这其实一个非常难回答的问题。因为你你你你你测试你做一测试，对吧？你跑了两天，那其实并不代表说我的这个结 p 又不够快，对吧？
09:55也可能是你的这个模型的这个训练的这样的一个这个这个这个代码不够好。那么到底问题在哪啊，到底这个这个能有没有这样的一个优化空间啊，那这个其实就是我们这个这个这个系统思维的人要去系统回答的问题。 OK。那么这个问题其实对于 AI 时代来说，
10:13我觉得是有一个啊比较好的特性。什么意思呢？就是说对于呃 AI 的场景来说啊，它的这个 workload 尤其训练啊相对是固定的。什么意思呢？就比如说我给你一个模型的大小，
10:26比如说是大模型，对吧？然后我给你个我告诉你，我有几个 GPU 啊，一般来说就是说它我们需要花多久把这个东西给训出来啊，以及它的这个性能的这个上界在哪里？
10:37就是我最快能多久训完，其实这是我们能够非常方便的估出来的啊，而且方便而且非常准确的估出来的，为什么呢？为什么呢？它的原因其实在于这个 AI 的这个场景啊，
10:49它的每个请求的算力实际上是相对来说确定的。什么意思？就是我比如做一次推理，做一次训练的一个 itertion，它到底要算多少个浮点数？大家可以思考一下，
11:00这个问题其实是非常确定的。它它跟传统的不一样大是像你如果传统你做一个我们之前讲的那个 transaction，对吧？大家回顾一下，就是我们做这个 two face locking 这样的一个操作。我们做一个 two face locking 这个操作，
11:12你能够估算出它到底要做多少条 CPU 的这个指令嘛。其实你很难估算出为什么，因为它上锁要到底要花多少个 cycle。它其实是 depends on 你的这个 workload 这样的一个呃 contention，对不对？ dedepenon king 呃有没有是个 dead lock，
11:26非常非常不确定。但是对于大模型来说，它其实非常确定的。为什么？因为你所谓的模型，或者说现在所谓的这个人人工制造的这样一个模型，
11:37他所干的事情无非就是做做做这个矩阵计算，对不对？大家想想我们现在的这种模型啊，大家没上 VI 课，没事也可以。其实站在我们系统角度来说，
11:47我们是根本就不需要知道它这个模型怎么来的。我们只要知道一个很简单的事情，就是你这所谓的几层神经网络对吧？一层神经网络无非就是我给你个 input，每一个就是个浮点数，对吧？
11:57乘以一个 weight matatux，然后加一个激活，形成成一个这样的一个这个这个这个 output，然后这个 output 会逐步递接下去，然后你模型有多少，我就算多少层，
12:08对不对？这个其实就是就是现在的这样的一个模型， essentially 看的是你唯一输完那些花活，无非就是什么？无非就是说 OK 我的激活环数可以变一变，对吧？
12:18然后我在这个算这个层激活之前，我可能要加一个天性模块，对吧？带着天性模块，大家想本质上也是什么？也是一堆这个这个矩阵成法搞起来，
12:27然后最终 MOE 对吧？ ME 的无非就是什么，我就在里面挖几个空，对吧？我挑几个 s 二，其实这个本质上是相对而言说是轻松的。
12:36好，那么有了这样的一个基本的这样的一个抽量之后，我们就会就可以把这个问题简化。比如说我假设我大家一个问题，如果我要去训练一个这个这个这个模型，对吧？
12:49我到底它做训练一次，对吧？要要要计算多少个负点操作，这个东西能不能算出来呢？这东西其实是能够大大差不差的算出来，大差不差算出来。
12:58因为其实现在的这个模型啊，它的这个训练方式其实相对来说是比较简单的。比较简单啊，我们可以讲一些 background 啊，其实大家模型本质是么？本质是就是说我要去决定这个就是模型本身身，
13:11对吧？所以从最抽象的这个角最最简化的角度来看，其实它无非就是什么就是你一堆这个矩阵乘法，列阵乘法当然当中加一个 patvation，然后所谓训练的本质是什么？训练的本质就是说我们怎么从一个 data et 里面，
13:27对吧？当然我们先不考虑这个 RL，这个问太复杂，就是说我们先考虑一个最简单预训练。那预训练无非就是说我告诉你一堆这个 ptext 的 pattern，然后呢，
13:35我希望的这个这个这个这个神经网络对吧？它预测的下一个词啊是实际上是我的个数数集集里见过的这个词 OK。那这种方式呢呃那个叫什么？我们做从站在一个系统里拿出拿出来，其实无非就是什么，就是我有一堆这个知道的这个 x 和它对应的 y 对吧？
13:52预训练型也是这样的一种范式。然后呢，我需要能干的事情什么？就是说我的这个模型 OK 它预测的这个词尽可能的和这个我数据集里的这个 y 更更更加更加近。那怎么更加近呢？那么 AI 的定义就是说我会有一个 loss function，
14:06对吧？无非其实很简单，就是把啊我的这个模型当前预测的值，当前预测的值和这个这个我见过数据的值做一个差 OK。然后它那个这个这个我需要什么？就我我的训练的目标是什么？
14:19就是说我找到一个这个这个这个 NN 的这样的一个 w 一 w 二能最小化这样一个 loss function。 OK 其实就干干这样的事。那么怎么找这个一个最小化的方式呢？那我们说这个其实就是用到数学里面的里面的一些这个优化技巧是吧？那么现在模型用的最多的对吧？无非就是一个叫做这个 so tistic great eket decide 什么意思？
14:38就是说啊我直接去解最优的这个 w 一 w 二，其实是是是很难很难解的那怎么办呢？那没关系，我只要什么每一次啊它其实说我们可以把 loss function 可以看成一个山路，对吧？然后我们其实要干的事情是什么？
14:51就是找到它的最低点，最低点，那怎么找最低点呢？那数学上的观察就是，而我给定你一个当前的这样一个 loss 方向。然后我换一个 w 的话，
14:59只需要往什么只需要往这个这个它的梯度这个方向啊去下降啊，其实就能够就能够比较快的逼进这样子最低最低。所以呢干的事情其实就是啊我每每每次我从数据集里面 sample 一个 batch，当然就这个 batch 不是随便选的，实际上是有点讲究的。但这是 AI 的人研究的事儿啊，
15:17给你这个 batch 之后呢，我就去去算这个 loss function，然后算完它的梯度。算完这个梯度之后呢，哎我把这个这个这个当前的梯度啊减一减，减一减。
15:26当然这个怎么减，其实是有些窍门的。但是这个这个质量量其不是是很 OOK 一一点之后啊一直迭代迭代，知道什么直到迭代。我说这个 loss 非常非常小为止 OK。那这个操作的话，
15:37站在这个站在我们的这样的一个系统的系统的角度来说，其实是非常非常容易的对吧？我们其实就就会发现啊，我们要预估我们这样的一个模型，大概需要做多少个浮点数。我们只需要干什么？
15:52我们只要去知道你这个这个算这个 DW 和这个这个这个 w 减的这样的一个操作，对吧？它大概需要有多少个浮点数？那么有了这这个之后，我其实就根据我的这个每个不同的这个硬件，比如说 GPU，
16:05它一般会告诉你说它每秒能算多少个浮点数，那其实我就能够估什什么估出的这这训练练少需要花多久，对不对？那么现在是接下来的问题，其实就是说我们在这样一个神经网络的这个 setup 下边，我们怎么去预估这样一个 w 那这个事情其实非常简单的。
16:22为什么我们说你你去算这样的一个过程，它其实无非什么？无非就是两步。第一步是什么？第一步就是我是先去做一次 forward，就是我把这个模型全部算一遍。
16:31那这个东西的话，我们对于每一层来说，其实它简化成什么？就是 w 乘以这个两个这个 XX，就就是有我们就要算一下 w 乘以 x 的这样的一个浮点数看一下。然后我把每一层全部加起来就结束了。
16:46然后呢，我们再算一个 backboard。那 backboard 的话，其实矩阵乘法的话，它其实这个这个这个这个我们需要同时算 DX 和 DY。但为什么要算 DY 呢？
16:53因为它它是模型是一层一层的。就是说我我比如说我在啊做做第第三层的这样的一个这个这个我我我在在我为了第第层的这个个层数，需要第三层层的这的这个这个这个底 DX 的这样的一个主的单位。本质上就是说我们需要算这个这个这个这个这个 y 等于 WS 里面的这个 DDDY 和二不 DDDDW 和 DXOK。那么这个事情其实大家可以看到，它就简化成一个什么一个非常非常简单的数学问题。
17:21就是我们的这样一个这个模型啊，它的前向它反向到底需要做多少次这个浮点乘法。 ok 啊浮点计算 OK 啊，浮点情的话大家去翻翻现现代书，或者去问问 GBG，对吧？
17:33就会发现这个东西其实非常非常简单的。什么意思呢？就是如果我有一个模型，它是一个服务的 pass OK 这个模型的它 w 参数大概是 m 乘以 k 然后 x 大于 k 乘以一。然后的话，那它其实需要的就是说这个这个两倍的这个这个 m 乘以 k 的这样的一个这个大概是这样子的计算。
17:50因为我每计算出一个 output， put 这个 value，对吧？我得把这个 input output 都过一遍都加一遍。然后为什么要两倍？因为你不仅要加你，
17:57还要减呃，你还乘，对吧？你要两个元素乘起来以是两倍大，然你得你得减去一，因为你最后一个元素是不需要加啊啊啊不对，
18:05不需要加了。然后 OK。那这样的话我们其实就做一个简单的变化，我们就 OK。所以我作为一个这个这个 forward pass，它所需要的这个算力的吧，
18:13大概就是两倍的乘以三 s of WW 什么？就是我们这个参数大小，大家看这是一个非常非常干净的这样的一个式子。然后我们作为一个反向，其实其实这个这个反向的它的这个矩阵的这个这个这个乘法其实是和这个这个啊这个正向均势的话，其实其实算力是一样的。
18:30所以说我们说如果你反向你要算两个叠 s 和 d 的话，其实大概也是也是每一次也是一个那个 w 参数大小的这计算。所以我们把它加在一起之后，我们就会得到一个非常非常呃简单，但是非常非常有效的这个公式。公式其实在模模型啊不至少是单 ance 模型下，
18:47它也是适用的。前面呢就是说当我要去做一个这个大模型的这样的一个训练 OK。然后我我每次做一次这个迭代啊，做一次这个这个基础下降的一个迭代，它需要算多少个负点？超算它的数量大概是六倍的乘以这样的一个这个这个这个参数的这样一个大小啊，
19:06对于每一个音炮的大小啊，对于每一个输入，那么你大模型的话，我输入的话，其实它它会额外的再乘以一个 sequence， less 再乘以一个这个白色色 anineal。
19:15它其实本质上就是这样一个六倍的这样一个 w 乘以的这样的一个公式。那有了这样的一个经验公式之后，我们其实就可以去系统的回答，对吧？比如说我要去训一个这个类似于 GP 四这样的一个模型，对吧？
19:28或者是我要去推推，其实就是个 forld 的嘛。那么每每一次的这个这个这个这个这个 iteration 大概需要多少负点超作呢？我们只需要把它的这个这个这个参数大小代入进去就行了，对吧？比如说 GPT 四啊，
19:41之前有一些这个这个泄露啊，当然这些其实这些模型其实都不都已经不算特别大对吧。当然之前说 GPT 四有一点七二 t 的这样的一个参数，那无非就是啊那么多个浮点数对吧？那么啊我们把它乘以六对吧？我们其实大概知道啊，
19:55我问我如果要学一个数据啊，在一个亿 g 学系里面大概就需要花啊那么多个零的这样的一个这个这个这个这个做做个附件计算。好，那么假设我我比如说我的硬件告诉你说，我们现在有一个这个 gpu，比如说 a 一百或者说拿一百电脑，
20:12现在都 b 了，对吧？来对吧？每个 GPU 它的这个其实都会标一个非常重要的东西，叫做 flops，对吧？
20:18大家可能经经常听说过这个字叫 flows。什么叫 flops 啊？就是说我一个硬件对吧？它每秒到底能做多少个负减数？好，那么这个东西我们除一除啊，
20:27我们其实就能发现哦，原来我这个如果一个一百 GPU，它如果这个这个要去算这个这个东西的话，对吧？它大概需要三十秒才能够去算完一个这个这个这个这个这个就是当然啊对，那么我们其实就就可以大如果你有多，
20:42那么多个数据集，你要算多少个特 atlation。对吧我们其实就可以去计算出这样的一个这个这个这个这个这个整整体训练时间的这个最快的这样一个情况。那这个时候我们其实就可以站在这个这个这个这个呃系统了的时候，对吧？我们就可以估计说唉你到底是硬件够不够的。
20:59比如说你的硬件，我告诉你，我的这个极端算力啊，我需要告诉你几十年才能够算出来啊，那我其实肯定就是我硬件是不够，那怎么办？
21:06我就得去换一些这个算力更长的设，就是说从 a 版换到 b 一 b 两百对吧？ anyway 这样一个事儿 OK 好好那么给定这样的一个计算之后，我们其实会发现现在因为有 skill ino，对吧？ skill e low 是说说我的这个模型参数啊越来越大越来越大。
21:23然后呢，我的这个训练的数据要越来越多，这就意味着什么？意味着说其实这个现在的模型对算力的这个需求实际上是非常非常大。大家其实可以看到这边我们虽然算出来对吧？这个 a 一百算这个 GBC，
21:34一个 GBC 啊，需要三十秒，但这个计算其实是非常非常的理想的。新现算第一就是这个 a 一百，它其实只有八十个 GB 的这个显存，它其实是放不下这么大的模型的。
21:44你这放不下这个模型的话，你的这个把缓存额外会有缓存的开销，会影响你这个基本上这是第一点。第二点的话，我们是说我们这边其实只训练了一个数据集度啊，就是 by by sisize 是医 c llze 也是等于一。
21:56但实际上你为了有这样一个常模态的这样一个能力的话，你的这个 sequence 基本上是要几千啊，现在是一到几百 k 对吧？然后你的这个这个这个你的一个 besisize 大概也是要要做几百。因为你不可能一个个数据选，那太慢了，
22:08肯定是几百个这样数据去选。所以我会发现你如果用一个 a 百的，我把这些东都都上去去，会发现你这个一特一个月的特一特征性的这个时间，对吧？就会从这个三十秒对吧？
22:19涨到一百啊，涨到涨涨了。好几百倍啊。相当于说如果你有一台机器一一张卡，对吧？即使在最理想它的内存能放下的这种情况下的话啊，
22:29它其实也需要这个这个这个啊几百啊几几，可能就要几几十分钟才能训。那这个其实当然现在的模型其实以你最大规模的话，一个一个一个及时性大概也需要几分钟。但是其实就是说这个其实其实是说这个算力还行，还是非常非常紧张的。
22:45我们理理想情况下，我们是希望什么？我们要解解这个问题呢？我们就希望我们的这个设备它每秒能够做更多的这个浮点数，对吧？你只有把美秒能做更多的这个负件数去提上去，
22:56 OK 我的这个整个系统啊 k 才能够啊算的更快，我们才可能更有可能去接近这个所谓的这个 AGI，对不对？所以这个这个今天这一节课，我们的一个很主要的这个话题就是说我们去看一看，对吧？
23:11现在我们的这个好算力设备这么重要，那这些算力设备它究竟是怎么能够提供这么高的这样一个浮点算力的。以及更重要的一点就是说这些算力设备它的这个瓶颈在哪？瓶颈在这。其实这其实我觉得最最重要的，因为呃我们可以看到的是人们想要去提升浮点算力，
23:31它其实并不是一个那么简单的这样的一个事。包括嗯我们可以看到英伟达它它其实每年都号称它的这个算力翻了好几倍，对吧？但但是他这个好几倍其实是有一些水分的。因为他的这个比较啊，其实大如果仔细去看它的四 s 店，
23:46电方可能会发现不大公平的一个最然的例思就是说他可能说哎我新一代比前一代这个快了可了四五倍。但它其实它快速被它的这个这个比较的对象是完全不不是非常公平的。比如说前一代算的是一个 FP 八，就是八位的这个浮点数。但是它后一代算的实际上是 FP 四，就是四位的浮点数。
24:04那么其实理论上来说，你算四位的这个一个算一个八位浮点数，这这个这个这个操操作的这个这个个个应该是能够算两个个位浮点点的这样乘，对吧？这其实就是一个相对来说这个公平比较。但为什么会会做这样呢？
24:17因为其实其实体积结构上来说，你要去进一步的 skill。这个这个浮点啊实实际上是是是是是是不大的，这个是是没有某一的啊。对，没有某一的 OK。
24:29那么这里面到底会有什么样的一个 challenge？我们这些都会大家讲，大家大家从头过一遍 OK。行好好，那我们来看一下啊，就是说我们其实现在的人类的这个制造出来的这个设备啊，
24:39其实在放在几十年前，其实是很难很难想象的。因为因为我们其实现在的不管是它手机也好，我们我们现在平板啊、笔记本电脑也好，它的算力其实已经比比几十年前的这个数据中心更加强了，
24:51对吧？其实怎么强呢？我们其实就可以去看它的这个这个浮点。比如说英特尔对吧？英特尔是个目落的公司啊，它的这个这个笔记本上啊，
25:01它提供了 CPU 的这个算力是是个六点三 g 啊，这就是是是是是兆呃，就是九个零啊，然后然后它能够提供哎，九是 g 是九个二点九个零。对，
25:11然后它其实最它每秒最多能提供的是三十七点七 g 的这样一个 prox。但是像华为这把华为的这个手机啊，它全称能能够提供二点三 t 的这样的一个 crops。然后啊苹果的这个这个这个这个笔记本做的还比较 AM 芯片，对吧？做的还比较好，
25:27它也能提供三点六 t 我们可以看到的是它的这个浮点数是有一个很大的跃迁的，包括像现在的这个数据中心，对吧？比如说像英伟达，它的这个 a 百啊，当然这个移数已经非常老了，
25:38现在其实应该会大很多。就是说二十二十七的这样一个 boss，其实可以看到，基本上都是数量级的这样一个提升。包括这个这个这个 TPU 对吧？就是说很多大家可能会听说过一些这个呃这个加速器的吧，
25:51尤其 TPU 最近还很火的就是说说用 gggle 的这个 GP 点。三是这个这个这个 TPU 迅能嘛，它这个效果非常好 OK。那么这些设备我就大家去想一个问题是吧，是是英是这个这个这个英特尔做的比较烂啊，他他没有办法把把这个这个这个这个这个这个这个这个这个浮点数提高到那么大程度吗？
26:12那那苹果的这个 m 二是不是我也能够提提供到这个英伟达的这么这么高的浮点数。那这个东西的话，其实啊从原理上来讲啊，他 scskill 呃，我认为啊就我人认为啊就是他们 skill 这个这个浮点数的这个这个这个方法其实差不多的啊，其实主要的差别我觉得还是在呃具体的细节的设计以及这个生态上啊，
26:33其实是可能做的不定有运用的。好，那为什么这么说呢？我们大家可以去看一下这个原因。当然其实我们前面说呃这个这个这个这个你光有这些设备其实是不够的。比如说我即使是有这个 a 百，
26:44对吧？ a 一百其实在国内这个已经算啊还还可以的。这个这个能买到的这样的一个比较比较好的这个芯片。我们其实可以看到的是你光有一个设备其实是不够什么。那这样大家可以去看一下，就是最近几年的英伟达的这样的一个这个这个这个这个设备的一个 t fflow。
27:05我我会发现它单芯片的这个这个 flops 啊，它其实涨的也也其实也就每年大概两倍差不多。这样其实也就是大概概概几百 t 的的这样一个程度。这个程度其实是对于盈的的这个舰舰的这种种 GT 级别的这种模型是是不大够的。我们其实可以用刚刚那个样的一个这个这个做一个简单计算，就刚刚什么意思？
27:25刚刚我们前面说了一个事，就是说我们去算一个头肯啊一个头，肯这个 a 一百大概需要三十才能够去做这样一个操作。但是你你为了让模型强对吧，我们根据 data 的 skilling law，我们需要给这样一个模型啊，
27:41它去这个这个这个这个这个这个喂很多的这样一个数据要喂多少呢？比如说这个 GP 四错了，对吧？它其实说是是需要为十三个 t 的这样一个个数。那么这样的的话，我们其实简单先去乘一下，
27:52就会发现你如果就是一一台这样的一个设备啊，你是 a 一百啊，我需要四百年，我才能够把这个 GPD 四给去往它选。这显然不这是你换你现在的比较百，它也就乘以了一百的这样的一个一个一个数一一个性能能。
28:08它你也需要四年才能训，这个其实是完全完全也是不能接受的对吧？那那吧那么我我们的问题是说，现在如果我们能买到的设备，比如说就 gggle TPU，对吧？
28:17现在最最最快的大家拍那么多，那么这样的一个设备，它如果也不能完全需求怎么办呢？这个时候其实啊我们就一直要强调的一个非常重要的事情就是什么？就是说我们的训练它或者说 AI 计算。其实现在 AI 计算，
28:30它不仅仅是这个单卡的这样的一个地方，它其实是一个所谓的一个分布式集群。那么分布式集群它的好处是什么？就比如说我一张卡对吧？它是它的浮点能呃算率是二百七十五 t 那我两张卡就是五百 t 五百五百五十呃，五百五十 g 对吧？
28:46然后我如果更多的这个卡，其实理论上说也可以，一是可以一直 scale out 这样出去的，那么就就要提供了这样一个更强的算。所以说我们的设备的这个版图啊，其实我们会发现它是从单核 CPU，
29:00对吧？到这个手机端 GPU，到这个最终 GPU，再到这个 NPU 啊，或者 GPU 最后到这样的一个集群啊，其实现在的人们的这样的一个问支撑，
29:09那么大的这个计算对吧？其实是其实设备是这样的一个啊逐步演进过来的。那么在这其实他会想想的一个问题，就是说那我站在这个用户户的角度说，是不是我永远挑最大的这样的一个算力的设备。比如说我就一直用 TPU 啊，
29:27不用这个 TPU claster，对吧？是不是就能够把这个能够搞定算力的呢？这个其实就是我们今天讲的另一个点，就是说你所有的这个硬件设备也好，分布式也好，
29:37它去 skill 算力啊，它其实用的一些基本的方法是非常类似的非常类似的。然后这些方法直接并没有说谁比谁好，他们之间其实是有一些 trade off。那所谓一个很明显的 trade， of 就是啊你算力更强的这样的一个方法。
29:53它的这个呃可编程性相对来说是是更差一点的，就是说你的用起来就会是更难的。大家也可以看到，对吧？现在有一堆一大堆，对吧？
30:01在用 AI 去写这个用 GPU kernel 的这样的一个 GU 程 g puu clo 对这个程序，那这样一些工作，为什么呢？因为这个 priability 是很差啊，相对来说是比较这种，而且不不仅仅是 probability。
30:14其实它的这个 flexility 且也会有一些对应的这样的一个差别。 OK。好，那那么那么那么到底这些差别是啊怎么来的呢？对吧？那那那我们就接下来我们就简单，
30:27我们就从从头对吧？我们先从这个一个 single device，就是说我这一个一个单核的这个 CPU 啊，我们给大家简单过一回过下去看看我们说在单核 CPU 的这个时代，对吧？我们怎么去 scale 这个算力，
30:39然后为什么单核 CPU 不够？我们得去用多核，那多核又会引入什么挑战？多核。不过说为什么我们要引入这个这个 DSA，对吧？
30:46类似于这 domestic 这个个 reon 啊，这些其实是都是啊逐步引号来。 ok 那么回顾回到最初啊，最初人们大家想我们就是说我们最早的这样的一个计算设备，对吧？其实都可以认为是一个叫 CPU。
31:01零四年以前其实主流的这个计算设备就就是一个单核的这样一个 CPU。那单核的 CPU 的话，它的一个极大的好处什么？就是说它的这个开发是非常符合我们人类的这样的一个直觉。大家想我们我不知道现在怎么样，但是说至少我我我上学的时候，
31:17对吧？我们就要程程序，我们都是一一个什么单线程的这个程序写起来的，对不对？我们不会有之前我们讲的这样一个并发的这样一个事情。然后在所谓的单细节程序呢，
31:27它的硬件实践其实也是非常简单的。比如说我写了一大堆 c 加加代码，或者说呃你拍断代码，其实也让让家更加复杂一点。就是说我无我的硬件，无非就是去 fetch 一下你的这个代码里的指令。
31:39然后代码指令之后呢，我就去一个这个 ALU 做一个计算。然后计算的过程中呢，我可能会有一些这个这个为了保为了这个这个这个这个这个这个提升这个内存性能也好，我有一些 cash 对吧？有一个 data cache，
31:53然后还有一些这个 context，就比如说我当前的这个 PC 啊，双方的是哪一步哪一步 cono k 就是这样的一个很简单流程，就是我一个个书记会会一个 stage 一个 stage 的去把你对应的这个操作啊，相信大家上过题结构可能都会清楚这样的一件事。好，
32:09那么这个时候有了这样一个架构之后，我们其实就可以问一个问题。就是我们之前这样一个取一个指令，做一个计算，然后做一个数据存储，然后再做下一个这样的一个这样的一体系架构架，
32:20对吧？它每秒能做多少的这样一个浮点计算，这个事情大家能不能算出来呢？那其实一个最简单的算法就是说假设我完成一条指令，比如说 a 零加上等于一需要花四条，这个呃就是 instruc PU 底下的 instrustrucycle。
32:38那么我们这个时候我们会发现就在其实就是取两个点就血 a 低这个这个指令对吧？到底多快的速度能发？那么这个东西呢就会关系刚才叫什么，我们就会大家回想一下，对吧？我们就会有一个东西叫做 CPU，
32:51有个叫 cooperate，对吧？就是说我的这个 CPU，它因为它是个时序机对吧，它是它是它是我们得以一个多快的频率去发射这个指令。然后呢，
33:00第二个关键点就是说我每一个指令周期，它到底能做多少条这个这个硬件的指标。如果我每一个指令只能做一个这个 fetch，只能做一个 ALU。那这个时候的话，那我的这个总的这个吞吐决于什么？
33:13其实决于你的 cooperate 去除，以你的这个每个 instruction，对吧？它到底要花多少条指令啊？平均下来平均下来。那这个东西的话，
33:22显然你这个一一般如果你要做一些复杂的 CPU 操作的话，它的这个只需要指令是很长。那么你这样的话，它其实你除了这个因子就很大，那怎么办呢？这个时候人们就会说，
33:32那我就是需要有一个是吧？大家对想经典的就是 pipeline，就是说我这个 CPU 在在某一个 cycle，对吧？它在做这个解码的时候啊，另一个另一个它的这个 ALU 啊和它不能不不一样，
33:44让它空下。然后同时时计计。然后这样一个 pipeline 下来的话，我们其实就会看到一个很重要的事情。就是说好我们在一个正常的一个比较基本的这样的一个 CPU 里面，它所需要就是单核 CPU 它它算算力实际上也是很好分析的的最高算是什么就约等于什么。
34:01它的这个这个 croperate 就是说它每秒能发射多少条指令 OK。那这个时候人们有了这样的一个基本的题结构之后，我们后续的这个体系结构是干了什么事情呢？就是说就是要让它这个变得更快，对不对？变得更更快。
34:16 CPU 怎么让它的这个每秒所然的更快呢？其实其实历来的话也只有两种方法，一种拍。就就是我们前面讲的 pipeline，就是我让每个塞购的时候，所有的这个取原件都在处理。
34:27当然这个事情不是那么去不是那么简单啊，你不同的这个指令，它的花的时间是不一样的。比如说你去做一个 ALU，它只需要一个塞口啊，一个 cyo 就能做啊。
34:36但是你要去读内存的话，它需要搞好几个 cycle。那如你你有条指令，它的这个内存它没有填满怎么办？那其实就会有这个拍卖的 buttle。所以说我们啊为了为了减减减少这个 pipeline buble 怎么办呢？
34:47其实一个经典化的这种就是要把这个拍卖的变得更更细。以 CPU 里面来说，一方面要干的事情就是说它这个经经拍啊，它其实是会变得更加更加的复杂啊，变得变得变更更加多。那第二个就是说这个我我要把把要 cccperate ate 去增加，
35:02对吧？这个其实是也也是一个很直观的因素。因为我们说你假设在一个理想的这样的一个吞吐情况下的话，这这它的 groups 基本上啊就等于 cooperate。所以我们看到的是在前几十年对吧？我们的这个机器的这个主频是一直在增长，
35:17比如最早八几年的时候，它的这个主频是十兆赫兹，对吧？它现在的机器基本上都是属于服务器，对吧？都是三 g 赫兹，
35:24三 g 赫兹，如果笔记本还会更加高一点啊，还会更加高一点。 OK。那么到了这个之后，其实我们会发现一点，
35:30就是说假设啊我们已经给定你一个判断，给定你一个这个 cooperate，其实我们我们不就这个这个这个这个这个这个上升空间不就定死了吗？我们有没有办法去更进一步的去去去去去提升呢？这个时候其实是体育结构那边啊，当时在这个八几年的时候，
35:48七八七十年八几年的时候，大家会玩的一个东西叫做这个 IOP，就是 instruction level pass。什么意思呢？就是说之前对吧？我们说你每一个 cycle，
35:57我们就发射一条指令 OK。那我们有没有办法我们去构造多个这样的一个 search cocode 这样的一个单元，使得说我每个 cycle 能够发好多条指令，比如发四条指令。这样的话我一个 cyl 能够同时解码四条指令，对吧？
36:11那这样的话，能不能去做一些更快的这样一个加速呢？其实可以，对吧？如果理论上来说，我一秒钟能发四条指令的话啊，
36:19那么那么那么我的这个吞吐对吧？理论上来说就是我的这个 proporate 乘以你的这个这个这个 LP 的这个维度就是四其实最高我觉得每秒能做十二 g 的这样这样的一个操作一个理响情况 OK。那这个时候其实我们会看到十二级已经是一个非常非常相对来说非常快的这样一个 s 它非常快，但其实离我们这个这个倒这个倒还还远，不过对吧？十级级其差不多也是现在这个个 CPU 和的差不多一个一个一个个标标档，
36:45对吧？十二级这个后面的 TT prs 也很快。好，那么这个时候大家想一下，就是说我们这个方法看上去是能够 scill 的，对不对？
36:55看上去我比如说我的主频主频是是能够 scill 的啊，其实这个主频 scale，然后我也能够通过加加 p 的这个这个宽宽，对吧？让它的这个每秒秒做的每个 cycle 能做的这更加加上去。然后其我们看到在二零零三年之前，
37:10这个 CCU 的的这个算啊啊，其实确实也是按照这样的一个趋势，每年翻倍。 double 什么是 double 上去的？为什么？因为这这个主频主频翻倍，
37:20我的这个算力就直接翻倍了。那是不是我们搞一个 CPU 就搞搞定了呢？对吧我们是不是就不需要 GPU 啊那些东西。其实我们站在现在这个二零二五年，已经快二零二六年的这个时间维度，对吧？
37:33我们来说这个事情我们可以肯定发现它是不对的。 CPU 其实已经停滞了很久，甚至是啊我觉得这个停滞，甚至十几年前就出现了。我我印象很深，就我们实际上是一五年买了一台服务器 OK。
37:44然后我们在二零年的时候又买了一台新的 CPU 服务器。然后我们测了一下，发现这个二零年的这个新的服务器的这个性能，对吧？其实还不是一五年的太慢，为什么 CPU 它不能够继续的这样的一个个上上？
37:56这个其实有两个原因，它其实两个原因就取决于什么？就它其实有三个原因啊，就是说家家我们这个 CPU 去提升算力的本质。就三条路嘛，第一条就是我拍拍的 bubble 要减成零，
38:07第二条是我的主频要升高。对吧？第三条是这个这个这个我的 ILP 宽度要变大了。那首先拍卖这个东西，它你再怎么设计啊，其实目前人们已经大家达成共识，
38:18就是说它总会是有一些环保是消消不掉的啊，它它你总归是有些空泡的，所以说这条路基本上它也就也也就堵死了。而且它基本上它也是不可能影响到这个最优的这个值的。那么第二步就是说我们能不能去增加这个 fast cooperate 呢？实际上被证实证是不行。
38:36为什么？因为它这个硬件，大家用一些现在的这个这个这个这个这个做芯片，对吧？都是都在纳米级别啊，或者纳米级别高一点上去做的那它里原因会导致一个问题，
38:46就是当你的这个芯片，它的这个这个这个主频上去之后啊，它里面的这个温度啊，它其实其实我啊我印象它是一个应该是个平方上涨的这样一个量。就随着你的这个靠贵的导致这个结果就是当当你的这个阻频提高到一程度之后，你的这个 CPU 内的这个热量会非常非常高。
39:05英特尔之前有是 skill 到，比如说六七级就会发现它基本上温度就会到达，这类似于太阳中心的这样一个温度。那这个这个东西的话，那你意味什么？因为说其实本质上什么，
39:15本质上是我只是这个热量，对吧？它没有办法及时的去散热出去 OK，那么没有办法及时散热出去，导致一个问题就是说你在实验室对吧？我在一个大的时间时候，
39:25我显然是可以去做一个温度受控的。但是如果你要比如说我放在一个笔记本电脑的，或者说我一个数据服务器，然后每个服务器温度都跟太阳一样，对吧？这个显然是这个这个设设备基本上就直接就爆掉了，
39:37基本上是不可商优的一个一个现象。所以说这是一个非常经典的东西，叫做这个这个东西。对，对于 GPU 也也是存在，对吧？
39:44你 GPU 也是有也是有类似主屏的这样的东西。所以我们就会看到一个东西，就是说在二零零三年之后，对吧？它的这个这个 CPU 来说，它的这个 crop fraacacy 已经停滞了。
39:55包括现在的这个 croprovy y 停滞，它的核心原就是有一个能量强，能量强的这样的一个这个因素在 OK。所以这个导致的结果是我们没有办法。对于 CPU 来说，我没有办法去过过增这个 ccorporate 的这种方式啊，
40:10让它这个吞吐去进一步的变高。那除了 cooperate 这样一种方式，我们也没有其他方式。因为我们前面说你的你 CPU 对吧？增增呃，增加这个算力，
40:19除了 covert，还有这个 LP，对吧？就是我每秒能发射更多的这样一条指令，能不能用这样的 LP 这个方式去提升算力呢？其实我们看了也不能啊，
40:29这条紫色的线啊，当然这个线比较啊，大家可以看一下我们这个发的课件。我们可以看到在二零零零后面的这样的一个情况下，其实这个 CPU 的这个算 inl p 啊啊它这个超标啊，它其实的的宽度也不会增加了。
40:43为什么呢？因为其实大家想想超超标量的这个技术，它所的一个 assumption 是吧？就是说 OK 我应用程序写了一堆这个 instruction，然后呢我把这些 instruction 去并行的去发射。好，
40:57这个时候并行发射。大家想想会有一个什么问题啊？就是我的串行指令之间其实是有 depenency 的。比如说我们有一条指令叫 x 等于啊 register a 就是我我读读 reduce a 的这样一值。然后呢，我们说 x 等于 x 加上一好。
41:12大家想想这个东西我 x 这两条指令能不能用超微量去同时发射去执行它，其实是不能执行的。为什么？因为这条指令里的 x 是值是多少，取决于你上一条指令的这个这个值读的这个结果，对不对？
41:27那意味着什么？就是说你要做超标量，我得去 track 这个指令之间的这样的一个 dependency 的这样的一个关系。那这种情况如果我只有四条这个超标量，嗯发射哎其实是没什么问题的。但是如果你要去做，
41:40比如说八条这种更更大的这种 LP 的发射。其实大家想想，我们这个硬件复杂度就会非常非常高的升级。就是就是这个其实是我觉得做集结构跟做这个系统软软件啊软件是非常不同的一点就是哎我们软件可能会觉得说 OK 我加一点这个这个额外的判断 dependency truck 操作这个事儿开销不大，对不对？那大家想想啊，
42:03像如果你要实现这个超标的话，你其实实现了什么？你实现的是一个硬件，什么意思呢？就是你的硬件无非就是决定我在一块这个方块内的这样一个新元晶元上，我到底要留多少资源，
42:16做抵扣的，我要离多少资源啊？这个抵扣的是指定抵扣的啊，不是大模型那个啊我要得多少资源做 ILP，对吧？然后我要去做这些 dependency，
42:24我每加一点逻辑，它都会用这个芯片的这样一个面积。然后你的一个芯片，它的面积其实是是是相对来说是固定的。几十年来，这个这个人们每个单芯片的这个面积，
42:37它的增长其实是相对来说是比较缓慢的。意味着什么？就是说我一旦超标做上去，我的这个逻辑辑 dependency track 的逻辑就非常复杂，非常复杂。导到结果就是我根本在这样的一个硬件的这个这个有限的这个 physical air 里面，
42:51它其实没有没有没有办法去去直接在这个芯片上焊上去，导致这个结果什么就是我就不能够去去去加更多的 IP。所以我的 IP 其实也就会停滞。我们可以看到在这个零零年以后，对吧？这要不二零二零年以后的二零零零年以后，
43:07对吧，这个事儿就就就就去停滞。这个其实我觉得就是在这个这个我们有很多大家很多集结过研究，对吧？会觉得说哎我什么东西去去硬化一下这块，这个其实就其实是哦我我不做这块，
43:18但是我觉得这块实际上是非非常非常难的。因为本质上的原因，它是有一个核心的这个面积啊，和你的这个到底要做哪些逻辑的这样的一个 trade off set 这个 trade off 非常非常重要。其实我们后面可以看到的是你 GPU，它为什么能够在相同的这个晶圆面积上，
43:35对吧？做到比 CPU 更快的四点数。并不是因为说 OKGPU 这个这个这个这个很牛逼，对吧？就是说它有什么黑科技，并不是只是说 GPU 它跟 CPU 在这个到底哪些逻辑用在计算，
43:47哪些逻辑用在这样的一个用在这样的一个这个这个这个这个存储上，它其实是有这个这个这个有一个非常大的这样的用 OK。好，行，那到这边来讲的话，我们就会知道，
43:58就是说你站在一个单核的角度来说，我强行要把一个单核的这个 stream 嘛，把它去并行的去去去去执行。这个东西其实是是很难的啊。因为你要做做很多的这样一个 dependency 的分析， dependency 分析。
44:12所以说呢里面的结果就是 LP，现在的话基本上也就是一个比较小的值啊，不会做一个特别特别大的值。那这边所以就会我们就会出现一个很经典的这个现象，或者说声号跟摩尔利律有一点关系。就是说啊这个这个这个我在二零零四年之前，
44:35对吧？我们的程序员其实是这个这个这个这个这个系或者设置系统软件的开发人员，但火是非常非常轻松的。就是我如果老板让你去优化一个新软件，我跟你说我不需要优化，我只要坐在这等等个半年，
44:48英特尔发布了一台新的处理器，主频翻倍还要可以翻倍。好，我的这个性能直接翻了个四倍啊，但且一般没有，一般还会积极啊，
44:56高没那么快 OK。但是我们会发现这个二零零四年之后啊，你这个事情就不存在我的这个 CPU 每年它它这个这个性能啊，就是说绝对性能是差不多的。当然 CPU 它其实还在演进啊，它演进的比如说有一些什么虚拟化能力啊、
45:12安全能力啊，相信大家呃像肖老师应该也会讲一些大家可以注意。但是其实至少我们从绝对的性能角度来说， OK 这个事儿就已经传到 scskill 上去了。好，那么这个时候我们去 skill，
45:23这时候大家我们可以还是要回过头来去看。这样我们说你 skill e 计算本本质什么？就是我要做并行，对吧？大家想 IOP 的本质什么？就是说我这个四个指令要并行的去计算，
45:34并行的计算。但是我们说这四条指令并行计算的我难点难点是什么？就这这些指令之间是由这个 dependency 的这样的一个关系的那我在硬件角度去 track 这样一个 dependency 是非常难的那我怎么能够做到既能做到这个并行计算，然后呢我又能够我能够做到这样一个 dedepenence trtrucket 的这个逻辑非常非常简单。就我硬件没有不提供这种 dependence trucking 呢。那大家想想它本质是什么？
46:02本质就是说我让软件来做软件来做软件方。我告诉你说这几条指令是没有 dependency 的。好，那这样的话，我硬件不就是傻傻的把这些东西都执行，这就结束了。
46:13那这一步出来的就是我们接下来要讲的一个进一步 skill 的方式叫什么？叫多核。多核是什么？就是我一个单核的这个程序啊，它其实是是是 LP 很难做并行。那我就是说我就给你提供个多层程序。
46:28我告诉你，你如果一个程序员对吧，你给我一个程序，你给我一个程序之后呢，我的这个每个我就告诉我给你两个核。然后呢，
46:37你要用我用完我这一些算力呢，你就让这个两个和尚啊分别跑一个程序。这个程序之间呢有没有 dependenze 关系？是理论上是没有 dependenze 关系。那这样的话我硬件其实就不需要去 track dependense，我就可以把原原本去留给这个 i 去做这个复杂 tracking 这个事情。
46:52对吧换成一个很简单的直接换成能做这个 ALU 这个计算单元，以及它对应的这个抵扣单元。那这样的话哎我不就是能够能够都能够就是说吞吐进一步上去吧，进步上去。好，那想想这套方案听上去跟 LB 很像，
47:08它的核心的 trade 腐是吧吧，它其实是把硬件的这个复杂性转嫁给什吧。转嫁给软件导致的一个结果。就是我们去软件程序员去写一个程序，它的这个这个开发成本就会高高不少，捞不住来这个东西没有那么吹，
47:25要没有那么简单。我们可以来举一个例子，比如说我们要做一个非常简单计算，就是说我把一个非常大的 array，然后呢我给大家去做一个累加。好，
47:34这是我干的这样一个事。我如果是写一个单线程的程序，对吧？我们是不是这么写就可以了，这么写我就写个 for 循环，对吧？
47:42非常的简单。好，但现在我告诉你单线程程序，我这个性能已经到顶了。但是呢我这个机器里面除了一个核以外，它还有很多个其他的核，
47:51那我要怎么做呢？那如果我要写一个 multiple ort 的程序，我程序员得干些什么？是啊，第一，我得写一个类似于 master 的这样一个程序，
47:59我要把我原本这个单线程的一个任务给切分成什么？每个 thread 它的任务对于每个 thread 直接切好之后，我还要去写一个单独的这个每个 thread 的这样一个操作。操作完之后， OK 我最后还要写什么？写一个这个汇总的这样的一个程序，
48:18把这个每个 spread 结果作为汇总起来。好，大家想想这个事情本质上是什么？本质上不就是把你的这个这个这个硬件的这个成本转嫁给了这个开发人员吗？其实我那大家可能会说对吧？你给的这样的一个很简单，
48:33例子很简单，就是说你是一个累加的这个程序，看上去很简单，对吧？那实际上你真实计算的例子，比如说大家想你如果算大模型，
48:41你算一个矩阵乘法，你能不能简单的以这种方式去划分啊，你能不能以这种简单方式去做划分？其实是不能的对吧？这个这个这个矩阵乘法你要做分块，你要做各种的这种场景，
48:52其实会会复杂很多啊，但是这个我就不会不是很具体写。所以我们可以看到你简单的把程序变成多核。虽然从理论上来说，我提高了这个硬件的这样一个并行性啊，但它带来的代价就是什么呢？
49:05就是你的开发人员啊，为了写这样的一个并行的这个程序啊啊，其实是需要花一些精力的，而且并行。你把计算并行这个东西，它们在硬件上并没有那么区别，
49:17为什么呢？因为大家想想，我们虽然是一个多核的这个程序，对不对？但是我们这个多核它访问的这个数据还是同一个数据，对不对？
49:28大家想想，这就会带来一个很经典的问题，就是我们的 CPU 是有什么是有这个 cash 的对吧？大家有没有记住？就是比如说我两个核读了同一块内存地址内存地址，他们其实都会把这个数据去读到这个 cathe，
49:43然后去修改自己 catch 的值。然后呢，如果我有多个核，它就会带来一个问题，就是我的一个 catch 的。我比如说我 CPU 零，
49:50我可以先在我一个 catch 值，我 CPU 一它它它它们到底能不能看到这个质量，理论上是什么？它是需要去看到这样的值。这个其实就是什么？就是我们之前分布式讲的这个森的 consimodel 值。
50:04它其实我们就发现你光有多个除了我这个编编程难度以外，对吧？它其实还有和一系列的这样一个新的问题啊，我们先先休息吧，然后下期节说在幸福里唱就是嗯第四遍。那好，
54:03 yeah，对不行。