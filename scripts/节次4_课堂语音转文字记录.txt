00:11对你你支付机器人嗯嗯， server 天。好啊，大家好。那今节课我来给大家我们的这个今天上课的内容主要是给以一个这个比较真实的这个系统。就是比如说像淘宝或者是这种这种大型的互联网服务，
05:49它背后的这样的一个系统的组成，来给大家介绍一下，更更更大家深更深刻的去大家理理解一下我们啊上节课夏老师里边所说介绍，对吧？有很多这个系统的这种性质，对吧？
06:01它在这样的一个真实系统里面到底的代表是然后这样的一个以以这种淘宝为代表的这种互联网系统，它本身的复杂性是非常高的。它的系统里面包含着几几十个上百个这样的一个大组件，每个组件里内部又有很多的这种小组件。那为什么这样系统会设置的这么复杂，对吧？
06:22其实它的本质原因在于啊，我们为了像支持这种互联网用的高可扩展性。我们每扩展很多系统其实都会遇到很多的这样的一个系统的这样的一个问题。就是为了解决这些问题，我们才需要引入一些系统的设计 OK。所以我们这边会带大家稍微回顾一下历史，
06:42看一下大家怎么从一个很简单的这样一个系统啊，淘宝一一点点演化成一个非常啊复杂的系统。当然这个这个架构本身不是局限于淘宝，是现在的大模型推理，对吧？其实本质上啊采用的这些架构是啊非常类似的。
06:57然后啊我觉得我们 CSP 本身啊，它并不会啊讲啊或我们会介绍一些比较细节的这种技术啊，但我觉得更重要的一点，可能包括我们今天课内容是带大家啊去领略一下，对吧？就是我们怎么去一点点的去发现系统问题呢？
07:12因为本质上我我个人的观点啊，在现在大方型已经非常厉害的这个时代，对吧？你去发现一个更好的问题，其实比你想的一个呃更好的这种 solution 可能会更加重要一点。因为呃其实不知道大家有没有关注，
07:26对吧？像那个大模型，最近像呃 HGPT 五啊，还还有吉木乃对吧？它已经拿了这个 ICPC 的这个世界冠军，对吧？
07:35然后其实我还完全的去看了一下大模型解的题目，然后发现很有很似性。就是大模型它里面有一解决了一道问题，是一个这个什么管道问题啊。然后他跟我，因为那一周我正好也投了一篇论文，
07:47然后他跟我这个论文里面，我在解觉得一个规划问题正好是差不多的。所以意味着什么呢？意味着其实以后你这个任何一篇 paper，对吧？你只要定义清楚了这个问题，
07:57很有可能啊，你把这个问题给的这个建模给扔给大模型啊，大模型其实是孙浩能给你解解个百分之八九十啊，我觉得未来可能会演变成这样一种趋势。所以我觉得更重要的一点，对于我们来说，
08:10对人类来说，对吧？因为这些问题它毕竟还是人类提供给大模型的，所以我们理解这个问题啊还是很重要。因为毕竟目前为止对吧？大模型或者说说还是没有办法手动的去一点点把我们的这个系统啊 build 出来啊，
08:25 OK 行，那这个就是我啊产品废好啊， OK 我们就正式开始啊这样的一个上课啊。那么我们说我们如果要设计一个系统对吧，那么我们这个一个系统它肯定是为了支撑一系列的这种目标，对吧？
08:40一些目标，那这些目标是哪里来的呢？这些目标并不是我们系统研究者拍脑袋，想当然，你也可以拍脑袋想。那你拍脑袋想的结果就是你做出来这个系统可可能没人用，
08:50对吧？就我我之前我跟我我学学我们学生跟我们讲我们在做什么样的研究时候，就就说对吧你你我们可以比如说为猫和狗设计一个操作系统，对吧？这里面肯定也有系统问题，但是你本身你你造出来这个操作系统没啥价值，
09:03因为因为因为不是不会有人用。对，那么其实对于网站啊也是一样，对吧？那么我们就得看看，比如说我大家想你如果是淘宝的这种，
09:12或者说你是一个比如说 mini，对吧？总架构师，好，你要想一想你的这个系统它要支持什么样的能力呢？其实我们会发现啊，
09:21不管现现在的所有的这种互联网应用，它所谓的能力啊，都是是你聚焦到三种非常重要的这个能力。第一个能力就是他每天需要处理海量的请求，对吧？大家每个人手机都有可能给这样的一个后台的这样的一个服务去发请求。
09:37那么人数尤其在中国，对吧？人人口非常庞大啊，我们肯定知道这个请求量非常的非常高的。那么伴随着请求的话，一个第二点很重要的需求就是这个数据的这样的一个容量，
09:50对吧？我们每一个请求不大道有没有注意？你跟大模型交互的时候，其实是大模型都会记录，偷偷记录了你这个历史的这个谈话内容，对吧？
09:57那这些内容它肯定都是要花很多的这种数据存储去把它给管起来。我怎么把这些东西给管理起来，对不对？然后第三点我觉得大家可能都没有注意到的一点，就是说我的这个服务对吧？它的这个服务能力，
10:12就比如它每秒到底能做多少请求，能存多少数据。大家有没有发现这个东西，它其实并不是一个禁止，什么意思呢？就是比如说双十一对吧，
10:21双十一的这个业务流量比这个这个比这个这个这个平时我们现在这个点肯定高很多。但大家想想，我们现在这个点跟双十一用的用淘宝对吧？体验上会有很大的差别吗？当然十几年前啊这个还是有一点差别的。但是最近两年对吧？
10:39大家会发现其实体验差别会非常小，为什么呢？因为淘宝啊它做了一个很重要的一个能力，叫做 transparent 的 celeability。什么意思呢？就是它这个系统的服务能力啊，
10:51包括它存储的能力，它能够随着你的这个负载这个去变化。这样的话我用户其实就不会因为你比如说处理能力不够，而感觉到一个服务不可用。这个其实也是啊一些像现在那种互联网巨头还是做的做的非常啊非常重要的一个能力，如实我们做的不好。
11:09那我们后面会有例子，比如 DGC，对吧？就就刚开始始 DPC 啊，刚才就是说互流量器一一一一下子子来的时候，那其实我们就会发现那个用户的体验其实受到很很大这样的一个影响。
11:21 OK 行，那么这是我们的这样的一个背景。然后我们这个背景啊，大家可能会说，哎呀，你你怎么都二零二五年了，
11:27对吧？还在讲这个这个淘宝对吧？这个这个例子不会有点老了嘛。啊第一啊，当然这个为什么选择淘宝呢？因为啊第一点对吧，
11:36因为我们的课件大部分是围绕淘宝做的对吧？这个是很很直接的这样一个，你迁移的话成本比较高。第二个呢，其实我觉得是系统里面一个另一个很重要的点。就是啊你不管是这种 AI 系统也好，
11:49也是这种互联网系统也好。你会发现他们背后的某一些构建的这个这个这个原理啊，你要你要发他们遇到的问题啊，其实是是非常非常类似的。当然每个不同的领域会有这样的一个他们自己的这样的技术。所以我们 CSP 其实我们并不会啊会深非常深入的去讲这个每个领域特定的这个技术。
12:12比如说你 AI 对吧？做做 AI 系统的这个专门的 AI 系统课啊，一个数数据处理，有数据库专门的课。但是我们希望传达给大家，就是说我们啊他们遇到的一些问题，
12:23其实是类似以及解决这些问题题的些啊啊本本原理啊，其实也是类似的。我可以举个例子，对吧？比如说哎这个大模型的这个恰 t 服务为代，对吧？
12:33大家想想，我们来类类类比一下的话，觉觉这个恰恰服务和这个淘宝宝有什么质上的的别别吗？大家想想，我们至少目前来看对还没有一个很颠覆的应用出现的时候啊，我们去和这个这个这个恰恰服务做交互。
12:49无非就是我发发一个 HTTP 请求到他的这个服务器，对不对？你淘宝不也是干这个事儿吗？它唯一的区别是什么呢？唯一区别是这个淘宝啊，它当它一个请求，
12:59那它可能就是会修改几个数据库，然后就返回了。那么大波型的请求呢，无非就是他在 GPU 上做框框框，做一个矩阵矩算，对吧？
13:07返回了啊，他们在服务模式上其实没有什么改变，改变的是他们服务的这个具体的这样的一个这个这个这个内容啊，所以你对于一些更好的服务请求，比如说你做一些弹性的这种 scale 啊，以及你去做一些负载均衡这些技术对吧？
13:24其实在大模型里面仍然会遇到这个跟淘宝的这样的一个场景相同的这样一个问题。那类似的对吧？我这边也说到大模型的这种服务商，为了提供更好的这个服务，对吧？它会把用户的这个历史记录都留下去存下来，
13:38都作为 context。那这些 context 它肯定要存在某一个数据数据后端，对吧？像现在有那个向量数据库，那向量数据库也也也有很多其实存在传统的这样的一个数据库里。那么它一定还是会需要面临这个传统数据库所遇到的这种容错啊也好，
13:55这个这个这个这个这个可靠性他们这个问题其实是一样的。当然其实新的应用对吧？新的应用它其实肯定还是会会那个叫什么这个这个这个有他自己的解决方案，比如说啊自己的独特之处。比如说我们这边提到对吧？但你恰恰一个服务它的一个请求的处理的算力，
14:13它要求是比这个传统的下订单要高好几个数量。这就意味着我们一定需要有一些啊专门的这种加速器，对吧？ GPU 啊好，或者说叉 PUNPU，然后也需要有专门的这种高速互联啊，
14:25去把这个服务的好。那这个我们会介绍一些呃那个大概的这样的一个技术 OK。所以我们也不是说我们只是介绍非常啊经典的这样的一个系统 OK。然后呃在在具体介绍我们这个架构的演化之前啊，我我们可以再再再强调一点，就是前面我们讲到的是啊一些，
14:45比如说 quest rate 也好，这样的一个这个 data 也好。那么其实我我觉得在我们系统里面那个或者说分布 sh 里面还有一点很重要的一点就是这个 stability 啊，我们能不能在供一更好的这个 stability。这个其实在 AI 时代其实非常啊非常重要。比比说举个例子，
15:03从服务的角度来说，对吧？这个是当年那个一月份对吧？ DBC 突然火了起来之后啊，大家不知道大家有没有印象，对吧？
15:09不管是微信也好，其后端端也好啊，他们都会报一个叫做服务器繁忙的问题，对吧？那么这个服务器繁忙的这个问题，站在系统的角度来说，
15:18它到底怎么实现呢？服务器繁忙不是带上不是一件好事情嘛，我厂商买了这个服务器，对吧？它他应该服务对吧？它不应该放能不能空转。
15:27那为什么这个服务繁忙会对用户带来一个不好的体验吧？它到底在系统层面意味什么？也就我们到底该怎么去解决它，对吧？这个是我们系统做 AI infile 的人啊，需要比如说需要解决的这样的一个问题。
15:40当然你的这个英尔的这个本身，它不仅仅在于服务端，对吧？它还在于训练端，对吧？相信大家这个研究生的话，
15:48现在应该都大家或多或少听过一个东西，叫 fskilling law，对吧？ skilling law，它本质上就是说你的这个 AI 模型啊，它的那个越大啊，
15:57参数量越大，或者说你训练的时间越长啊，数据元数越多，它的能力会越强。这时候其实就会涉及到一个很有趣的这个问题啊，很有趣的问题。
16:07就是大家有没有想过一件事情，就是说我们现在 AI 对吧？翻天覆地的这种方式去改变了我们的这个生活。那它背后到底是因为这个算法的人啊非常啊牛逼，还是说是因为系统的人非常牛逼，还是说是这个为两百七二百分？
16:26大家可能会好奇说这里面有系统的人什么关系，对吧？我 AI 的人搞了一个算法，我把它跑通不就行了吗？那大家其实可以想一想，对吧？
16:33其其实我我个人觉得啊，就是说这种 AI 算法的这个成功，其实或多或少离不开系统的这样的一个在 scheduability 上的突破啊，导致它的成功。我们可以举几个例子，比如说二零一二年对吧？
16:46当时 alex net 大家有听说过吗？第一个这个卷积网络对吧？卷积网络在一在呃刷新了这个图片的数据，大家有没有想过，对吧？ alex net，
16:57它的这个算法上跟经典的这个卷积网络到底有多大的这个区别？大家想想它的一个其实从整体的算法角度来说，并没有特别大的这样的一个区别，它它无非就是它更大一点，对吧？更深一点。
17:10那么大家想想为什么 alex net 能取得这么好的一个效果呢？其实大家很很多人都没有注意到的一点是， alex net 是第一个呃，在应该是第一个啊在 GPU 以及在多 GPU 上训练的这样的一个神经网络。它的那个那个是一座的 alex，那个非常牛逼。
17:27在当时啊二零一二年的时候，他成功的用现在的这种模型并行技术啊，在多个 GPU 上把这个模型给跑了起来。所以它的这个模型不仅啊不仅它能比别人做的更大啊，它也能比这个别人训更在相同时间内训训练更多的这样的数据。它用 GPU 这样的一个高速的这样的一个技术。
17:48这个其实啊就是一个系统其实是一个系统侧方面做的事。虽然它是一个算法的人 OK，然后这个事儿其实并没有并不是很区别啊，比如大家用过排套去就会知道，对吧？如果你非常简单的把你的这个排套去跑的这个模型，
18:04比如参数乘二啊或者乘四。你当你乘到一个一个 factor 的时候，就很很可能就会发现，这就是他那个会报什么这个 GPU out of memory，对不对？这个时候你就需要什么，
18:14你就需要去在很多卡很多卡上去跑，那么你可能去跑八张卡啊，可能还好，对吧？如果你要把一个系统跑到一千张卡一万张卡，对吧？
18:23大家有有想过这一一千张卡一千一万张卡到底怎么连，对吧？这个本身都是一个纳个问理，包括其实这边是举第一个例子。 alson。第二个例子其实就是那个叫什么叫什么这个这个这个 GPT，
18:35对吧？ GPT 其实大家都很感受到，它其实就是个力大专飞的这样一个事对吧？一二三每一代其实参数量都会这样一个庞大很多，那么对吧？那么好好，
18:44大家想想 GPT 我记得是二二年末，对吧？二二年末当时火爆的，其实二二年末有一个有一个很大的这个世界标志性事件啊，就是大家都有没有注意啊？就是二二年末是这个这个这个英伟达的这个 a 百这个 GPU 大量出货的这个时间点。
19:01然后 a 一百它跟前一代 GPU，这个 v 一百啊，它有个很大的差别，就是 a 一百它的这个显存会比这个 v 一百大很多啊，大很多大两倍啊，两倍都不止。
19:13导致的一个结果。就是说哎然后对，然后导致一个结果就是其实是你 a 一百这种集训，其实集训非常非常大的这样的一个这样一个模型对吧？僧耗。所以说这种啊 skill 上的这样的一个提升，
19:25也是很啊能直接带来这个啊 AI 的这样的一个这个突破的。当然这个需要我们 sisteter 能做很多的这样的一个这个系统设计啊，对我们这节课会啊稍微讲一些啊，也会讲一些这个怎么 skill 过程中遇到的这样一个问题。当然最后这个这个现象啊，其实 AI 的人其实也注意到啊，
19:45他们其实有一个非常重要的这个定义啊不要定义嘛，叫做这个叫呃经验，对吧？叫做这个呃的 btiless lesson 啊， bitters lesson 说了什么事儿呢？就是你你有有很多 AI 的算法，
19:56对吧？你花里胡哨，搞了半天，其实效果还不如什么呢？就是你把一个简单的这个算法 OK，你把它 skill 十倍或者 skill 五倍啊，
20:03它的效果往往会比你这个一个花里胡哨的这个算法更好。其实大家想想，这个定理在现在还是封号还是成立的对吧？你你想那个有 kiimi k 二，对吧？它号称比 DBCC 好，
20:16它为什么好呢？它其实价格跟 deep c 的长得是非非常非常像，对吧？它就把这个参数乘乘了一点几倍，本来应该有两倍啊，一 t 一 t 对这个六七一币对吧？
20:26当然它其实小小的架构会有一些调整。但是就是说啊我们可以发现就整体来说的话，如果我们的一个系统对吧能够能够提供一个非常强的 skill 的这样的一个能力的话。 OK。那么那么这个本身其实也是非常重要 OK。那么我们怎么让系统提供的一个非常 skill 的这样的一个能力呢？
20:46其实我们会发现啊，它背后所支撑的这样的一个系统啊，它它基本上都无外乎都是某某一类特定系统的这个子集啊，这类特定系统就叫做这个 paral and 这个 didiriributed 这个 system m 这这也是我们那个实验室的大名，对吧？这个这个这个事 OK 行行。
21:04那么那么我们今天这节课就跟大家介绍一下，为什么这个 partner 一个典型的这个 parner and distributed 这个 stestem 啊怎么演进的的，以及他这个研究过程中对吧？到底会遇遇一些什么样的一个问题？ OK 我们的这样的一个例子啊，我们就拿淘宝嘛作为这样例子，
21:23其实也是非常经典，对吧？非常经典。那么我们说做系统的研究者对吧？我觉得一定要有的一个或者不不一定系统研究者，或者说你你假设我我我我是一个系统设计的，
21:35或者说我是一个系统实验实现的，或者我是一个系统架构师。我觉得一个非常非常重要的能就是我们要知道每一个请求它背后发生了这个到底发生了什么事情啊，就是说它你知道的越细节啊，说明你对这个系统越了解什么意思呢？大家想想看，
21:53我们比如说一个互联网淘宝的这样的一个应用，对吧？那么它给我们的应用的点视角，就是你无非就是摁几个 button OK，我就可以去下单了。 OK。
22:05那么大家有没有想过，当我们按了一个 button 的这样一个动作，对吧？做完之后，这整个系统的背后会发生什么样的一个内容呢？其实现在的这样的一个淘宝对吧，
22:19它是非常非常复杂的。当我们啊不管你在手机测也好，电脑测也好，或者是甚至你这个现在你这个 agent 也好，对吧？当你按一按一个这种按钮的时候啊，
22:30它其实背后会 fok 出啊几十个几百个请求。会经过非常非常多的这样的一个系统的这样一个组件。然后为什么它要变得这么复杂呢？其实本质上原因就是因为它要实现我们最开始讲的这个三个需求。大家会想我们最开始讲三个需求什么？就是第一我们要处理海量的这个请求。
22:50第二是我们要存储这个海量的数据以及啊第三就是我们需要的系统能够 scale。而且这个 skill e 要是 transport 的，这是我啊用户啊不去感知的。那么大家肯定会想，对吧？你去 build 这样的一个那么复杂的这样系统做这样的一个提供这样能力力，
23:07那么肯定是是呃肯定是开销很大，对吧？像这种系统一般跑在一个数据中心啊，一个数据中心美元啊，就上亿的这种运营成本。那为什么我们不能够？
23:17比如简简的，我就比如说把它跑在我一个台式机机上，或者说我一个实验室机房上去做这样一个事呢。其实开始始吧，最早早的宝最早早这样样的个像像 ebo 他们其实啊也是从那个时候演变而来的。但是他们在刚开始，
23:34比如说我把这个系统啊部署在这个这个这个这个一个一个一台机器的时候，他们会发现啊我的系统没法满足我这三个要求。当然他这三个要求也不是一一蹴而就，对吧？他的离近一点点这个增加上去。那么这时候他就会发现啊，
23:49我需要每每每次有一步，比如说我美性就让每出历史呃增大增大两倍啊，他可能就会遇到一个新问题，每增大两倍，他可能遇到新统，所以他就一点点的去把这个系统给完善完善，
24:02变成我们这个样子。所以我们啊第一部分对吧？我们其实就会带大家看一看这样的一个这个过程啊的过程。那我们可以看到就是说当你的这个这个这一开始对吧，我们最省事的啊这种啊，去这个这个这个这个 go build 的一个这种淘宝的话，
24:19其实我们像现在这吧，这张大模型就是在我的一个笔记本上去生成一个淘宝的网站。大家想想我基本上给他一个 prompt，对吧？稍微交互几个人就能够完成了，为什么能完成呢？
24:29其实是因为我们人类对吧？之前啊为大模型 build 了很多好的工具，对吧？比如最早的这种工具是这种 linux 对吧？老板 touch 这种前端的服务器以及 mysql 这样的一个数据库和 PHP 啊，这样的类似的这种可以去定制前端的这种语言，
24:47对吧？那么大家有没有想过这种非常经典的连大模型都能完成了这个搭网站的这个架构，对吧？它有什么样的一个问题的，我们可以去看看，对吧？
24:56它的这套网站搭起来之后啊，它背后的执行流它是这样子吧，每每当我按一个按钮对吧？它其实就会啊通过网络对吧？发一个请求到前端的这个比如说 apache 的这个服务器，然后呢，
25:09它会根据他会去跑一个脚本，这个脚本会从这个文件系统啊去拿这个图片，会从数据库对吧？去拿这个商品的订单，拿完之后呢， OK 他会把这个结果返回给面 FF 之后再返回给用户。
25:23 OK 就是这样的一个很简单的这个架构。那么在这样的一个架构下，我们能想到的第一个问题就是假设我这个用户对吧一一流量一直在，然后每个用户他一直都去这个在里面去上传这样一个数据。那大家想想会出现什么样的一个情况？我们说你上传的数据得存在这个文件系统和这个 datababase 这边，
25:48对吧？然后这个 data base 它的数据又会存在哪呢？大家想想你这数据库课，虽然你可能大家都上数据库，但但大家可以想象到，我的数据库的数据肯定得存在这个硬件上的这个能存数据的地方，
26:00也就磁盘，对吧？磁盘也好， SSD 也好，我所 m 也好。那么大家想一想，
26:05我这个磁盘，它一台机器，假设啊我一开始用这种非常简单的这个我在笔记本上布一个方案，它会遇到什么问题啊？我一台机器它能存的数据量是非常有限的对吧？或者说至少在给定的时间，
26:18比如说半年内啊，它其实是很难扩展，除非你去完全买一个更好的服务器。但如果你当时买的服务器，对吧，是当现在这个这个最新的啊最新的这服务器，
26:28你会发现它这个服务器上它就是几个固定的啊，这个磁盘 OK 你插满插满了之后，好，我这个服务我这个数据就存不下了，存不下了，那我怎么办？
26:39我这个系统我这个网站就可能就崩了吧啊，崩了吧。那这个时候这个问题其实在这个非常早的就出现了。一九八零年七零啊七零年八零年九零年时候，那时候就已经有这样一个问题。然后发现现了这个问题之后呢，
26:53就有些很厉害的厂商，比如说像 oracle 对吧？他就说哎我能够给你们这种蜂桥网站的这个服务商啊，做一个提供一个服务。什么服务呢？就是当时大家有没有呃他他 oracle 啊，
27:07它提供的是一个非常巨型的这个机架啊，这个机架里面呢可以插满这样的一个磁盘，插满磁盘，然后它也有自己的处理器，定制的处理器和这个定制的这个内存 OK 它的什么好处呢？他就说第一我这个机架比你就服务器大很多啊，
27:24它有一个大的机架啊，全部都是装满了这个磁盘啊，所以说它的呃 capacity 空间啊是比你传统的这种一台服务器大很多的。当然它至于为他怎么为什么能管那么多磁盘呢？其实你用到的本质也是一个分布式系统，但那时候因为他会赚钱啊，
27:38但是他就帮你全公众号。然后他对外提供了一个这个这个对外提供了这样的一个这个 SQL 的这样一个服务。也就是说我的一个服务器上这个应用啊，它可以基本上啊不去花很多的这个力气，我就可以用你的这个 oracle 的这个服务器 OK。然后这种其实我们现在很多国企对吧？
27:59他应用的也是用的这种巨型的这种盒子啊，来来来去做这种服务的。所以大家可以看，我们有时候国产化其实非常痛苦的。因为你跟这个 oracle 这个网页比较深。 anyway，
28:08那这种情况有什么好处呢？就是我应用端对吧？它其实不怎么需要去考虑，我这个数据存储，其实他其实还需要考虑到。但是比如说他那他那个每年对吧，
28:17可能需要我去 oracle 买一个更大的这个磁盘阵列 OK。但是整体来说，他把这个任务外包出去了， oracle 就可以帮你负责搞定。这个存储。其实我们可看的话，
28:27把存储 skill 其实是个非常难的这样的一个问题。所以刚开始就会演演进出一一类的这种架构，就叫做这个计算存算分离，对吧？其实现在都都是在讲很多，对吧？
28:37其实就无非就是啊我我的这个网站服务商啊，我就去做服务网站啊，然后我存储就交给给另一个人弄。但是大家想想，我们一旦把这个东西去分离了之后，就会有一个问题。
28:50就是啊我原本比如说我一台机器对吧？我访问这个 database 啊非常快啊，非常快的就访问好了。但是我现在要通过这个第三方的这个服务啊，不管是这个 oracle 也好，现在是语音上也可以提供这务啊。
29:03就就发现一个问题，大家想想，那从我的服务的质量角度来说，是不是我的这个一个应用啊？它读取数据速度会变慢，对吧？
29:12大家想原本我去应用去读取一个数据，我就读一下本地的磁盘结束了。现在我先要通过网络，通过网络之后呢，我还要去读取一个后端的这样的一个 disk。那它的这个实验不就会翻倍吗？
29:24对不对？那这个时候其实就是我们为为 fill 过程中， oracle 它提供了一个很强的这个数据存储能力。但是他第一他他他必然而然的就会引入这样的一个访问延迟增大的一个问题。那这个时候怎么办呢？我们的系统能就想想到一个事儿，
29:42对吧？那么他观观察一一事事，就是说我虽然这个用户的数据很多，对吧？但是其实真正某一时刻用到的这个数据啊其实不多啊不多。但是数据这其实就是二八定律嘛，
29:56二百百分之二十的数据会接受百分之八十访问。那如果我把这百分之二十的数据缓缓存在一个离业务更近的地方。比如说我缓存在用应用的这个服务器这边，那我们就能避免掉这个慢速存储的这样的一个开始开箱嘛。这其实也是系统里面最经典的三大优化技巧，对吧？
30:14一个 cash 啊叫 cash。那么有问题。就如果我这个一个 application server 对吧？它的这个容量不够怎么办？因为一台机器，它的内存当尤其在当年当年的这个机器的这个内存其实都不是很大。
30:27一两个 g 到头了都套套了了又怎么办呢？人们就会想到一个事情，就是哎我这个要存这个数据，本质上不是需要有很多的这个呃这个内存嘛。那我一台 server 的内存不够，那怎么办呢？
30:39我就开很多个这个缓存的服务器来去存。那么这样的话，我不就是说我能够只要我这个这个这个这个这个这个这个文字估计看的多，对吧？我就能够很大程度的去加速我这样的服务的这样的能能这这个架架构，大家看上去其实都非常简单，
30:57对吧？你其实现在大模型也有轴，对吧？你把 KB cash、里里这这这个这这个 ch 里对吧？放到磁盘里面，
31:03其实现在也有这样一种这种设计，因为它其实必然而然的就会遇到一些新的问题。比如说在这个传统的 catch 里面，一个很经典的问题，就是当我的这个数据分散在了多个这样的这个这个这个这个 cache 服务器里后，那我的 application server 对吧？
31:21它到底要去我比如我要访问的一个数据，它的它比如说名字是 ADC，对吧？我到底应该去哪个服务器是什呢？这个本质上什么问题啊？它就是一个这个这个 routing 的问题是吧？
31:32对吧？其实大对大模型其实也是一样，对吧？我一个请求我要找到它那个前缀匹配的这个这个 KV cathe 在哪里，对吧？其实都是都有这样的一个 routing 的问题。
31:42那这个问题和这个问题好好不好做呢？好，我再大家想想这个问题，其实第一眼想一想，其实看着还是挺好，做对吧？
31:50最简单的方法就是哎我做一个这个 hash，对吧？我把它这个 hash 到这个这个这个我通过 hash 以下，就是它的这个 key 啊，当然不是 k 以开始这个啊，是是就是那个数据的 kekey 到它对应的机器器，
32:03我不就能到到这个应的的个个数据所在地方嘛。 OK 这个其实 hash 这个方法在大部分情况下都是能够非常好的这样的一个啊这个也是一个系统里面经典用的这个方法。那他会遇到一个问题，什么问题呢？在我们去做这个 transparent skiling 的时候啊，它会导致很多 cash 的东西不可用。
32:23什么叫大家再回想一下，我们前面说 transpaskilling 说什么。当我这个 workload 的负载变多的时候，对吧？我能够系统能力自然而然扩强。那么对于我这个 cash 的这个系统来说呢，
32:33我就是当我的这个 workload 变大的时候，我能够开更多的 cache server，对不对？那大家想一想，我开更多的 cache server 这件事情对于一个非常简单的啊，我们这种用 t pass 一下，
32:47然后磨一下 server 这种方式会有什么问题啊？大家可以简单算一下，或者问一下大模型，对吧？这个些我就是让大模型算，对吧？
32:54就是说假设我一开始有三台 catasserserver，然后我突然我的我因为这个要要访问区便多了，我把它开了四台开 server。在我开这个这么多 server 的一瞬间啊，会导致我百分之五十的这个 key 啊，它的 address 就是它的在机器的位置比这个射变变了。
33:13这个映射一旦变了，大家想想就会出现什么问题？站在用户的角度来说，它这个态势瞬间一败就不可用。它会有个普通的的的这个 job，对吧？
33:22突然一瞬间就会有一个很大的空间，然后得慢慢的才能够会上去。那这个东西的话对于现在，尤其是大家可能有听说过 serverless，对吧？这种服务器的数量啊非常频繁的在变，
33:34这这种场景的话显是非常非常不不友好。所以为了解决问题，当然这个问题很早就出现了。我觉得最早是这个应该是零零几年、零零八年还是那个啥，就 amazon 有个 diamond 的这个 paper，
33:47对吧？那么它里面提了一个方法，就叫做这个 consistent hashing 啊。它的意思就是说 OK 我的这个 hash 的这个模的这个 server 数啊，它不应不用去这个这个这个不应该不应该去映射到一个具体的 server ID。而它应该是映射到一个逻辑的这个 server 的这个逻辑的这个地址空间里面。
34:05然后呢，我用逻辑的方法去找这个啊上面的这个自由地址啊，那它的好处呢就是说我每比如说我机器从三增加到四之后，其实我只有百分之二十五的这个呃 cash entry 会 invginate 掉。那么这样的话，它相比较之前这种钛双了，
34:21它在这个 transpspskill 的这一个能力上，对吧？就能够啊做的更好更好。所以我们可以看到，即使是我们加一个这个非常简单的这个 catch 的这个问题，对吧？
34:32它其实也会有这个这个新的系统问题出现。那再加想其实对于大模型来说，对吧？也这个问题也是比较也比较不一样的。因为大模型的话，它的这个 p 啊它并并不是一个 exactly match，
34:45它是一个 prefect mash，对吧？也就意味着你一定得需要有一个高效的这种是吧？在高校里边的一个前缀的这种匹配啊的这种这种啊 lokup 这种方法啊去做。所以啊在它本质上对吧？但本质上其实都是一个这个 lokup 这样的一个问题。
35:01行，那么到这边为止呢，我们讲过了 OK database 啊，这块事情我们可以外包出去，通过分离的方式让它 skill。然后呢，
35:09我们可以通过 catch 的这种方式啊，去减少这个 skill 带来的这样的一个这个延迟问题。那么接下来就会有一个很重要的事情，就是我们的这个最终对吧？服务的人他是一个每台机器，我的这个笔记本上或者说服务器上的一个前端的这种服务器。
35:26那大家想想我一个前端服务器，它到底能服务多少的这个请端？大家有没有想过，如果你作为一个网络总架构师，对吧？你就我就开了一个这个服务器有没有想过我这个这个这个笔记本，
35:38对吧？它每秒到底能处理多少个请求？这个事情其实并并不难，对吧？我们可以用一个压测去把它算出来，对不对？
35:44比如说我这个笔记本，假设他就每秒钟能处理十个这样的一个请 OK。我们知道我这个这个网站现在的 picak 的这个流量十。那大家有没有想过一个问题，我真实就我这个部署的这个服务啊，它能服服务十个。
35:59但是我在真实的这个 serving 的这个场景中，对吧？它可能正正好就是一直都给你来十个这样的请求嘛，那可不可能会说有一瞬间，对吧？他访问了这个，
36:09他给了你一千个这样的一个请求来来做访问，对吧？大家想想没有？有可能。那如果我假设我有一台处理能力，是每秒十个请求的 server，
36:19就是我突然来了一千个请求。那大家没想过我这一千个请求里面最坏的这个处理时间会是多少？大家有没有想过，这其实这个经典的这个排队论的这个问题，对吧？就是说那其实结论也很简单，
36:32它的一个处理时间至少是要做这个一千除以十是多少一百秒对吧？它至少要差不多是在一秒一百秒才能访问，才才能做完最坏的这样的一个请求。那大家想想，如果你发了一个请求，他这个做了它需要一百秒才能响应，
36:47这意味着什么？意味着说我这个请求基本上属于不可用的这个状态，对不对？所以我们很多时候我们前面提到消息，像 diep ick 那个繁忙对吧？繁忙，
36:57它确实这个 server 在繁忙，但他其实并没有讲到这个问题的本质。他这个本质其实说我这个 server 盲道我来不及处理你的这个请求了，对吧？所以他在比如说他 deep sic 规定好，我两秒内一定要给你个 feedback。
37:09那么他发现这个两秒内 server 没有处理完，他只是告诉你繁忙，但他其实本质上这个请求要花大概一百秒毫五九。刚刚我们这个十二是一百个因子，把它横走完。那所以这个问题本质是什么呢？
37:20本质是我的这个前端这个服务器，对吧？它没有足够的能力去快速的消化掉这个堆积的请求。这个时候他其实请求的这本身的执行时间已经对于你的这个整体响应已经不重要了。他的排队的这个时间就是在等他之前的这个请求完成的这个时间啊，才是这个整体的这个性能的这样的一个结论啊，
37:42这个问题非常非常有意思。我们对也来研究它，他其实有一个背后有一个很深的呃呃，也不是很深吧，就是说有有都有一门专门的学科，对吧？
37:50叫叫排队论啊里为其实有些很有意思结论。那么排队论里面有一个很很经典的结论是什么呢？就是说假这我的一个系统服务能力是 x 然后如果它接收到的一个流量是远大于 x 的话，那么最终它这个这个延迟啊，就用户感受到这个延迟实际上是随着这个队列就是等于多少请求等待啊，它随着这个平方上涨平方上涨。
38:14因为什么呢？就是说当你的这个一个系统稍微过载了一点点，一旦你过载的时间稍微长一点，你这个系统基本上就烂掉了，服务不可用了。所以意味着什么呢？
38:25意味着说如果你是一个 system 的这个总架构师，对吧？你得保证啊我的这个系统的这个这个核心的这个吞吐应该是要稍微大于应该是要大于呃这个这个它当前受到的这个流量了。好，那么这个时候大家可能就会有一个问题了，对吧？
38:43就是我们说我一台笔记本对吧？一台局源，那它的每秒的处理的这个东西，它就是有个上限。那如果我这个时候用户的这个请求这个就是远大于这笔记本怎么办呢？对吧？
38:57一种方式是我能不能买一个更好的笔记本呢？其实现在来看也比较难，对吧？因为我们也知道计算能力很难去上涨。这个时候一个很自然的想法，就是我能不能根据我的这个请求有多少，
39:12对吧？去动态的去调整。我有多少个这个前端的这样的服务器，对吧？比如说我有十，我一千个请求，
39:19我就开一百个这样的 x server。如果有十个啊，我就开一个，我如果没有我就全关掉。那么这个其实也是现在呃大家有没有听说过的名字叫 service 吧，对吧？
39:28就所谓 liservice service 就是这样的一个这样的一个范式 OK。那么这种 skill 的方式就是目前大家肯定一想到吧，这个不是我小我初中生，我小学生我都能想到嘛，对吧？我这个几倍的流量，
39:40我就跑几倍的这个请求啊，几倍的这个服务啊，它其实啊里面还是有一些一些挑战，有一挑战的。比如说一个很重要的挑战，就是说我有十个这个服务器。
39:52假设啊我也是个服务器去做这个服务。那我一个理想情况应该是我这个实物十个服务器，它访问的这个负载应该是差不多，对吧？如果我所有流流量仍然打我虽然开十个服务器，但所有所有流量都打到一个服务器。
40:03那这个事情其实等于你开了十个也没有用。那这种时候呢就会人们就会发现啊，对于某一些请求啊，我是能比较方便的做成电视，这种请求叫做 statulist。什么叫 statlist？
40:15就是说我一个请求啊，它这个执行啊它不依赖于它的这个历史记录。因为大家想想啊，假设我一开始有一台服务器，然后我所有请求都打到这台服务器啊啊这个时候呢，然后然后这个后续的请求可能会依赖于这个当当前的这个执行的这个结果后，
40:30这个时候我突然 skill 到了十台服务器。我当前这个请求能不能去用这个这个这个这个能不能去这个十台呢？如果你是个 state ment 的的，就是说就是说它依赖于状态了，其实不行，为什么？
40:41因为它得依赖于这个它的依赖于这个低地零呃原来的服务器里面的数据。当然你也可以去用一些这个 workkilling 的方法，对吧？你可以把这个状态给扔出来啊，但是这个东西的话就会让你的系统这个变得复杂。所以一般来说对吧？
40:54业界的话，他们为了做很多的这个啊各种业务场景。所以他们希望说，我要如果要做 skill 的话，我的这个请求流量得变成 stateless 啊啊 CS 就说我我个请请求以在任何的的附加值，那么大家就很好奇。
41:08对，那这个时候我如果这个这个这个我如果这个这个这个这个请求原本是个 stateful，比如它依赖于一些状态，比如说像大模型对吧？大模型其实一个很经典的例子，就是我的这个请求可能会依赖于我历史的对话记录，
41:22对吧？那这个时候我怎么去把它在一个 statalist 的这种可扩展的这个 FK inserver 上去做呢？其实方法也有很多，对吧？一种方法就是我们前面说的，我每台机器可以互相的偷这个 context 啊，
41:36其实这种本质上也是一种 designovation 啊，其实大模型 KB 开始 desigvation，就这个意思对吧？还有一种方法就是说我可以把这个状态的信息带到这个请求里面。比如说我可以在用户的这个这个手机端，对吧？
41:47我去记录一下这个对话的历史记录啊，然后再把它给发到这个云端搜索啊。那这种方式的话，我就可以把这个一个 stateless 请求变成一个 stateless 请求啊，去用这样的一个横向扩展的方法啊去做扩展 OK。那这是第一步，
42:02对吧？最好我们是要有一个 stateless 的这个请求比较困难。那大家有没有想过一个问题，假设啊，我这个用户的请求是 stattlist 了。然后呢，
42:10我这个服务器的数量可以根据你这个请求的 rate 动态变化。那么我们能不能保证每台 server 它接收到的流量差不多是一样的？这个问题其实啊没有那么简单，没有那么简单。它在它其实是一个经典的问题，就叫做 load balance。
42:28就是我们其实需要把这个 road 均匀的去分分摊到这个不同的机器上。这里面有很多经典的方法，比如说像这个 random，对吧？随意挑一挑，比如说 round robin 啊，
42:40这个每台 server 按按按按需给。那大家有没有想过这些方法对吧？能不能严格的保证我每台机器接收到的这个流量是一样的呢？比如说我们可以举经典的如 n run lobin，对吧？这个这个大家可能我觉得特别特别简单，
42:56那 run lobin 能保证每台 server 拿着这个流量一样的这个前提是什么？前提是每台 server 这个处理的能力是一样，以及每个请求它处理的时间是一样的。对，不对当，你出的不一样的时候，
43:10其实我比如说有举个例子，一个他可能就会跑很久很久。那么其实这个时候我们应该是吧应该要做调度的时候，做萝卜单的时候，我们不应该把这个这个后续的情求发给那个一个在做很久的题就是这样一个思路上，对吧？
43:24但是王罗比显然没有办法做到这一点没办法做这点啊，这个问题其实在这个大模形象其实也非常非常的严重啊，其实我们最近在和这个这个这个这个这个通艺实验室，对吧？我们就合作了一项目，就我们在干的一件事情就是哎我作为一个云平台，
43:41对吧？我有那么多大模型推理进型，我该怎么去做这个 load balance，对吧？我们发现这里面有很多挑战。第一个挑战就是我们今天说的就模模型退机型，
43:50对吧？虽虽我看上上去有一百 GGP，但是实际在这个工业界的场景，对吧？它有些 GPU，因为搜个过热的关系也好，
43:57或者说是因为它那个出厂的这个这个这个这个质检其实没有办法做完全一样。会有一些同型号的这个 GPU 啊，它的速度就是比另外几张慢很多。那么我们在做调度的时候，其实我们就需要去考虑到一点，对吧？
44:13同时其实我们也看到大模型起球，它跟传统的这个 server 呃这个请求稍微不大一样。就是它一个起球其实要要要做相对来说比较长的这样的一个时间。而且它这个长短其实是依赖于它的这个 context 来源于依赖于你这个你这个 pround t 吧，它难度度底底要要模型型做多少个抵扣的那这个本质上也会影响到你这个调度的这样的一个算法该怎么做的呢？对，
44:37我们看到这个东西并不是这么好做。所以所以我们在扩展到这个利用这个备份也好，利用这个就边配件去扩展性能的时候。其实一个很重要的需要解决的问题就是我们怎么去保证这个每个 server，对吧？它接收到请求应该是差不多，
44:54它流量应该都是啊差不多的啊这样的一个场景。那么当我们解决完这个问题之后， OK 那么这个这个这个这个事儿其实就就差不多解决了，对吧？那具体怎么解决？其实我们就本说不同啊，
45:05特定的这个应用啊，它其实有自己的这个解法，其实并没有一些非常统一的解法。当然在传统的这个排队论里面，它会有很多这个经典的这个算法。大家可以去看一下这个教科书啊，
45:17包括现在其实主流的这种呃这个大模型推理已经开始用的还是一些经典的这个教科书的这样一个方法。 OK 行好。那么假设我们这个应用已经这个 level skill，然然 ddatabase，我们之前是用了这个 oracle 的这种巨型机的方案去持 ill。这个时候厂商在二零零几年的时候呢，
45:41他发现有一个很大的问题，什么问题呢？就是 oracle 这些厂商啊，他这个非常非常黑心啊，比如说在我前面说过， oracle 他给你提供一个非常大的机柜，
45:51对吧？这个机柜啊，它能够帮你满足很大的存储容量的这个需求。那他那个机柜非常贵啊，在二零零二二零一零零几年的时候，那个那个机柜要卖几百万几百万。
46:03然后这个时候呢，一些互联网厂商，像这个 google 对吧？他就发现啊，我其实花个十万块钱，我买一些普通的这个笔记本电脑，
46:12它的这个存储容量加起来啊，其实跟你这个 oracle 一百万的那个大盒子的这个这个储储量是一样的。那我为啥不用这一百个这个便宜的电脑上，我就构建一个自己的这个分布式数据库，帮你我就把这个钱给省下来，对不对？
46:28那这个时候开始的话，互联网厂商就会引进到一个非常重大的趋势。就是我们的这个数据库啊，它要跟完全跟原原原来这种巨型机去解绑啊，我们要自己从头构建一个这里面产生出的这个浪潮，对吧？
46:42就是有一开始有 no cpu 啊，后面有一个这个 google 的这个 spanner，对吧？它说明了一个那个事情，就是我这个 CQ 就 database 啊可以扩展到很几千台这样的一个 common dity server 上。同时我还能保证 ACID 这样的特性。
46:56然后它也催催生出了后面一些大家都能听听过的系统里边像太 DV 一嘛，在里面的事情，它背后都是这样的一个浪潮，下面的这样的一个产物。那么这个事情大家可能会想了一个很想一很矛盾题，就是我们前面说唉我这个事情给 oracle 做，
47:10那为什么我不不自己做呢？因为它本质上的一个原因是我们这节课也会花很多篇幅去讲的一个事情。就是说你要把一个 datatabase 啊 ddatatase ase，你要把它这个这个这个这个扩展到这个很多台机器上，这确定是比较难的，比较难的。
47:26为什么呢？因为你一个 CQ，大家想一个 CQ，它访它访问的不仅仅是一个数据，他要访问很多台机器的这样的一个数据。那如果我在访呃我这当我这个数据啊，
47:36把它分散到很多台机器之后，对吧？我万一我访问一台机器的时候，这个这个这个机器挂了怎么办？我这个 CQ 到底是算执行完，还是算没有执行完呢，
47:45对不对？那这个其实就会有很多叫做一一致性的这个问题。这个问题虽然有很多经典的算法，但是在一个非常大的规模下，对吧？只要不够啊才会明确的告诉别人这个事情啊可以做。
47:59所以我们可以看到的是在这个数据库扩容的这个变成分布式这个过程。摆脱 oracle 的这个过程中啊啊它其实有很多的这种啊这个这个里面需要做很多很多这个这种设计。我们这边这节课也会讲讲其中的这样的呃这样的一部分内容。然后它其实为了为了避免搞这么复杂的，一开始大家也可能会听到过一些很很很愚蠢的图，我觉得不是很愚蠢啊，
48:21就是很很打愚蠢。就比如说我看一个数据库当专门做 read，开个数据库当专门当 right，对吧？它本质原因就是因为其实我们很难把一个物理数据库做一个分库分表啊，分库分表。
48:32但是现在在现在这个问题其实已基本解决了。那解决完结果就是我们的这个集群中啊会有很多的一个存储的这样一个 server 集群。这个集群上面存着这个数据库表中一部分，然后我一个 sq l 会在很多的这个机器上啊去跑。当然除了这个数据库以外对吧？我们的这个文件系统啊，
48:52其实也会以类似的这种啊方式去 scale。所以到这边为止之后，大家就可以看到，为了支撑这个不断膨胀的这种数据请求对吧？以及这个请求的这呃数数数据容量以及这个请求的需求，以及这个请求。
49:07它实际上随时间不停变化的这样一个特性导致的一个结果。就是说我们的这个最终啊像淘宝这个背后它会这个这个这个这个演演进出这样的一个非常啊非常复杂杂这这样一个架构啊。然后它每个请求我们用户的这个点击跟按钮钮不管迅风也好，也是 a 镜头也好，点这个按钮就会发现它会经过这个几十台几几百台思 ver 啊这样一个写作来完成。那么在这样的一个架构下，
49:37我们能不能总结出一些共性的东西。如果要让一个 server 对吧？这个或者让一个服务变得可扩展，它有什么样的一个核心的这个这个这个系统呢？原理呢？其实我们啊我们其实已经把这个原理用用两句话可以给总结出来。
49:55第一个很重要的原理就是我们的这个不同的任务啊，它需要把它分离开来，分离开来啊，比如说我计算的服务器就专门有计算的这个节点去做，然后存储的集群就用存储器来做。因为本质上这是两类任务，
50:13他们的这个扩展需求是不一样啊，是不一样的啊啊，那么我们先休息一会儿，然后那个嗯 ok 都不上来需求的。亲是是的嗯嗯。