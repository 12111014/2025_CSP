00:58嗯是嗯是你可以我真的嗯那个我们啊接着接着接着讲 OK 行上节课。我们其实讲了一个呃很重要的点，就是说为了你去支撑支撑这样的一个作为一个比如说淘宝对吧？你你是一个淘宝的总架构师，对吧？为了支撑淘宝的这种海量流量啊，
05:48海洋数据存储的这个需求，以及需要动态扩展的这样的需求。我们的这个系统啊最终会演变成这样一种非常分布的这样的一个方式。就是说一个请求求需要经过很多个组件啊去经过协调啊，协作啊才能够完成。那么这个其实也是当前所有的这个分布式呃这种可扩展服务的这样的一个背后的这个基石。
06:10他们最后的这个原理其实都可以总结成一个就是把你的这个算啊和存储去做一个这样的一个，或者说你不同的任务类型做一个分离。然后每一个任务类型，它用的这样的一个计算资源啊，可以作为一个这个按需的扩展，根据它的这样的一个需求 OK。
06:29那么有了这样的一个总体的架构之后呢，我们其实上上上节课还说了一个很重要的问点。就是一旦你去做这种分离也好，做 scale 也好，你每扩一点点，它就会遇到一些新的问题。
06:41比如说上节课，我们讲到有这样的一个你你去把存算分离，就会有这个开这个数据访问慢，你就得需要 catch 问题。有 catch 的问题之后呢，你为了 skill 这个 memory 的这个 server，
06:53你就会有这个 data location 的这样的问题。然后你需要 skill computer，你就你就会遇到这个 load balance 的这样的一个问题。那这些问题对于任何系统来说啊，他们都需要啊解决。那么具体怎么解决啊，
07:06可能是会啊这呃不同的这个系统啊，不同的场景，还有自己特定的这样的一个方法。那么在这样的一个整体的架构上，我们其实可以看到现在的服务其实会复杂很多。但是它不管再怎么复杂，
07:20它里面其实都就都是在这样的一个小的整体的这个呃也不是小在这个一个整体的架构上去做修修补补。比如说大家想想看，一旦我们用这个一个那么多几千个组件，对吧？去几几千个组件去协作的服务。一个请求之后会发生什么一个问题，
07:40我一个请求的这个处理的这个时间肯定会比我就在我一台笔记本上，对吧？部署一个服务要长，对不对？那这种时候的话，对用户来说，
07:49它体验会受到什么影响，它的响应时间就会受到这样的一个影响，对不对？那怎么去做减？这要降低这个响应时间开销呢？其实我们说了这方法其实很简单，
08:00就什么就是缓存，对吧？但是有有些时候有些东西是能缓存，有些东西不能缓存。比如说我这个大模型处理，对吧？
08:08我除非你这个状态完全一样啊，对吧？不然的话，你这个没法直接缓存下来，那时候什么东西能缓存呢？比如说你们发现在我们的现在互联网服务中，
08:17对吧？有大量的这种静态的，比如说视频也好，音频也好啊，这些都确定的那我就把它给缓存下来，那是那么我缓存哪里最合适呢？
08:26大家想想啊，我如果缓存在这个数据中心后面，那它不是还是得经过很多的这种组件吗？所以呢那个叫什么互联网厂商，或者说这个呃网络的运营厂商吧。他们就会发现啊，
08:40其实我们自己网络厂商大家如果去了解一下，就发现就是我们用的这种手机的厂商，他们也有也在很多地方都有这种小集群，大概几十台私乐。那这些私乐的话，他们其实可以用来去存储一些常见的数据。
08:53这个时候应运运，而是那个服务就是什么就叫做 CEN，对吧？就把这些静态的数据啊都绑起来。这个其实对于用户的响应时间其实来说非非常非常重。比如说你看这个是上周吧，
09:05上周看了一个很有一次新闻啊，他说为什么 netflix 对吧？总比其他的 netflix 是美美国的一个这个这个这个这个这个流媒体服务商。那视频为什么总比其他网站快三倍呢？因为这个 CDN 的巨头啊，它这个比较偏心啊，
09:21他把更多的这个缓存留给这这个 netflix 的这个视频。因为看的比较多啊，所以它就会会更快。那它其实背后原理其就是拥有个这样的一个缓存 OK。那么有了这样的一个架构项，我们之前说了我们之前的一个这个 application server 对吧？
09:36它的主要的是这样的一个淘宝对吧？那其实我们可以看到的是，当你一个业务，比如说你数字化程度越来越高的时候，我们就会发现这个这个这个你要跑的业务是非常非常那个叫做复杂的。比如说你淘宝对吧？
09:50现在啊淘宝其实背后是阿里的阿里，它不仅现在要跑淘宝，对吧？他还要跑支付宝，然后他现在还要跑很多这种通的这这种服务，对不对？
09:58那这些服务的话，大家想对于每一个服务来说，它其实都应该是用我们之前讲的这样的一套大的架构去 skill，对不对？去 skill。那这时候就会有一个问题，
10:09大家会想我那么多服务，难道我每一个服务我都给它去 build 一个数据中心嘛，对吧？大家想这个时候肯定是这个这个是非常划不来的那怎么办呢？我能不能把数据中心我的这个硬件给抽象成一些虚拟的这个数据中心，然后让这些硬这些这些任务按照虚拟的方式去部署的。
10:29这个时候其实就是大家会听到很多的这个有很有名的一个系统叫什么 k 八 s 对吧？它其实提供的就是这样的一个能力。我在一个大的这样的一个这个物理的数据中心池子上，我把把这个任不不任任务，好好可以让他们独立的的这样去部署。然后我还可以根据不同的业务流量去针对性的去 scale 他的这样的资源。
10:50所以这个时候这个时候我们将发现，当应务复杂的时候，它会有一个这个 KBS 这个东西出现啊，但这个东西出现它并不并不会改变啊，每个用户对吧？他是用我们这样的一个非常的 scale 的这种架构去演进的。
11:03这样的是这样的东西其实从耗是分离的。所以我们也会发现这个这个开发对吧？它会分成这个开发人员，也会分成那个一个有个专门的，现在有个就叫 demo offs，对吧？
11:13比如说我专门有个方呃这个运营团队的去去去去管这个什么应用应用的部署啊，啥的这就比较复杂。这不是我们啊这节课讨论的这样的一个他他他他们也是个很有很重要的这个系统 OK。那么除了那个叫什么，我们有多应用以外，对吧？
11:30还有一个很重要的趋势，就是我们每个应用内部它也在变得更加复杂。大家想想我们之前啊现在的大部分的这种业务，比如说我是淘宝，我相信用大模型对吧？写个前端的呃脚本就能解决了。
11:45但实际上你的这个包括阿里也好，对吧？包括抖音也好，它的核心竞争力其实并不在于它这个前端对不对？而是在于它每一个点击按钮背后它会跑很多这种复杂的算法。比如说去做个性推荐，
11:58对吧？比如说像最近回来 tip tok 对吧？就是跟美国人搞的那么那么僵，也不是这么僵吧，就美国人当然很坏，对吧？
12:06但是说但是他贴透，他想想它的核心是什么？核心是它的那个推荐算法，对不对？那么这些推荐算法本身，它为了什么为了去做这种，
12:14比如千人千面也好，这种推送。那这种代码大家有没有想象过，他可能会去写在你的这样的一个，比如说 PHP 也好，对吧？
12:22算也也好，不不不，这也好，时代的那个啊各种前端的这种什么框架也好，可能会直接写在那些前端的那这个这个这个脚步里嘛啊显然不会对吧？那这些这些业务，
12:32这些计算算法，它本质上背后是意味着说它有一需要跑一些这个大数据处理，对吧？需要跑一些图算法的，需要跑一些大规模的这种机器学习的这种推荐算法。所以呢我们在这个应用层背后又会演进出很多的这种啊计算的这样的一个这个这个不同的 framework。
12:52他们的 framework 本这些 framework 产生的本质，就是希望我们比如说让一些 AI 的应用，对吧？也很方便的去去让开发人去写出来啊，然后去跑，而不用去考虑这种很复杂的这样部署的这样的一个事情啊，
13:07然后这样就会导致一个结果就是我们啊应用会架构图更稍微再复杂一点，就是说我们每一个不同的应用对吧？它背后其实还会对接到一个这个这个相的这个 frame 口，比如说像那个 chat boot 对吧？ chat boot。它背后其实是会对对接一个像 VRM 啊这种啊推引擎啊，
13:26推引擎啊，那这个这个比较像这个像这个这个支付宝，对吧？它背后就会接一个图的分布式图理图引引擎，对吧？去做一些欺诈检测。
13:36像这个淘宝对吧？它就背后就会接一些大数据处理，做一些这个简单的这样个这样的一个推荐 OK。所以当所有的这些都给拼凑起来之后呢，我们其实就会引出啊我们这节课下一个要去给大家介绍的这样一个系统的大类组织叫做分布式系统。那什什么是分布式系统呢？
13:55对吧？一个一句话啊总结啊，就是说这个系统是有很多的这样的一个计算组件参与去完成计算。但是对于用户来说，他看到的并他并没有看到这个几千个这样的一个这样的一个组件啊，它其到就是一个完整的服务，
14:14对吧？大家可以想想看，我们说的淘整的服务对吧？那个为呃叉 GBT 也好，对吧？它其实非常符合这样的一个定义，
14:21对吧？我们看到的就是一个前端界面，然后我们跟一个服务在交互。但是它背后到底是其实有几台服务器器，在呃 g 千 MP 也几百台服务器去协作，完成你的这样一个请求。
14:33这样一件事儿。这个事情本身我们实际上是不知道的那这个就是啊我们系统里里所定义的的这样的呃一个一个很经典的啊，当然只是很经典的一种这个分布式系统的这个定义的方法 OK。那么我们现在知道了，对吧？我们假设我们需要去 build 这样的一个这个很 scalable 的这样的一个互联网服务。
14:54大喜雄为我们需要一个分布系统。那么我们到底该怎么去 build 一个分布系统呢？这其实我们会发现一个点就是你不同的应用，对吧？你 build 的一个分布式推理系统，那你 build 一个分布式数据库对吧？
15:06它里面用到的这个技术点肯定是非常差的非常多的。但是呢我们想说的一点是说，在这些不同的应用里面，它作为分布式系统，它会有一些共性的这样一个要解决的这样一个问题。这些问题啊，
15:20几乎所有的分布系统都不一到。所以我们这节课接下来会给啊大家介绍一下这个这样一些共性的这样的一些问题啊问题。那么在介绍这个固定问题之前呢，我们先得看一下，对吧？就是说现在的这种这个这个这个分布式，
15:36对吧？它到底啊我我指的这个风式是一般偏啊，互联网公司在讲啊，大大家手机这种无人机对吧？也算是一个分布系统，这个我不考虑在内啊，
15:46他们背后是怎么运行的呢？他们其实现在的这种啊互联网厂商，他们都会自建一个很大的这个数据中心啊， host 这样的一个大的分布式系统啊，这是因为啊这个数据中心是大概率得这么构建。所以它的很多问题其实也是来自于这个呃构建的时候啊产生的这样一个问题。
16:06 OK。比如说我们可以先来看一下，对吧？就是说一个现在的这样一个数据中心，对吧？它的其实其实嗯说它的核心东西什么呢？
16:15核心东西无非就是我把几千台、几万台这样一个 server，把它放在一个很大的这样一个厂房里面，对吧？去给它提供供能供电，然后把这个东西弄好，
16:25对吧？这这个这个实际上是一个非常直观，非常非常显显然的这样的据据。当然现在数据中的规模可能是得得排仓，你这个当地的这个供电对吧？以及这个这个这个冷却的这样的一一个开销。
16:38那么大家有没有想过我把这么多机器对吧？垒到一个这个这个这个这个这个大的这个地域里面，它有什么样的问题呢？它有一个很重要的这样的一个问题是什么呢？是我我们前面讲是吧？我们前面讲那个一个计算服务，
16:55它需要交互。那么交互意味着什么？意味着是我说我服务器之间需要通信，对吧？那大家想想我我一我一个比如一个教室对吧？我可以连个 wifi 几百台，
17:05这个笔记本可以可以通过 wifi 连大家没想过我比如说我一台数据中心对吧？我有一万个这样的一个这个这个一台机器，我能不能用 wifi 去给他们连起来了，显然不行，对吧？我需要一个非常靠非常就是稳定的高效的这样一个互联的这样一个机制。
17:21但是我们想想看，我们会我们要高效稳定的互联，我们怎么办？我们得连线对吧？连线，那大家想想我一个服务器，
17:28它能连多少根线对吧？它其实要连的线的这个数量其实是非常有限的，它其实只有几个而已。一般现在一个网卡大概也就最多双端口，两个两个插口出去，对吧？
17:40所以像那个现在的这样的一个这个这个数据中心，它实际上是采用一种这个 high erary，就是呃层级的这种方式啊去构建它的网络。比如说最简单的就是最小的一个单元，肯定是一个服务器。然后比如说每十台或者每二十台服务器，
17:56当然这个如果是你是 GPU 服务器可能会少一点，它会构成一个机柜啊，一个机柜其实就是这样一个柜柜子啊，里面每一排插的都是服务器。那这个机柜顶上呢有个叫做 pop ranck 的这个交换机啊，就是说我每个机器都连到这个这个一个 rock 交换机上。
18:14那它能保证说我一个 rock 内啊，所有的机器它的都是能互相连通，还是它的网速是一样的。那么我一个数据中心它就会有很多的这样的一个这个机柜。那么这些机柜怎么连呢？那其实就会有一些这个数据中心的这个交换机啊，
18:29交换机，然后会把这个连，然后它这个连了多少啊，就取决但但然你机机和机机柜之间，对吧？你网网速底底通信多少取？
18:38取决我需要连多少根线啊。一般来说说一个像我们买的这种 top rock 交换机好一点的话，大概这就是三十到四十个这样的一个端口啊。四四十三到四十万的端口，然后这个机器其实非常非常贵，非常非常贵。
18:52我们当时我们不好意思丢的时代的话，我们一台这个这个这个一一根板子啊，不一根一个这个这个服务器啊，大概价格也就是一万块吧，还是两万块。但是你要买一个这个两百个 g 的这样的一个全对等的这样的一个交换机的话，
19:06大概是要这个四十万到五十万这一台，然后你还要买对应的这样的一个数动性交换机。当然如果小机芯不小啊，会这样刷刷刷一点啊，被这样一种 herarchy 的这个方式啊，把这个服务器迭代。
19:20那么这个海拉的方式会带来什么问题呢？它会带来两呃其实带来的一个核心问题。就是第一，我一个机器机器之间的通信啊，它可能会经过很多条交换机 OK。如果你的交换机出现了一些故障啊，
19:34就会好带来很多这个网络网络上的这个问题。我们那会讨论几个比较经典啊。然后第二个就是你假设网络是网络连接啊，我前面指的问题是网络连接问题啊，就是两个两个机器规法互障通信。那第二个问题就是你你如果这个这个机器，
19:50我们发现它的不同的机器之间，它走的这个交换机的数量它是不一样。也就意味着说它很有可能说理得成就是我一个 rap 类的交换机啊，这个机器啊它们互联的速度很快，对吧？但是跨交换机肯定会有速度变慢。
20:05那这样一个问题，那么从算法上我们怎么去考虑到这样一个特性，做一些设计，比如说你训练对吧？你不可能说我这个这个不可能，就你就没不一定能总是能假设所有网络都是都是一样的，
20:18对吧？那这个就是系统这个需要解决的一些问题，所以它就都是由这样的一些架构而造成。对，那么当然呃，除了这个这个除了这个这个这个一个数据中心内，
20:30对吧？其实厂商的话啊，它还会在地域跨地域会构建很多个数据中心。比如说像这个有时候它上海有个数据中心，在北京有个数据中心啊，为什么要建这个数据中这些数据中心呢？
20:42它主要是有两个原因。第一个原因就是说我为了服务的性能更加的快，什么意思呢？大家想想，如果我假设我们美国有个数据中心对吧？然后中国有一个数据中心，
20:54那么我如果在中国的话，我肯定得连中国的数据中心，对吧？因为你连美国的数据中心的话，它的一个网络延迟大抵就是几百毫秒啊，这个其实是没有办法减少的。
21:02因为你你你的信息的传递速度对吧？不能超过光速，所以我最好是连一个本地的这样的出球心，它会比较这个考角。那么第二个目目标目的就是说为了容错对吧？万一我真的这个很不巧，
21:15对吧？这个美国这边发生地震了，对吧？我是我这个美国内控怎么办呢？我只能连中国直输中国值。好，
21:22那么这种地域的架构的分布，它虽然这个提供了两个比较好的特性，对吧？一个响应时间比较短，一个是这个这个这个容呃那个容错比较好。那大家有没有想过它带来的一个问题，
21:34就是我如果数据中心和数据中心之间要做同步怎么办？比如说我有个数据同时存在了两个数据据心的对对吧？他们的这个同中性实实际上是比这个单个数据中心内的这个同步是要慢非常非常多的那我到底该怎么怎么去处理，对吧？以及我这个两个数据中心，它的网络的这个连接其实不像一个数据中心那么可怕。
21:53因为一个数据中心在数据中心内，我们大家可以看到，就是它有很多的这个交换机做冗余啊，做冗余，它的这个网不大会断。但是我跨数据中心的话，
22:02网还是很断很容易断 OK 行。那么这个就是由我们现在的这样一个也不算特别底层，对吧？但是我们已经有一个比较 high level 的这个数据中心的这样的一个架构。那么这个架构啊，它其实会引入很多的这样的一个系统的这样的一个问题。
22:20可能第一个也就所有的分工系统都要解决的一个问题。就是啊我怎么去容错？因为在这个分工系统里面的这个 fault 是非常多的啊， faut 是非常多的。那么什么是 faut 呢？ fault 它其实就是说我的这个一个组件对吧？
22:36它可能出现了某些问题。比如说在我们这个做大部模型系统里面有个非常经典的问题。就是我这个内存会那个比特翻转，就我一个内存原本刷的是零， GGPU 存的是零。它它突然过了一段时间就变成了变成了一啊，
22:52它就会出现这样的一个这种这种 faut 啊，它原因也是因为这个呃这个 GPU 对吧？算的太快了，它这个 GDM 刷新太快了，它可能会有一些这个稳定。好，
23:02那么有了 fault 之后，我们怎么解决呢？那大家一定要想想的一个问题，就是我的一个系统里面，对吧？不管是软件也好，
23:10硬件也好，它出现了 fault，一定意味着我这个系统就不可用了嘛。大家想啊其实不一定是这样的一个事情。因为什么我只需要把这个 fault 给处理好，其实就就就能够能够能够能够能够屏蔽掉一些问题。
23:25比如说我我拿我前面的例子来说一下，我们这边说比特会翻转。那翻转的话，其实我这个是现象的一些条件，高端的这种 GPU 上，对吧？
23:35它都会有这个叫 ECC 的这种检测机制，对吧？它能够 detect 一啊，企业取决于配置，对吧？它有些是能 detect 到几个变 it 的翻转，
23:43然后修复一个变成的翻转，有些是能够 dedetect 到几个 bit 反转。那么当你出现 fault 的时候，很多时候你的这个硬件或者软件，它会爆出一个叫什么 error，就是说我会有一个这个错误不传传达给用户。
23:56那么其实对于我们一个分布系统来说，我们只需要什么把这个 error 给处理好。其实对用户来说，我这分布仍然是能够 work，对吧？比如说比如说这个这个这个这个这个呃那个比如说我发现了一个翻转，
24:11对吧？那么在我比如说在模型训练里面，如果发现一个翻转，那大家想一般会怎么做？他这个做法很简单，就是我把当前的这个训练给丢掉，
24:19对吧？我去把它退回到一个正确的这个没有翻翻转的这个状态，再重新做一遍训练就行。那么这这样的话站在一个算法工程视角来说，你这个训练其实没有挂，对不对？
24:29那么直到什么？直到说比如说我这个代码写了个 bug，我的这个 error handle in 有 bug 啊，导致了这个这个修复不了了。那么我们对于最终用户来说，才可能会产生一个这个非裂的这样的一个状态。
24:42所以我们的目标是什么呢？我们的目标其实是避免非脸，而不是什么，而不是避免 fault。因为 fault 你其实是很很很难去避免，很难区别的。
24:53为什么这么说呢？为什么这么说呢？首先我们先来看一个事情，就是说大家应该应该能想象得到，对吧？我如果要 build 一个任何东西，
25:02对吧？你要说完全不出错，不出错，那个叫那是不大可能的对吧？那么举个在我们这个数据中心场景的话，那么我们的一个假设是我们每一台服务器对吧？
25:13每台服务器很可靠很可靠，比如说三十年才挂一次，这个假设已经很极端了，对吧？很极端了。但是大家想想，
25:21为什么我们前面说分布系统里面的 fault，它比你传统的这个系统会更多呢？因为啊给我们的这个分布系统，它并不是由一台这样一个三十年不会挂的这个机器组成的。它其实是由什么？它其实是由我们先说的几万台这样的一个机器组成的。
25:37那么有了有了这个情况下，这个机器之后，我们就可以做一个非常简单的这个计算，对吧？计算。比如说假设我有一台机器，
25:46这个是不过我算的啊，就是我有台有有个有 claster，有一万台机器，每台机器它一万呃三十年才会挂一次。但是我从但是我把这个一万台机组组在一台机机，一一个一个 class 中，
26:00其实就会不过就会发现它每天都有都会有机器化，都有机器化。所以这是分割系统的一个非常大的这样一个特征。尤其当你的 skill 做上去的时候，其实你的这个发生故障这个频率也会也会上升。这个不这跟你每个组件啊做的非常非常高效，
26:18其实没有关系的。而在事实过程中呢， google 还发现啊，其实这个这个这个很多的 fault 啊并并并不是那么那么低概率如说三十年才发生一次有些很很常见的事情。比如说 google 这边做了分类啊，这本书非常好，
26:34大家可以推荐，就是我推荐给大家，可以看一下，叫 data sencenter as a computer 啊，这是 google 对于他们运营了几年的数据中心做了一个总结。他里面就发现说哎，
26:44我的这个数据中心里发生的 fault 对吧？有很多，比如说是来自于人为的啊，我们也可以看到一些例子对吧？比如说这个微信对吧？施工把这个电缆铲断，
26:55比如说这个字节对吧，程序员字节字节刚开始的这个权限管理做的很很很简单啊，或者或者他们很信任，导致这个实际上可以相除跑路，对吧？字字节装置发发生过很多次，
27:05对吧？然后还有这个断电对吧？很多事情都都都有。然吧。然后当时还统计了一下统统计发现什么呢？就是说在所有的这个 false 里面啊，
27:16其实硬件比如说网络也好啊，这个硬件 CPU 或者 GPU 故障也好，相对来说是比较少的。但是这个人为的这个造成的这个 fault，其实还是还是非常多的，还是非常多的啊，
27:29当然这是二零一零年的结果啊，不知道现在比如说对吧？现在很多时候是不是我们现在很多很多人在研究，对吧？我们能不能用大模型去替代人人类？对，
27:38那么能不能生号把这个这个人人的这这 fault 给干掉，但是你即使干掉了这个人为的这种 fault，对吧？你这个还有百分之十几的这种硬件的这种故障，其实是很难干掉的。而且当时他这个统计是在 CPU 上的，
27:51以及现在 CPU 的话，因为它算的太快了啊，它这个能能耗什么都会有比较大的压力啊，其实这个这个它的故障和 CPU 的性也不大一样。 OK。所以总结来看的话，
28:03我们就可以看到的一点就是不管处于 scale 也好，也出于这样的一个各种各样因素叠加也好啊，我们在这个数据中心内啊，数据中心内啊，它这个 fault 实际上是会是会非非非常常非常常见的。那么这个对于我们设计一个分布式系统有什么样的要求呢？
28:21它的要求就是我们要在能够 partial 这个飞裂的情况下，由 falth 产生这种 partial 飞列的情况下，仍然能够用。什么意思呢？大家想想，我们如果是跑一个系统，
28:34一个 APP，对吧？就是在一台笔记本上跑，那么如果我这个笔记本挂了，那我就只能重启。我这个应用肯定是全挂了，
28:41对吧？我肯定不能用了。但大家想想，我们前面说的这个分布式系统，它跟单机的这个笔记本系统有什么不一样，它是跑在几千台机器上的。
28:50然后这几千台机器里面，它可能有一百台机器，因为 fault 挂了。那大家想想，我们这个时候能不能比如说这个几千台机器全认为这个任务挂了重启呢？那像其实这个东西是很没必要的，
29:02对不对？我一个一个组件里面百分之十的组件挂了，我为什么要让它这个百所有的组件全都重启呢？这就是带来一个这个很重要的就是我们要能够在 partial for t 这种情况下啊，能够能够正常的这样的一个工作工作。那么这个事情好不好做呢？
29:21好不好做呢？那么其实这个其实就是跟我们这个分布系统，它构建啊，跟传统的这个 debug 稍微有点不同大。像以前我们比如说 debug 的，我们是说我们发现了哪里报错，
29:33我们去找到这个报错的原因在哪里，然后我们去把它修复，对不对？但这个方法在分布式系统下，当然肯定你 bug 是要低。但是你去容错跟 debug 稍微有点不一样，
29:44因为在分布式系统里面你有时候很难去区分，对吧？一个东西它到底是不是 fault？还是说是因为一些其他的网络原因，还是说因为它跑的特别慢啊，跑跑特别慢。
29:57我们可以来举一个这个例子啊，举一个例子。比如说大家想想我们比如说手机上对吧？我们用淘宝 OK 淘宝，有时候我们会发现它会告诉你一个很很罕见，对吧？
30:09但是有时候也会有告诉你一个这个网络竟然崩溃的这样的一个问题啊，这样一个问题。那么当出现这个问题之后，大家可以我会问大家一个问题，大家可能想想说这个问题造成的原因是什么呢？这个原因是什么？
30:24其实我们会发现造成这个问题的原因是非常多的。但是站在我一个端到端的这个系统角度来说，我其实没有办法去判断到底哪一个哪一个问题。打个 ford 造成了这样的一个这个最终的非典。我可以来举一个这个例子对吧？比如说我们就拿刚刚那个淘宝为例，
30:48对吧？淘宝它显示的什么？显示说哎我这个网络竟然崩溃了。那么什么叫做网络竟然崩溃了？他无非就是我的一个用户站在这个手机上面，我发了一个请求。
30:58好，这个请求我没有，我在一个，比如说一分钟内没有呃有一分钟很长，在两秒钟内对我没有收到淘宝的这个回复。那我觉得为这个网络竟然崩溃了。
31:07对，那么这个崩溃的这个是本身，它从这高层次抽象来看，就是我发了一个消息，它没有得到回复，对不对？
31:16那么在背后这个发的消息没有回复，它有多少种可能会造成呢？其实我们会发现它有六种，至少六种可能啊会去造成他这个这个抢场景出现。比如说第一最简单的对吧？我的这个网我发送这个消息丢包了，
31:30对吧？那这个网络挂了，那显然这个这个这个这个这个这个我这个这个就飞裂了。那么这种时候我其实做一个 retry 可能就能就能解决这个问题。但是除了我这个发消息挂了怎么办？还有一个还有一个情况，
31:44是我的这个 server 也挂了，对吧？我淘宝后端的这个，比如我收到我这个请求的 FPK server，他挂了，是不是？
31:52我也说也也也也说不到这个消息，那这时候我要怎么做啊？我在在淘宝层面来说，我需要去紧急的修复这个服务器，并且去部署一些冗余的这个服务器，对吧？
32:00那么但是这这两种其实站在我一个端到端的系统角度来说，我其实分辨不出来的，对不对？好，第三种情况。第三种情况，
32:08我 server 没有挂网络，也没有丢。我有没有可能这个这个用户仍然达到一个网络崩溃，或者说没响应的这样一个请求，极其有可能，对吧？
32:17但实际上我们前面举例例子，比如说我一个一个淘宝这个服务器，它每秒能做十个请求。好，这个突然我我我比如说调负载均衡的算法出问题了，我给他他发了一千个请求，
32:29然后我正好不巧，我发的那个请求就是一千个。大家想这个时候这个会有什么问题啊？就是这个服务器，它没有办法在两秒内去把这个消息做回来，对吧？
32:37因为你做做做回来，你又你不它就不可能的输出，就是这个。那这种情况下的话，它也可能会造成我们这样的一个这样的一个这个服务响应的这样的一个问题。当然其实还有很多。
32:48那么假设我网络也没挂，服务器也没挂，然后它也没有堆积。我有没有可能造成这个服务仍然是仍然没有按时返回呢？其实有可能因为它有个现在的，比如说很多的这种淘宝的这种服务，
33:01对吧？它最早早期都是用这个一个语言叫 java 写的啊， java 写的啊，现在也是有可能会拍照。这些语言有什么很重要的特点？它有个很重要特点叫做 garbage collection，
33:11就是它会定期把这个应用给停下来啊，去把这个用的内存这个这个回收掉。这个过程它有时候会触发取决你用的内存情况，它可能会触发在大概几百毫秒到几秒钟这样的情。然后当我运气非常好，对吧？
33:26我发了一个请求，正好正好我这个 server 正好在做这个 garbage colacction。好，这这个候候家想想想我这个也能得到一个啊不不无法享应这个系统。这个事情其实现在都都有出现啊。我前前几天还还上过，
33:41他跟一个同学聊天的时候，就聊到他说他在跑一个大模型，这个推理引擎叫 VIM。然后 VIM 大家不是，他是用拍丧写的嘛，对吧？
33:49因为现在 VI 的人很喜欢拍照啊，他就发告诉我一个现象，是说这个这个拍葬啊，他他发现有时候他吐词正常来说吐词是每隔十毫秒啊，就能吐一个字。那有时候他发现了一个词，
34:02吐了四百毫秒，到最后他看了看，发现什么？就是因为那时候拍照发现发生了一个这个这个 w ge lelection。因为你这个这个这个 GPU 的计算，其实都还是由 CCPU 这边的这个这个这个拍上去驱动的。
34:15所以你一旦 CPU 停下啊，你这个吐字流漫啊，这个东西虽然很罕见啊，很罕见，对吧？但它确实确实会存在。
34:23那这个时候其实对我们来说一个很重要的一个 take with 什么呢？就是对对于一个分布式系统，其实你你你很难分辨你某一个节点，它到底是挂了，对吧？它到底是挂了，
34:36还是说它做的很慢？那做的很慢的原因可能是因为它发生一次降频。还有一种原因是可能是我有很多请求堆积。还有一种可能，其实甚至还有一些很奇怪的，可能比如说我这个服务器过热了啊，
34:48我们其实在真实的测试中也遇到，我觉得一旦一个服务器过热了之后啊，这个服务器会变得特别差。为什么？因为它降降频频降频，所导致这个计算变慢 OK。
34:58所以对所以这个这个事情，当然我们除了前面讲了那么多问对吧，其实还有这个这个这个你你你你这些 feedback 的这个数据包，对吧？也可能会丢失。所以我们就会发现一个很很很分布式，
35:12有一个很要的特质，就是说哎有时候你你会发生这些 fault，然后我们想通过 detect fault 的 root cose 是啥，然后再去再去这个修复。这个事情其实很难。因为我我我不知道有很多 root cost 都有可能导致我观测到的这样的一个请求，
35:27不可响应的这样的现象。所以我的这样一个协议，包括我们我们之后会讲的一些像 russ 这样的协议，对吧？它也假设说我在不知道这个 server 挂了这个的原因的情况下来，保证我这个系统能够正常的工作。
35:41这个其实在分布式里面很多做容错需要啊考虑的这样的一个事情 OK。好，那么其实网络啊这个东西啊，其实涉及到网络一些大规模网络这个这个里面打的坑还是非常多的。这些问题可能啊当然在学校里不一定有有有有有机会能够接触到。但是在工业界的话，
36:00其实这些事情是经常发生的。比如说在工业界里面，其实除了我们网络连接不上，对吧？连接不上，可能是一个还是一个非常简单这个明确的这样一个指示。
36:12那在工业界里面很有可能一个会出现的一个事情，就是说我网络不是连不上，而是不同机器它们之间构成了这样一个小团体。就是说比如说我我一百台机器呢，五十台机器互相能够通信信，那五十台机器互相的通信。
36:25那这十台机器之间啊没有办法通信。那一旦发生了这种情况呢，就会出现个问题，就是我们很难去做决定啊啊大家想想我我总不能。而我五十台机器一个组做一个决定，另外二五十个人做一个决定。
36:37那这个决定可能会打架，对不对？那大家想一下这个排排序为什么会发生？为什么出现这样的一个情况呢？一个原因是因为啊这个我们的这个机器啊是因为是由这个交换机相连的。然后交换机它有时候会丢包，
36:51有时候会这个过热重启啊会出现故障。有时候会因为升级啊，各种各样的原因，有时候可能会都都都会出现啊这样一个情况。那么当我们的的这个交换出出现障障之后啊，其实在我们这样一个 hierarchical 连接的这样的一个数据中心网络里面，
37:07其实会出现啊机器存组的这样一个现象。比如说在我们的这样的一个这个 case 里面，对吧？我们其实可以看到，比如说当我们我们这个 case 跟我们前面讲的这个数据中心，其一样样就是每每个 port 就代表的是一 rack。
37:20然后每个 rack 它会有一些交换机。当然我们这边画了多个交换机，因为它已经是有了一些冗余的交换机去避免这个全部交换机挂了。然后每个这个 top of rap 交换机呢，它会连连到这个这个顶层的这样的一个这个一些 caster 交换机去做互联。我们看到在这样的一个架构下面，
37:39只要我挂了三台交换机啊，就会出现我这个炮零的这个机器，对吧？能互相连接。然后胖的一二三的机器其实就没有办法没有办法互联的这样的一个场景出现。那么这个时候其实你对于系统的这种 coaliination，
37:55其实就协调就会有很大的这样的一个挑战。那我们在后面会讲一些例子， OK，当然其实你你跨数据中心对吧，其实也也会出现一些呃这个意想不到的对吧？比如说你跨大洲的话，
38:07你的数据中心的这个互联其实会比这个一个数，一个数据中心内要要要差很多。因为一个数据内我可以部署很多中冗余的消换机。但是你如果是跨数据中心的话，那可能尤其是跨大洲对吧？它可能就是依赖那几根这个海底光缆。
38:22那如果这海底光缆断了怎么办？你要么就是重新绕绕一遍地球，那非常非常慢。你要么就是就属于于白的这样的一种，就就这种情况。所以啊正是因为有了这么多啊这么多就是不稳定网络也好，
38:40这个服务器的扩载也好，也就是因为 g 然后因为因为 sandability 导致了这个出错的概率啊变大，任何教育事情堆加在一起啊，我们就会发现就人们就可能就会用一些另外的这种方式去定义一个这个分布系统。什么意思啊？它这个是这个 lesy lamp 的这个啊分讲得主，
39:00对吧？在这个数据成存储一致性，基本上就是奠基人，对吧？他说了一句话，就是你什么时候，
39:07你你你你什么时候知道你自己啊在 build 的一个这个分布系统呢？就当你发现有有一台机器啊，你从来没听说过是吧？它导致了你你当前的那个系统不能 work 啊。那那你就发现你在搞一个这个分布式系统，当然这个这个至于你，
39:25你发现了之后，对吧？其实还是能解决有些经典的这种啊这种方法。比如说在图形讲的这个表彰里面，对吧？讲了就讲兰破的贡献，
39:33包括这个 consciety，对吧？包括这个呃逻辑 acrown，逻辑中对吧？包括这个资资本性引器，都是啊解决这样的一个这个方法。
39:45所以在有了这样的一个分布系统，它我们会发现你分布系统需要解决的第一个，或者说也是很重要的。这个问题就是它解决能不能用的。这样一个问题是在于我们的分布系统必须得解决容错 for talents。我们必须得给用户提供一个这个一直在线的这样的一个场景。
40:04因为出错实在是啊，在实际过程中是太频繁了啊，太频繁了。那么要做到这个事情呢，是肯定是有很多技术点和 principle 是能够做到。但是你要完全做的非常优雅啊，
40:16实际上是非常难的啊非常难的。后面几页 PPT 呢是就是我我这边对吧？从每年啊每年我们这个都会加两页，加两页，就是在每一年中观测到的这个现有的这种服务厂商去挂的情况。比方说最早对吧？
40:30二三年的时候，我记得就是对吧，一站在春节的时候就挂了吧，就不用了，来访问不了。然后比如说去年对吧，
40:39去年的时候那个九月份有一个新闻，就是阿里的这这个是去年还是今年啊，我可能忘了他说阿里的一个数据中心着火了，着火了，导致用这个数据中心的这个服务器全都用不了。那大家想这个其实说明什么？
40:53说明他的这个服务只部署在了一个数据中心，没有用我们的这个多数据中心这个冗余的这样一个机制去做对吧。然后包括像他在今今年对吧今年的这个 descick 吧，这这个 desigic 其实并不是啊并不是在于这个这个说 dedesik 它这个它模型很强，它的系统也很强。但是它其实没有考虑到有那么多的这个流量，
41:15对吧？导致的结果就是他部署的这个 app p in server 的这个数量，其实是远低于这个用户的这个需求的那就导致了什么结果啊，结果就是这个这个服务器繁忙对吧？说明它没有预料到这样需要做这个传的四有零。那这个本身其实也会导致你的这个服务属于不可符合用的的啊，
41:32当但现现在好很多，现在所有所有的云厂商似乎都会啊提供这个 DPCC 服务，算力应该是够的。包括这个这个训练对吧？训练的话就是模型训练。当你这个这个这个模型大到一定规模的时候，
41:47它的这个 GP 的故障是非常常的的对吧？当时 GBT 四出来的时候，其实它有一个新闻新闻，说什么呢？一个推特的爆料，还是说这个 GBT 四对吧，
41:58在这个两万张一百上对吧？训文一百天啊，但是它的实际算力利用率是百分之三十到三十六，什么意思？就就是说这 a 一百它只有百分之三十的时间是在做真正有用的这个计算啊，剩下的时间都是浪费掉。
42:12那为什么浪费掉呢？它其实说的原因原因就是因为这个故障太频繁了啊，其实基本上呃之前 facebook 和 report 啊，就是说你现在这种 AI 集群，它的这个这个这个比如到到千卡万卡级别的话，基本上每小时都会有卡啊，
42:29会会会会会会宕机啊，每每小时会有卡，所以你相当于每小时都得去做一次这种好好二字啊。那这个的话如果你当时做的不是特别好，对吧？那其实就会有很多的危害。
42:39当然现在的话其实大户型的容错会比那个传统的数据库容错要简单很多啊，相对来说简单很多。所以其实现在的话做的相对来说还可以，但这个肯定是还有啊更多很多的这个优化空间呢 OK 行。所以所以我们前面介绍对吧？就是说啊这个这个你作为一个分控系统 OK，
42:58我们要提供一个啊一直在线的这样的一个这个 abstrption 啊，其实是相对来说是是是是是很有挑战的。但是呃在现在这个节点，二零二五年的话，我觉得呃我觉得能实现这些呃不出不出错的这样的一个技术啊，其实基本上都是存在的啊，
43:16我们其实可以可以举几个例子，对吧？我们可以看到像不管是我们平时用的微信也好，淘宝也好，对吧？基本上它是不会挂哦模型。
43:25对吧它虽然这个每小时都有卡挂，对吧？就最终其实不同场量还是能够很快的去迭代啊自己的这样模型。因为它背后的这个系统啊，它一一一定是在一直在这个演进的 OK。好，
43:39那么我们接下来就会介绍几个这个这个这个这个怎么怎么去做容错的这样的一些基本的这样的一个原则啊原则。那么介绍容错之前呢，我们先得定义一下什么叫做不出错，为什么呢？大家想想，就我们前面讲了，
43:55你这个分布系统对吧，它总归有机器会挂，对吧？那这台机器挂了的话，它如果物理上就是挂了，反正它物理上挂的机器，
44:03它可能一个小时内都不可能去在线。那么我们这个服务一定会有一段时间，对吧？受到这个影响，那么我们怎么定义你这些影响对用户重不重要呢？比如如果用户我一秒钟的一一一微秒，
44:17一大秒的这个出错都不能容忍。大家想这个是肯定是你没有办法去提供这样的一个一个不不出错的概念，对不对？那实际过程中呢，其实用户也不会那么离谱，对吧？
44:27大家想实际过程中，用户对于这个服务的需求的是么？只需要你在一定的时间内给给反馈就可以是吧？这个叫做 service level level agreement 就是说你就服务在在多少时间内，比如说一秒钟啊，剩下的服务大概都是一百一秒钟或者几百毫秒能给给反馈就行了。
44:46那这个意味着什么呢？意味着说当你的一个系统出错的时候， OK 我的这个系统只要能在你的这个 service 材料去响响应。那么这个时候我其实就可以认为这个错误误用户来说是不可见的。所以我们分布式系统的高可用，实际上是你这样的一个这个你能在多少时间内响应应这样的一个指标来去定义可用性的。
45:11而不是说定义就是说我这个这个啊对，是这样的。因为大家想一想，我们如果这个多少时间可用，我们定义非常宽泛，对吧？
45:18我们定义说一小时内你能返回出来返回结果我也有可能。那这个事情其实就没有什么这样的一个这个这个这个挑战，对吧？那么我们怎么去那么有了这样的一个出错的 vidiility 的这个定义啊，之后，我们其实就可以去很明确的知道我们的系统需要做什么什么意思呢？
45:38就是我们系统不可用的时间，就是我们去发现这个飞裂之后，对吧？到发现有有飞裂之后，我们能把这个分裂给 repair 的这样的时间。比如说我如果有台机器，
45:49我发现它淘宝，我发现我的服务是两秒。然后我在一秒钟的时候，我发现这个服务器不可用了，那我能不能发另外一个请求，对吧？
45:56那一台可用的这个服务器啊，就就就就就那个服务器，然后在一秒内返回，对吧？那这个时候其实我就认为是可用，所以本质上来说，
46:05我们就需要尽可能的去 repair 这样的一个分裂。那怎么 repaay 呢？那我后后后面讲是怎样 repair 方法。对，然后那么说到这里的话，其实大家就可以看到，
46:14就是说呃我再解释一下一个事情，就是我们大家可能会看到，对吧？厂商就会以这个几个九来定义这个这个这个这个 service。 lover agreement 什么意思呢？就是你看就常比如说三个酒就意味着什么，
46:27就是说我一年会宕机，八小时就是八小时的时间，这个图可能是不可用的啊，五个九就是这个这个五分钟，对吧？然后七个酒就是三秒钟 OK，
46:37它这个定义的本身本身就是其实也是来自于我们这样一个 lalalated 的这样一个定义。好，那么有了这样的一个定义之后，对吧？那我们接下来要考虑这个问题，就是我们怎么去做这个冗余，
46:53对吧？那个要不不么么去做容错，对吧？那我其实剧透了吧，其实所有的解决这个飞利 forfortonance 的方法就只有一个就是冗余。这个冗余可以分成空间上的冗余和这个时间上的冗余。
47:07但那这两种其实是一般的来说，是这个这个这个互相互相用在一起的。那么第一个是空间上的冗余，空间上冗余什么意思呢？其实很简单，就是如果我有一个服务它会挂，
47:20比如说我部署在在这样一个文件文件系统，我把一个文件存在的服务箱会挂，那我就在空间上把它复制两份，复制三份，复制四份都可以啊，复制越多，
47:30反正成本越高，但是容错越高，对吧？那么这样我如果空间上有一个服务挂了 OK，然后我就去这个把它给导到另一个这个服务就结束了。好听上去很简，
47:43对不对？大家觉得哎我做个备份，那肯定是能容错啊。那么我们说做系统来说，你解决一个问题的同时，一般会引入另一个问题。
47:51那么做冗余的话，它的最大的问题就就是叫做一致性。这个东西其实是包括数据库也好，对吧？几十年来人们研究的这个啊最最难的一些问题，其实都来自于这个一致性。
48:03什么叫一致性呢？就是大家想想，我们把一个文件从物理上给它做了三个空间上，做了三四这个备份。但是再到我们的服务角度来说，我们肯定是期望什么期望的，
48:14是一一个文件，对吧？我应该只访问的是一个文件，我我逻辑上空间上这个就应该是只有一份文件。但是一旦我们备份之后，就会出现我们可能访问的这个文件。
48:24它的访问行为跟我们存在在一台机器上是不一样的这样的一个情况。比如说我们可以举个例子，假设我这个文件在空间上复制了啊三份，然后在第一个时间节点对吧？我一个应用 OK 写了一个这个文件。然后这个时候我突然这这台服务器挂了，
48:41然后为了保证服务可用，我帽 tiout 了之后，我去另一台这样的一个服务器去访问这个文件。但是这这这是是这时候大家想想会出现什么样的一个情况。我一个用户明明修改这个文件，但是我又读我是读不到我的这个修改对么？
48:58这个现象其实在这个我们日常生活中非常常见。比如说我们去用不同的设备登录微信的时候，大家想想是不是我们不同设备之间的微信聊天记录是不一样的。那么有时候这个其实非常令我头疼的一件事，就是我经常电脑、笔记本啊、
49:13笔记本、平板，还有手机我都会用，对吧？这个其实就叫做不一致。那么大家有没有想过一点，
49:18就微信为什么不把它做的一致呢？不把它做成这致。其实我们在历史上对吧有很多的这样的一个方法啊，这些方法其实现在所有系统基本上都都在用。像这个 rapiid machachine，像 primarate、
49:30 private fashion 都在做这样的一个能够保证在一致情形下，我做这个吗？为什么不做呢？因为它本质上背后是因为它会有很多的这个开销啊，你要保证它一致，你得做额外的这个同步啊，
49:43我们后面都会继续讲。所以这个其实就是我们在做一个 system 的架构师的时候，对吧？你就要选择，比如说我在做微信的这样一个个多端端的这个消息的时候，对吧？
49:54我到底同步要做到什么样的程度？我的这个消息乱序得做到什么样的一个程度，对吧？这个其实背后都是由性能和这个空啊这个正确性上面的，有一个这个就考虑了。 ok 啊，
50:06行，我们那我们再休休休休息，休休息会会吧？就是是是嗯嗯一起和你来，这是是。