00:02一必须的，屁不要。好，我们继续啊，我们继续。那么刚刚呢我们在介绍了这个硬件虚拟化的这个 IOL 虚拟化 IO 虚拟化的目标。
05:58为什么 IO 虚拟化是为了能够让虚拟机里面的应用程序和 OS 啊，能够去更好的复用这个硬件啊，尤其是这个像网卡这种外部设备啊、网卡呃磁盘，然后包括 GPU 对吧？所以 GPU 其实也是非常重要的一个需要去做虚拟化的这样一个设备。
06:18这块的话呢是我们将来是做了很多这个这方面的贡献啊，在这个科研领域。好，那么这个前面两个是第三方方，就是是这个 parapgril device。 paramhul device 跟前面两个是一样的，
06:33就是要改硬件啊，说错了改 OS 啊，改 OS 改里面的这个代码。那但是呢实际上我们看来的话呢，这个的 paraversiizzdevice 这件事情的话，相比 paradiverialized 的 CPU 和 paraverialized memory 来说的话呢，
06:50其实它的整个的这个接受度要高很多啊，要高很多。那么为什么 devices 的虚拟化就更容易用 parach 来来做呢？其实原因啊分析一下也觉得比比较简单啊。就是说 device 嘛很多时候大家都习惯了，要装一个 driver，
07:11对吧？要装一个 driver。所以说如果我们去把这个 devices 变成一个 parallel 来的一个 devices，对于 OS 来说确实也要改。但是它改动的话就非常的非常的直观，就是装一个驱动就可以了啊，
07:27装个驱动就可以了。所以通过这种装驱动的这个方式，我们就可以很轻松的让一个 OS 去支持一个 paraporalizze 一个 DOS。那这个驱动是谁写的呢？毫无疑问就是由虚拟机的厂商来写的。比如说如果我们在 win wear 啊，
07:47我们我们装一个 in wear 面， in way 里面我们前面提了，它里面会给你一个八三九的一个网卡，对吧？早期的有些是好，那么他也可以告诉你说你我可以给你一个新的网卡，
08:00这个网卡呢叫 vm well，这是个网卡哈。这个这个这个制造商就是我们员工委会啊，因为他是个假的，它是个它这个 parwer 会出来的一个一个 US。它这个假不是一个真的去模拟，
08:12而是一个假的。然后呢，它有了这个假的这个网卡之后，它可以提供一套新的这个 API，那就不叫 virtualization，叫 abstract，
08:21对吧？我们前面提的 abstract 是新接口啊， vertuization 是这个旧接口。好，一旦它提供这么一套新的接口之后，那我就势必需要新的驱动。
08:31所以呢在 VM wear，它的拓子里面，大家如果用 VM where 都知道啊，它的底层菜单里面有个 tools，兔子里面有一个要装 VM wear 的一些有一组工具可以装。这组工具里面就包含了 VM wear 牌网卡的驱动。
08:49那当你装了那个之后，装了那个 tools 之后的话呢，就默认把这个 VMV 的网卡的驱动给装好。于是你就可以去驱动 VMVR 的这个虚拟出来，或者说他自己创造出来的这个这个网卡 OK。这个呢就是我们说的这个 parroh，
09:06那 paracrils 呢他会他是他怎么做的呢？我们可以看到他会把真正的这个 device 真正的 devices 啊，这是啊我们看啊，这是这个 guess，对吧？这是 guess 啊？
09:18这个是 KBM 啊，这是 KBS。然后呢，在 guess 里面呢有一个 front end driver，在这个后面呢有一个 back end driver， OK 这个 front end 和 back end 就组成了一对啊，
09:30然后呢这个 bank end 最终去驱动 device，它驱动 device 既可以是真的 device，也可以假 device，这都无所谓。对于 guess 来说的话，都是透明。
09:40盖 ss 只需要装一个 front end driver 就可以。对于网卡就装一个 front end 的这个网卡驱动。对于这个这个这个这个 SSD 就装一个 SSD 的这个 front end 驱动。这样来的话呢，就把整个的驱动啊把它进一步简化啊，驱动就进行简化了啊，
10:00那么这个他们这个 front end 和 back end 之间是怎么通信的呢？就通过一个叫 vert IO 的这样一种方式， vert IO vert l 其实就是 virtualize ation l 的一个缩写啊，它是一套可以认为是一套协议或者一套接口，它也是有一个库，那去实现这个 vert l 的能力。
10:20然后呢，这个 vert IO 呃，一旦有了之后的话呢，可以看到啊这个这个 form m 通过 wort IO 就可以连连可以连连到不同的这个呃表现啊。也就是说啊我将来这个 front end 我只要写一个就可以了。我的 back end 的话呢，
10:38可以有很多个啊我这个不同的应用程序呃，不同的这个这个这个网卡啊，我就可以有不同的这个 back end。这样的话呢，就把 guest 里面需要因为你的这个最终最真实的物理硬件不同，而要装不同的这个驱动，
10:54这件事情就没有必要了。我只要装一个就可以了，我不用说你硬件坏了话，就重新装一个六啊，只要该盖的去更新一下就可以了。这个呢就大大简化了这个 linux 或或者说这个 guess OS 啊，
11:07它的这个这个这个要持续更新的这样的一个负担啊，减减轻的这个负担是一。那么到今天呢，我们说这个这个这个接口，本来这个 front i 的这个接口是一个新接口，所以呢我们需要装一个新驱动。
11:23但是到今天虚拟化已经这么成熟了，对吧？它这么成熟了，所以呢它其实已经变成了一个旧接口了哈，已经变成旧接口了。就是就是这个这个 front end 这个东西已经变成了一个旧接口啊，
11:36大家都支持。所以呢后续其实很多事情就变得更加的这个方便了啊，今天我们这个随着时间的推移啊， virtualialiation abstraction，它的这个边界也在变得更模优异。新接口生产需要时间长了之后就给你救借口。
11:55好，这是我们现在常用的这个 paracatalize 的方法。第四种，也就是最后一种叫 highway support for hiovoa tuansition。这个 hardware 就不是指这个 CPU 或者 memory hardware，而是指实际的这个硬件设备。
12:13比如说在 PCI 的这个这个这个小组啊， PCI 的小组，因为他在里面也是重要的成员，对吧？ PCI 小组，然后呢，
12:21他们又推出一个叫 SRLV，叫 single rout i ovatalization ation 样一个技术。当然那后来还有 multi rout， i oatalization ation 是我们 single rout 用的更多一些，我们见的更多一些啊，叫 SSRVV。
12:34那这 SRLV 这个技术的话呢，它其实可以让一个硬件变成多个虚拟硬件。你举个例子，比如说我们这有一个 physical devices，它自身在硬件这个层面就有一个叫 physical function 的一个组件和若干个 virtual function 的这个组件。这个 vitual function 的组件呢，
12:55它的一个作用就是去配置不同的这个 virtual function。 OK 这个 virtual function 呢就可以去做真正的事情。我们举例，比如说网卡网卡的 virtufunction 本质上就是一组发送和接收的这个队列啊，就是 virtual function。它的 physic 方式呢就是去配置这些 virtual function 之间资源占用的比例是多少 OK。
13:21所以其实我们可以把它认为是一个 control l then 和 data then 的关系。 physical 方式是以 control l and contrrol 方式呢可以被认为是一个 data。 then 啊这个对那么这个飞后方式呢就可以去控制，它占百分之八十百分之十百分之十啊，这个是百分之零啊，它可以去做一个控制。
13:45所以呢很多时候我们就可以啊通过这个去灵活去管理不同的这个虚拟之间资源占用的这个比例是多少。而这些维手方式的数量可是很多的。早期的呢，当时这个买一块英特尔的这个网卡，插到 PCIE 的插头上，就可以看到有七块 virtual 的这个方式。
14:09七块网卡啊，还就相当于说有七个虚拟网卡，这样我就可以去支持七个这个虚拟机，对吧？七个虚拟机，那后来呢就多了一些，
14:18现在最多的可以到五百一十二，就是你买一块网卡插到 PCI 插槽。然后你 LSPCI 一下，你发现这个设备你的计算机多了五百一十一个 virtual 的这个方式。那你就可以在启动虚拟机的时候，指定任意其中的某一个，
14:35给这个虚拟机，让他去用就行。 ok 啊，其实只有一块网卡，但是还有很多虚拟网。这样的话呢就把整个虚拟化的工作又减轻了，
14:45很多软件要做的事儿很少了。 OK 就意味着我们通过这个 virtual 的这个 poweer，就已经回到了第一个啊，就是 pass 住的这个阶段。那第一个的还记得是什么吗？第一种方法，
15:00 direct access 对吧？ direct access 我们这一共四种，一共四种。 direct access 就是 VM 控制一个完整的一个 device， exclusively 跟别的都不兼容，不需要跟别人信。
15:15 are OK。现在的话我们就相当于回到第一个，这是最简单的一种状态。而且呢它通过一个 vehicical function 去做这个控制的话，还有一个好处就是它的迁移本身啊也会比真正的这个 direct access 要方便一些，迁移本身也方便一些。
15:31因为它如果要获取当前状态去做迁移的话呢，它可以直接通过 physical dress 去做这个状态的获取。然后呢在另外一台 destination 的主机上面去做这个状态的恢复啊。好，我们看一下发展的这个时间轴啊，这个时间啊。
15:47首先呢在过去的时候呢，我们只只有 software only 的这个 VMM，主要通过 binary、 translation 和 parary translation 这两种方法去实现啊这个这个虚拟化。然后代表性的工作的话呢，就是 v 烟不业。
16:04然后呢，后来呢就产生了这个英特尔提出了这个米 TX 这样一个硬件虚拟化的这个技术。然后这个启入之后呢，整个的这个 vm 就变得更加的简单了。因为硬件技术支持吧，那我软件啊要做的事就就软硬件协同，
16:21对吧？接着呢这个这条线就去往下走 OK，然后包括这个怎么样把 VM 的 switch time 降低，怎么样去做这个 extensial payable 啊等等，就是要做的事情啊，这个就 excel case 缺口就 EPT 啊。
16:40 PT 的话就是我们说的这个呃有两个可以认为有两个列表，对吧？两个页表表就是 g 啊。然后呢，这个让整个的这个这个这个 physical 呃，就 guest、
16:52 papastable 和 host pasttable 同时能够存在啊，这个就是 EDD 啊，我们说的内存虚拟化的第三种方法好之后呢，就推出了米 TD。米 TD 的 d 啊，是 device 的意思，
17:05是 device 的意思啊。这个 device 的意思呢，就是说我要要去做这个呃去做这个 device。 MA remarking 就是 IOMU。我们前面说的啊 MMU 要加在 IO 这方面，而不是仅仅加在 CPU 这里面啊，
17:18就是在这个时候做的第三个阶段呢，就是 focus 在这个 IO 上面，就是 PCI 的这个 c 股推出的这个 SRLV 啊， SRLV 啊，这个就是我们说的这个第三阶段啊。第三阶段的话呢，
17:31主要就是把这个 CPU 和 IO 的 vturozation 的性能和功能进一步的增强。这样的话呢就形成了一个完整的一个啊完整的一个平台。所以可以看到第一步呢主要是在 c pu 这个级别，就这个这个集中在 CPU 的这个改动。所以呢我们看到的东西就是 CPU 的虚拟化和 memory 的这个虚拟化的这个支持。第二部分呢主要是在这个平台层，
18:00平台层，大家知道英特尔的话是有芯片组的，对不对？主板上的芯片呃，也就芯片组也是要跟 CPU 配套的。然后呢，
18:09主要是这个这个这个就是第二阶段在主板的芯片组上面的改动，增加的主要的这个功能就是 IOMMU 啊，这是第二阶段。第三阶段呢就是集中的 l 了。 IO 就就是 device。注意啊，
18:24这个芯片也有芯片，但这个芯片不是 CPU 的芯片，也不是芯片组主板上面的芯片组芯片，而是网卡上的芯片啊，网卡上的芯片。所以这个网卡和这个 SSD 等等啊，
18:38这些设备唉就是这个第三阶段。那这个呢其实就跟英特尔其实关系不是很大。但是呢因为这些卡都通过 PCI 来作为扩展，要插在 PCI 上，而英特尔控制了 PCI。所以呢可以看到整个的这一套都是由英特尔来控制 OK，
18:54英特尔控制了 CPU，英特尔控制了主板的这个芯片图，英特尔控制了 PCI 的这个 CU。所以呢整个这套虚拟化是由英特尔来主导啊，是由英特尔来主导。所么啊后面的话就不知道随着英特尔的这个示威对吧？
19:12也许这个这个这个将来不知道谁在主导啊，会坏的。好，我们总结一下今天所说的这个虚拟化的技术会发现呃，今天我们主要讲 CPU memory 和 LL 轴 device，然后呢分别从 software solution 和 hysquare solution 两个角度去阐述。
19:33在 software solution 里面呢，有对这个硬件啊，对这个虚拟机没有任何修改要求的的方法和 parameuizze paramitizze paramitialize 的这个方法啊，它主要是分成两大类啊，就是看要不要改应用程序或者要不要改。 guest OS 如果不改，
19:57那就是一个纯粹的虚拟化。如果要改，那就是一个半虚拟化，对于硬件来说呢也是一样的。这个是我们说英特尔它是不断的推出相应的这个 harriway 去支撑啊我们的虚拟化的这个程序进一步更好的运行。这也是我们今天说的主要的这个技术。
20:15在研究领域的话呢，虚拟化它带来的一个最大的一个挑战。除了性能之外啊，性能毫无疑问是一个挑战啊，这个是我们一直到现在都在讲这个叫 data central tax 数据中心税。什么叫数据中心税啊？
20:29就是你一个应用程序，你在你自己家里买了，比如说十六台服务器，你跑下来是一个性能。你把同样的这十六台服务器变成阿里云变成百度云或者华为云或者酷狗云。然后你跑同样的 workload 配置都一样，
20:48钱也差不多，你发现就慢了百分之五。那为啥呢？就是因为你本地啊一个很重要的原因就是本地没有虚拟化对吧？然后远端是有虚拟化的啊，所以呢它就会产生了一个 tax，
21:02这个叫性能税，叫数据中心性能税。当然呢这个性能税呢，就我们说在过去的二十年，基本上就已经被解决的差不多了。今天我们的虚拟化，
21:12它的 overhead 是能够很好的控制住的啊，差不多就是在百分之五以内，百分之三、百分之二等等啊。当然你说百分之二要不要再提升啊，肯定也是有有有有有价值的，
21:25尤其是在数据中心，对吧？你说我这个这个每年要花多少钱？在这个数据中心的百分之一就是一个很大的数，可能就是百亿级别。所以呢我们说这个呃性能是一方面它带来的挑战对吧？
21:40觉得 overhead 是会变大的那另一个挑战是什么呢？或者说另一方面的挑战是什么呢？就是这个 semantic gap，就是叫羽翼的鸿沟，羽翼鸿沟。我们举个例子，
21:54就是在我们的 VMM 里面的话呢，我们要去管理这个 memory 管理 memory。但是呢我们怎么才能够去知道每个 memory 哪个 mary 这个应该被 evict 出去，对吧？哪些 memory 应该放在内存里面，时间再长一点啊，
22:15这个就那是一个挑战，我们传统方法是怎么做的呢？传统方法就是用 LRU 来做 LRU 的，全称叫 list recent use 对吧？ list recent use。那有了 LRU 之后的话呢，
22:31我们就可以去呃统计一下啊，哪些是最常用，哪些不常用。然后把那些不常用的把它踢掉就行了。很简单。但是呢这里有个问题，
22:40就是如果我们在 VMM 这次这一层去做 LRU 的一个 tracking，其实是很浪费。为什么很浪费呢？因为这个 OS gas OS 它其实比哎 VMM 了解自己的内存需求啊，包括内存的这个这个这个这个使用的方式比这个更了解啊，而且是非常的非常了解。
23:06 ok 那我们怎么才能够去充分利用这个 OS 对于自己内存使用这个模式的了解啊，然后更好的去做这个内存管理，而不要去依赖于 VMM，再去做一层这个 LRU 总裁。做到这一点呢？我们就会想到用一个叫 balloon 的这样一个方法啊，
23:27 balloon 这样方法。具体来说就是这里有一个 OS， guess OS。然后呢，然后这个 vm m 呢就在 guess OS 里面呢放一个间谍哈，放一个间谍或者叫一个气球。
23:39然后呢，当这个整个机器整台机器啊边面面是可以看到整台机器的当整台机器的内存压力太大的时候呢， VMM 就把这个气球变大变大。变大之后，什么叫变大？变大就是要要求更多的 memory 啊，
23:56就是我现在在 guest OS 里面这个间谍，他去申请更多的内存。那 OS 呢被压的不行了，就开始回收别的地方的位置。他先问他，那你真要这么多内存吗？
24:09这个气球说我真要这么多内存，你把别的内存都给我，那从谁那儿抢内存呢？ OS 就会就会去这个就会去抢内存啊，就看那些通过自己的 LRU 去找到最不需要内存的人，把他内存把它给都给都给收过来，
24:26收过来之后放到这儿放在这儿看呢，没想到这是个间谍气球啊，他拿内存之后不是给自己用，他是还给这个 VMM 啊，还给 MM。然后呢，
24:35还给 VMM 之后呢，这个 VMMM 就可把这这内内存给到别的，有需要的这个 VM 那里用。这样的话呢就完成了在全局范围内的资源吊配。而且呢 VMM 本身它不需要知道谁哪块内存常用哪块内存不常用，它不需要知道为什么，
24:55因为他只要负责在这个气球要内存就可以啊。至于哪些内存常用，哪些内不常用，是由 OS 来来判断来界定啊，然后呢就把这个数据把它给这个都把它给收走啊，就是我们说的 balloon 就是这么去做的。
25:12 EFX 呢就是我们前面提过的这个，对吧？就是这个四变位，它就使用了这样一套技术啊，它就使用这样的技术。然后呢这个这个这个呃去做这个内存的这个 balloing 的全局范围内的这个调配，
25:27这是一个还呢而且 ESX 还做了一件事情，什么事情呢？就是他会去做 cross the m 的 pay sharing，也就是我们很多时候起虚拟机啊都起的差不多的镜像，对吧？比如说取个 u buunto 啊，
25:39这个这个二十四点零四类似于这样的这个呃 image。然后当你起完这个鲁班布之后啊，你发现另外一个虚拟机器，它其实也是这个二四点零四啊。这样的话内存里面的话其实就有很多个二四零四的镜像保存之后留下了一些一些数据。所以呢这个 ESS 呢就有一个定期去会去扫内存，
26:01看看内存的这个哈希是多少。如果两块内存的哈希是一样的，直接合并一下， merge 一下。这个呢就这个这个就就就可以很好的起到这个把内存，把重复内存消掉这样一个作用啊，
26:17这个是比较早期的一些工作。此外呢，在这个语义方面的话呢，其实也是有啊。比如说我们说 BMI 当时呢就虚拟化兴起之后啊，有很多做病毒研究的人，
26:30就觉得这是一个特别好的一个蜜罐系统，或者说是一个用来研究病毒的一个系统，为什么呢？我起一个虚拟机，不在里面跑病毒，对吧？
26:38看看这个病毒它是怎么攻击的，它行为是什么？他怎么把自己展开啊，怎么样去从呃注入别的这个进程等等，可以去观测这个病毒的这个行为。那么反过来我们也可以说现在有个讯息跑的好好的，
26:53对吧？然后呢，好像被人攻击了，那我是不是可以从外面去看，他是不是被被人攻击了啊，他是不是被什么东西。
27:01那我们怎么去判断一个虚拟机是不是被人攻击呢？有很多种方法啊，这个就就说就是我们要找到它的这个不变量。我们举个例子，比如说我们要去想一个虚拟机，它里面的一些东西，
27:15哪些是不变的啊，就比如说这个地方加这个地方就应该等于这个地方，这是一个所谓的不变量 vivirment。如果说这个不变量发生了变化啊，就是 a 加 b 不再等于 c 了。那么很可能就是出问题了。
27:33我们来看一下这个不变量。举个例子，假设我们现在有一个这个 task list，就是 task list。什么 task list。在 linux 里面的话，
27:42 task list 是一个把所有的进程啊啊对它它其实叫 task。当然串起来这种方式，这个 task 本身是一个链表啊，它是个链表啊，来看它有个列 list，然后把它给串起来之后的话呢，
27:57所有的进程都穿在这个双向列表上面。然后呢，当我们去运行一个叫 PSAUX 的时候啊， PSAUX 的时候，对吧？这个就会显示就会遍历这个列表，
28:10蓝色这个列表把所有的这个进程啊全部都给打出来啊，这是 PCYX 怎么做的？好，这是第一。第二个呢就是在 linux 科能里面，还有一个队列叫 run q run q ue。
28:23这个 wrn q ue 呢，它不是所有的进程了，而是当前正处于 active 的运行的进程。这个 active 的进程，它是属于 ready 状态，随时可能被调入的。
28:34剩下一些呢是在等硬盘等各种东西，它处于一个这个这个非 active 的一个状态 OK。所以我们可以可以看到 task list，它是这个 wrong wrn q 的一个一个一个超级对对它一个超级啊。好，这样的话呢就有一个 run q 那么当我们去运行啊这个这个想要去这个 CPU 啊，
29:00想要去找哪些进程要运行的时候，就从这个 rn q 里面去找啊，反正运行一个下一个，运行一个下一个，运行一个下一个，它是这样去做好。
29:11现在问题来了，有一个黑客啊，有一个 marry，这个呢它这个名字叫这个 malwaddoor， NG 啊，叫 adr NG。
29:21他呢就发现了说，你现在有两个东西有两个对联。然后呢，他说我想跑一个恶意的应用程序，但是呢我不希望被管理员发现我怎么办？就我要偷偷的去运行一个运行一个这个这个黑客的一个一个后台的一个进程。
29:38但是呢我不需要被发现，那既然你要运行，你就要把自己放到 rong q 里面去，对不对？因为 CPU 它的调度器是从软口里面取一个硬件取一个零，所以把发放在软口里面去。
29:50但他不希望被人看到，什么叫不是不希望被人看到，就是当程序员或者说一个管理员运行 PSAU 去检查有哪些程序在运行的时候，他不能看到我这个恶意软件在运行。所以呢他就做了这样一件事情，就是他把一个应用程序从大家看啊，
30:09就就这个应用程序对吧？他把应用程序，他把这个应用程序呢，把这个两根这两根把它给删掉。变成这样。于是呢这个应用程序 task one 它就在 wrong q 里面，
30:24但是它不在 task list。也就是说当 roq 应用程序啊这个 cpu 去取下一个程序去运行的时候呢，会取到它。但是你运行 PSUX 想要便利一遍啊，把所有东西打出来时候呢却看不到它。这样来的话呢，
30:42就起到了一个隐藏的一个效果，就是它可以被调度，但是呢却没有人会看到它啊，没有可能这也是一个非常著名的一个这个这个这个这个这个黑黑客的这个这个软件。他用的这个方法呢啊直到现在为止还是一种说常见的方法。好，
31:02那么我们怎么解决这个问题呢？我们就可以用 VMI 去做这个事情，怎么做？ VMI 呢？就是我把一个虚拟机把它给暂停 pos 暂停住。暂停住之后呢，
31:14我就去遍历它所有的这个 task list 大柜子。便利背完之后呢，我再遍历所有的这个 cpu 便利，说有点 q 好，便利完了之后我就去检查讲什么呢？如果说有一个 PID，
31:32它在这个 wrn q ue 里面却不在这个 fast list 里面，我就认为它是一个恶意的一个鉴谍软件，对不对啊？这个呢其实也很很容易理解啊，很容易理解，这就是一个这个获取数据分析这样一个过程。
31:47但它有个缺点，就是它会暂停 VM 啊，它不能同时跑，会把这个 VM 暂停起来，这也是他的一个一个问题。所以 VMI 的速度还是挺慢的啊，
31:56当时做了很多的工作啊，大量的这个研究论文在想我怎么样从 VM 的外面去看 vm 的理念啊，是如何 work 的，到底有没有出问题？你是在跑什么？这点的话呢跟我们今天啊我们说这个 AI 其实有点像啊，
32:15我们今天很多时候其实要把这部分的工作啊交给大模型去做的话，可能他能够得到的一些东西啊可能还还真不一样。因为我们有很多个让他学一些不变量出来，然后呢让他去分析啊，某一个 BM 镜像是已经被攻击了，还是说正常运行啊，
32:34那就大模型去分析，也许会有很多新的一些东西啊会出现啊，因为这个变量太多了，变量多复杂，用大模型可能就比较合适。那么 VMI 它的最大的这个挑战的话，
32:47就是怎么样快怎么样不要中断这个虚拟机的正常运行，以及怎么保持一致啊，就是不要说这个误判是吧？这样不要误判，就是 VMI 的这个这个点 OK。好，
33:00那么等到 VMI 这个点都被解决了，性能这个点也被解决了。那我们说这个 vm 的这个相关的这个工作啊，也就也就差不多了。今天呢我们说在这个呃数据中心里面的话呢，这个基本上虚拟机运行它所开销已经很少了。
33:16我们现在提了百分之三以内，对吧？大部分是百分之三以内，然后呢这个 VMI 呢也已经被用的很广泛了啊，所以呢慢慢大家发现没有什么问题需要解决了。所以呢慢慢的它这个研究的论文就就下来了啊，
33:30就少了啊，这个就是形成一个周期啊。所以说这个我我我我们自己在做的这个虚拟化相关的工作，也差不多就是到性能到这个羽翼的这个鸿沟，就是所谓的 semantic gap 羽义鸿沟啊，就是用来做毕业班这件事情慢慢慢慢的收尾之后啊，
33:49后面确实也想不到什么更好的很好的工作去做。当然后面有一个虚拟就是机密虚拟机啊，就安全 security 啊，也还是现在目前还是还是有很多人在研究这个点啊，但是呢后续慢慢慢慢的我相信啊，它也是会有一个周期的这样一个呃这样一个存在啊，
34:06这个呢顺便也是跟大家一起炫一下这个这个这个一个研究 topic，它的这个这个这个这个 life cycle 啊 lifeyyle。好，那我们今天就上到这儿啊，我们中间中间休就中间少休息了十五分钟，对吧？
34:21好，下课吧，算我算了，你想你好吧，谢谢。滚可以没有黑色，
35:19对呀，直接说谢谢。所以这个吗？也可以什么东西来好的，那个在哪了？对，
36:15不是今天对不起，你要搞自己的，他会有这个一好给，然后两个放在一起比较好。你是把什么东西放在我图书简介，就是我也把图书简介，
41:21我就什么显示的最熟就就对呀，他就看不出来问题了。我是图书剪辑，还有一个那那个图片，那个图片调了，我很久起来难调，
41:34难调就不放，有问题就要学会规避问题。是的，而且而且就是我之前就不是用 red IF 嘛，然后我我们就用 red IF，我就显示关键就是我发现就是反正我那个 RE dits 还有什么那个和对卡夫卡相关都是和 order 相关的。
41:59所以就如果如果写的，我不想拿我两个都不能他在后端会报什么，找不到找哥，怎么会黄色味，怎么会这样？对呀，
42:13不管他一人一个。你好，亲爱的，等一下，行，超级喜欢好累。
42:38这积极心里是每一句医生，我是一种好平准，就 AI 完全写不了。昨天写了一个的一些字 q 然后写完之后把标黑给关掉。对不起，真的很这是我从哪说一句话，
43:11对我一点不想看这个这些人有点。你这样七点嗯是谁先看一下那个截止了截止了，我真的觉得嗯你是嗯天气好好是的，真的我今天就既然限一主嗯有计会嗯，什个三个人是我在嗯结实可以有病，还有人在群里冰，
50:30就是当这才估计老丁要有没西敢点进去，然后呢说说有人在群里，我这节课会会很精彩。大家讨这群那谁，那群里的那个消息应该不是从直接从这定开，我们讲过一起是去十么点，
53:02嗯嗯，对嗯嗯。