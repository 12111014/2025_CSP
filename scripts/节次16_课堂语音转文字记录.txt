02:08好，必须得西，没听清去你。不对，谢谢爱你嗯我爱很好心，今天在上课 OK。
05:34那今天上课的话，我们会讲啊另一个跟执行非常相关的问题。就是当你的这个系统出现并发的时候啊，一定就会遇到过各种各样奇怪的问题。为什么这些问题会出现，以及啊我们怎么去避免他们？
05:50这是我们这个有一些经典的方法，像 TKS logp OCC 对吧？他们这些脉络是怎么来的？他们背后到底是由于什么样的系统原理都这样，就是我们今天的这样的主题。 OK 仅我们来看一个经典的例子。
06:04首先为什么我们需要并发对吧？大家可能想到我们自己平时啊写的程序最多，对吧？如果你不做系统研究的话呢，很多时候你会发现你写代码都是单线程的啊，单线程这这样一个服务，
06:16单线服务其实写起来最为简单。那么写这些程序它背后到底有什么问题呢？到底有什么问题呢？其实我们会发现发现现在你你如果是一个单线程的程序吧，你其实很难够啊达到这样的一个非常高的这样的一个吞吐。一旦你达不到一个非常高的吞，
06:32你可能都到导致一个结果。就是啊你虽然每个任务本身做的很快啊，但是你做的很快，它其实并不能转化成这个用户端到端的这样的一个延时 OK。我们来举个例子啊，假设啊我们就要实现一个这样的一个银行的这样一个服务。
06:50然后我们说你要实现这样的一个服务，它本身很简单啊，我在某一台机器上啊搭一个这样的一个 RPC server。接收消息收到一个消息，做个消息，然后消息就是我呃做内容就是我每次转账 OK，
07:04就这么一个非常非常简单的应用。你刚才想想，假设啊我们不考虑说有容错的问题。我们假设我们的这个说所有的数据对吧，都存在在这个内存里面。那么我们这样的一个银行服务对吧？
07:17它其实是的延迟是非常低的。大家想想我们就在内存里做一个银行转账，它的操作大概是多少呢？它其实大概也只有这个几微秒啊，现在的计算机机能够在几微秒内完成一个类似银行这样的一个应用了。但是我告诉大家，
07:33在实际过程中，如果我们就用这样一个非常简单的这样给银行的这个几微秒的这个这个时间。你实际上用户会告诉你说，有时候我的这个这个请求的延迟啊会到几几百秒，或者是更是甚至更长。为什么会出现这样的一个情况呢？
07:49因为其实延迟它不仅仅跟你做一个请求的这样的一个这个时间有关，它还跟你这个当前的这个吞吐有关。我们可以来举一个具体的这样的例子 OK。那么我们来具体看一下啊，假设我们是这样的一个单线程的这样一个银行的这个 service，对吧？
08:05那它处理模式式实非常简单，就是我一个用户是吧，发一个请求 OK，然后我这个 server 处理完之后啊，把这个请求发发过来啊。那么其实站在我这一个用户的角度来说，
08:18他这个请求延迟什么？就是这个这个 server 在收到这个 x 四之后处理的这个延迟，基本上加上一些网络，网络的话，其实是比较稳定的 OK。那么这样的一个延迟的话，
08:28它大概也就是一个几微秒几微秒。那么我大家想想，我们用户，他难道这个体呃平时体验到的一个延迟就是这样一个几何秒嘛？其实不完全是我们来举例一个例子。假设这个时候对吧我有另外一个用户啊，
08:44他也往你的这个 banks ways 去发了一个这样一个消息。那么大家想想想，这个时候由我的这个系统，他只他正正正在处理当前前面一个用户请求，对不对？所以我们这样一个新的用户的这个请求，
08:57他其实没有办法处理的，对不对？那这个时候怎么办呢？在现在的系统里面，我们这个假设我这个系统没有办法处理你这个请求了 OK 我的这个用户的请求会被缓存在一个这样的一个队列里啊，我们叫 QQ 啊 q 然后呢这个队列里可以使。
09:12比如比如说你可以实现在软件侧，对吧？比如说网络协议 TCBID，它其实会帮你去做一些缓存，对吧？如果你没有收到消息，
09:19你的消息其实就会放在这个包裹里 OK。那么这个时假设我们这个启求时时候候对吧，直得等到什么等到我前面一个用户做完了，对吧？它才能做后面的这样的一个请求，对吧？
09:33这是个非常简单的这样的一个 model OK。当然有这样的一个 model 之后，我们就会发现一个很重要的事情。就是你对一个任何的一个现代的 service 啊，不管你是 AS 也好，对吧？
09:43何老师说的是银行的这样的 server 也好，它的这个用户的响应时间实际上是由两部分组成的。第一部分是什么？是说他去等待当前的这个这个 server，没有处理完的这个请求去处理完。然后第二部分是什么呢？
09:57才是它自己本身的这样的一个数据线，它应该是两者之和。那么后面的这个直接的处理时间，它其实是跟什么？跟你的这个一个请求，它需要多少计算有关，
10:09对不对？但是它前面一部分请求取于什么？取决于你的这个 server，它当前有多少堆积的请求，以及更重要的事情。什么呢？
10:18是我这个 server 它到底有多快的速速度去消耗这样的一个请求，对吧？如设这个是什么？其实就是你的 server 的吞吐，就是你的这个 service 吞吐。如果大家想想你的这个服务器的处理能力 suput 它跟不上你这个请求会出现什么情况，
10:37那就是什么什么况况。比如说我举个例子，假设我们的这个请求到来的这个速，对吧？ lambda 它是远大于这样的一个之的，这样的一个你的 system super 就没们远处出多少个请求，
10:50意味着什么呢？意味着说你在任意一个时刻，任意一个时刻，我用户的它的这个排队的这个 service 的这个延迟啊，它等于什么？它等于 lambda 去去 ruooput 乘以 t 然后 t 是你当前的这个 service 的服务时间。
11:05 OK，大家想想，我们作为一个银行的这个 service 啊，这个服务它是会上线很长的时间的这意味着什么？意味着说你当你的这个服务速率是远大于你这个 service 的通你的这个用户的这个请求啊，也不用远大于啊，
11:20就稍微大一点点。你的这个用户他的改应的时间，它其实根本跟你的这个请求处理时间是没有关系的。它完全就取决你的修复的，而且这个时间是非常非常大的。因为我上线了一个小时。
11:30好，我的这个等待时间就会变成一个小时。那么这也就是大家很多时候我们说哎看到服务不可用啊，什么原因？它其实并不是说你服务不可用，是因为这个 server 它堆积了非常多的请求，
11:41对不对？所以我们可以看到的一点就是在一个真实的这个系统中啊，我的 server 花多少时间处理一个请求？这个事情很重要。但是他它不仅仅啊你光有这个处理时间很短，它不够，
11:55它还什么？它还还还依赖于你这个 server，能多快的去消化这样的一个需求 OK。那么回到我们之前的这个样子运。那么大家想想，如果我们对于一个单线程的这样的一个 server 的这样的一个实现的话，
12:10那么它的消耗的这样的一个请求的速率大概是多少呢？对吧？就是我通过这样的一个模式啊，我们其实是可以通过这样一个 system model 很方便的推出来大家讲它的它的库的去选什么。它库的拉满，它的库的其实本质上是取取决于就是说你连你你当前的负载对吧？
12:29如果理论上是我们最理想的什么？就是说我这个 susususerver 他这个每时每刻都在跑这个请求，对不对？也就是说我这个请求会把你的这个时间线给填满。那么这个时候假设我们这个 request time 大概是这样的一个一个一个这样的时间的话。那么其实我们可以知道它的 sup put 每秒能做多少呢？
12:47无非就是一除以大概就等于一除以你这个 request time 之吧，这就是你这样的一个时间。好，那么这个时候我们们就会发现一个问就是你你比说说你作为一个这个架构师，对吧？你要上线一个服务，
13:00我比如完一个这个这个 suu put 之后，这个时候大家想想，根据我们前面的例子，我们得干什么？我们得去比对一下，就是你的这个当前的这个 suput，
13:10对吧？跟你的这个呃这个这个这个这个这个这个用户的请求到来到来率，它的关系是怎么样，对吧？那么在工业界的话，一般来说有一个经典的标准，
13:21就是说你的这个思路啊，你的呃你的这个呃这个 request rate 比 su put 大概要是一个零点八就百分之八十这样的关系，为什么呢？为什么呢？为什么是这样的一个关系呢？因为第一啊就是说就是说其实其实当然然这个里面有一些排队论的这个理论啊，
13:38大家感兴趣可以看一下它其实核心说的一个事情就是说当在在比如假设你的请求是一个这个扩松分布，就是说我我可能会有一些呃这个 burst 这种请求的这种情况下的话，那如果你的这个 output 它是很接近于这个 request rate，即即使是这个它大于 request rate，它的这个尺这个这个延迟的标示啊，仍然是会平方于这个这个 request 的这个时间去上来就会标的特别快。
14:05这是是这是一个排队的这样一个经典的这样的这样的一个结论。所以说它原因其实就就就是来自于我们这张图的这样的一个解释，对吧？你得非常快的，要要等它这个这个里面当当你来一个 birst 的时候，你的这个队列会快速这个积压啊，
14:21导致你的这个啊这个行头处理过来 OK。所以这个时候当我们判断出 OK 说如果我 suput 它跟不上这个 request rate，这个时候我们怎么办呢？我们就得想办法去提升 output 对吧？提升 output，那我们怎么去提升 output 呢？
14:38一种方式是说哎，我们能不能把这个 request 的时间给压下来，对吧？就让这个时间变得更短啊，因为你 output 其实约等于这个一除以这样一个 request，这个 process cess time。
14:49但是这边会有一个问题，就是在我们现在这个二零二五年的这个时代，对吧？你的这个单线程的这个处理能力啊，它其实已经很难去呃增长了。当然至于为什么我们我们后面会讲计算的时候，
15:01我们会啊单独剖析一下。那么所所以所以我们该怎么做？那么一个核心的思路就是唉既然我一条线处理它每只能处理这么多能力，那我多增加几条线，把它去给并行处理不就行了吗？那这就是我们一直讲的就是说叫做 parison 或者 compparense 或者叫做对吧？
15:21我们就是通过这种租械程以及多台机器的方式去提升我们这样的一个系统存储。在我们单线程情况下，你没有办法提升存储前前提下大来。通过那 skill 里的话，它其实分成两种，一种叫 skill up，
15:35一种叫 scale out。那么 skill up 就是说我一台机器有很多个线程，包括 GPU 去写上 GPU，它是有很多个空。那我希望把我的这个计算均摊到这样的一个扩上啊，提升进程。
15:46那 skill out 的话它就比较直观的，它就说我就很多台机器对吧？把它组合起来啊，这个这个是来做。那么为什么我们在做 skill 类的时候啊，要区分 skill up 和 skill out 呢？
15:57因为一般来说如果你是在一台机器内的话啊，它的一个好处是卡呃卡之间的这个互联啊，很多就是通信会更快一点啊。但如果你 skill out，你得用网线连的话，这个速度其实就就比较慢啊，
16:09所以我们得做这样一个区分啊，但是具体这个区分它其实是主要是对性能设计考虑，它并并不像我们啊这节课考虑讨讨论话题，我们这节课要告告大大什什，就就是说啊当我们 suill up 不够的时候，对吧？
16:23我们就得去 skill up skill out，去提这样的一个系统制制。但是一旦我们 scale out， skill out，它本质上就是一种 concurrency。那么一旦你出现了 concurrency，
16:33我们就会发现一个事情，就是你如果这个这个系统啊设计不到或者应用写的不到的话，其实我们就会出现你的这个数据啊，会因为这个一个叫 race condition 的这样的一个问题啊，导致你的这个数据全都算错了。 OK 那么是什么叫做 ace condition tion？
16:49我就来举举个例子。好，对吧？还是我们之前的这样一个银行这样一个例子啊，我们这个银行它有一个基本的操作，就要就是说转账啊，
16:57比如说我给比如说哦就加钱啊，我可能就给这个某一个账户，对吧？加一个钱好。这个时候呢我们发现我们这个银行它的这个流量比较大对吧。这个时候我们希望能够增加它的吞吐。
17:09那我们怎么吞增加吞吐呢？ OK 我们就让两个 thread 或者说 n 个 thread 去做这样的一个加钱的这样的操作，对吧？就我不同用户来，只要我有一个空的 thread OK，我就能把这个 thread 分配给它，
17:20开始做 OK。那么然后我们现在为了简化问题，我的我们就考虑我们的这个这个钱前的这个东西就是放在内存里啊，我们也不考虑持久化持久化。我们上节课已经讲过，这个啊这个 login 啊也好，
17:32这个这个这个 check point 也好，这些技术都能解决 OK。好，那么大家想想我们这样的一个假设，我们现在就最简单的一个应用，就这个应用这个应用，
17:42我们最理想的情况是么呢？就是我们对于这个银行的正确性保障什么？假设我们这个这个这个这个这个这个里面只有这一个操作啊，就不同用户啊，希望疯狂的这样的一个加钱加钱，对吧？
17:54那么其实大家想想我们一个理想情况，就是我们这个用户加了几次钱，对吧？那么他最后的这个账户的总额应该是等于你这个加钱的，所有的历史记录的累加和的。比如说我 IOS 对吧，
18:05他就转了两是十块钱，对吧？那么它理论上来说，它最后加出来的钱，账户的钱应该是二十块，对不对？
18:12那大家想想，如果我们 IS 发了两个这个并发的这样的一个请求，然后这两个请求正好在 t 零 t 同时做的时候，可不可能会出现一种情况？就是我 IS 明明给自己加，或者说有人明明给 IS 加了两次钱，
18:25那他最后唉只能算出十块钱呢，十块钱的那现在这在并发下实际上是完全有可能的。为什么？因为其实在这个这个这个分布式的这种场景下，是吧，我做一个这样的一个请求，
18:38但是并不是一个一瞬间就能完成的指令，对吧？它实际上是由背后啊背后它是背后有很多条指令去组成。比如说大家想想我们就实现一个 c 加加里面最简单的加上等于这样的一个操作。对吧那这个操作其实在硬件上会被翻译成三条这个指令去执行。第一条指令是这个这个这个这个把这个这个这个这个这个这个你要加的这个钱，
19:04对吧？移到这个寄存器里 OK，然后呢再把这个寄存器里加上你期望的这样的值，然后最后把这个寄存器里加好的值返回。然后每个寄存器是每个县城独有的，它是其他县城是看不到的这样的一个操作，
19:17对不对？好，那大家想想，我们假设我们每一个转账操作是由这三条指令组成的。然后这个时候我碰巧有两个 thread 啊， t 零和 t 一他收到了这样的一个 IS 的这个转钱的这样的一个加钱的这样的一个操作，
19:33对吧？这个操作要用刚刚我们说的那三条指令去加钱，大家想想会出现什么情况，会出现什么情况。我们在这这两操操作的过过程中，其实这两个操作完全是无视掉对方。
19:43除了最后这个写入操作不不对，为他们都都在自己的操作， CPU 的寄存器里面去操作，对不对？所以我们就会发现，为什么你会就会出现我们最后加了两次，
19:55对吧？加出来会等于十情况，为什么？因为大家想第一我们来看一个执行流，对吧？因为第一我 spread 零好，
20:01我说做这个请求，我把这个账号读到这个啊这个寄存器里。然后呢，这个时候我 spread 一同时也把这个账号给读到这个寄存器里。然后这两个人之后，他们都都在这个什么都在自己的这个寄存器内 OK 对我的这个账号去做了这个加线的这样一个操作。
20:19加完之后，我再把这个写回写回。那大家想想，站在我一个这样的一个操作的角度来说，它的三个操作是正确的，对不对？
20:27但是在这两个这样的一个操作来说，他们是不正确。为什么？因为这两个操作之间其实是有一个依赖关系的对吧？我一个这样的一个 thread 一的这个这个加加同一个账号的操作，它其实应该要等到前面一个做完了，
20:39他才做，对不对？这是分布式你你你就是说对吧？那大家想想这个核心的原因是什么？核心原因是当你一个操作，它没有办法瞬间完成之后，
20:49你的这样的一个交错的这样的一个执行啊，它实际上会影响你这个有些应用你内在的这样一个依赖的这样的一个关系。那这样的话，如果你不去做一些控制，那么它就就会出现你的这个最后最后的这个数据错了。所以这个导致这个问题就是我们想要用并发去提升吞吐 OK，
21:08这是一个非常简单的设计。但是一旦我们要用并发，我们就一定要去思考什么。就是你在程序中可能会出现的各种因为这种特 intet 运造成的这样的一个不一致的这个问题。那么这个 in interliving 的它造成主要的不一致问题是什么呢？那么人们把它总结出来一个现东西叫做这个啊 race condition 啊，
21:29就是说有没有发现啊它它那个叫什么？一旦你有 race condition，那么也就意味着你的这个程序是有可能出错的那什么叫做 race condition 呢？就是说我有两个 thread 在并行的对一个数据操作啊，一定注意要是同一个数据。因为大家看你操作的不同的这样的一个数据的话，
21:45那它其实是天然是可以并行的。然后其中有至少有一个是写操作啊，那其实就会触发这样的一个问题。那大家想想刚刚这个例子其实也是对吧？我两个 thread 对同一个操作，这个既读又写，
22:00那么就会造成一个情况。就是说我一个 thread 可能会因为 inter leving 看不到另一个 thread 的这样的一个这个写的这样的一个操作，对吧？那么就造造造成结果，就是我我把你的这个结果给覆盖掉，对吧？
22:12这个其实是是是不对的啊，其实是不对的那这种情况，那我们就叫做这个啊 reconconnition 啊 recoconnition。好，那么 race condition 的话，我们怎么去？
22:24它有一个当然 race condition 本身它只是一个现象，它这个现象为什么叫做 race 呢？因为这个现象它有一个很重要的特点，就是它不是所有的时候都会出现的。就是它它不是不是说你你有 ace condition，就一定会造成这个这个这个这能性问题题。
22:39比如比如说我们前面可以看到，对吧？我们这个例例啊它是有 race condition 的那它显然最后结果是错的。但是呢如果我们换一种这个调度方式，对吧？我碰碰巧我的他正好在做其他的这个操作。
22:52然后苏二零先把这个账号全做完，然后再做苏二零的账号。那大家想想这个时候的话，其实它加出来的指标是正确的。一手为什么？就是说你的这个正确与否是取决于你的这个处理器多快的速度，
23:05处理你的这样的一个不同请求。也就是说它只有部分的这样的一个请求，它才呃部分的这个调度才会出现这样的一个问题。好，那么有了这样的一个问题之后，我们其实就会做系统呢就发现有问题就是你的这个这个微常能件其实非常难以敌 bug，
23:22为什么呢？其实我之前也提过，对吧？因为 risk 它它最大的问题，就是不是你所有的执行都会出现问题。对吧当然我们上面这个例子，
23:30右边这个例子它其实就没有问题，左边这个例子才有问题。那大家想如果你你有时候跑出了一个 bug 之后，你到底该怎么去敌呢？你会发现你你你发现那个 bug 之后，你再跑，
23:40它的结果其实就完全不对了。这其实就是 risk condition 非常难的问题。而且它的甚至它跟那个物理学量子量子力学对吧？里面有个字叫海，叫海斯堡的不确定对对吧？也不是不行，
23:51定就是测不准，对吧？就是你有一种测不准，就是你你有时候我们为了 debug，对吧？我们是我们会代码里去加一些这种什么 print f 对吧？
23:59 log 对吧？去去去看。但实际上大家想你，有时候你在你的并行的这个代码里，你去插入 print f 或者 log，它其实会影响它的调度，
24:08对吧？实际上会会有时候也会会会使得一些错误去出现出来。所以这个问题其实其实 recoconnition 是非常难难敌的啊这样的一个问题。然后它在真实的生活中其实也非常常见的。比如说我们可以看这个，这个是之前这个我用那个知乎，
24:26对吧？我们截的一个图，我就发现一个很神奇的事情，就是这个知乎啊，他告诉我说，你这个问题它有五个评论，
24:34五个评论。但是呢五这上面写的是五条评论，但是我一打点开啊，发现它里面就有四条评论。为什么？这个其实大概率是由于什么造成，
24:43就是我我发了一个请求求吧吧，正好他再读你的这个这个所有的这个评论。然后呢，正好呢又有一个人再去给他并行的加这个评论论后，他加了操作。可能就是他先把的是吧，
24:54先把你这这个个这这个这个个这个个这个这个评论加一，然后呢再去插入请求。然后我的这个请求呢，他看到了我的这个评论当前这个评论说的这个这个这个消消息，然后太多片，但是他并没有等到那个音色才做完，
25:08对吧？很有可能就会造成这样的一个看上去，就是不是特别好的这样一个 case OK。这是所以啊所以我们说你对于这样的一个这个这个这个这个这个并行来说的话，我们有 race condition 这样一个非常啊讨厌的现象。然后 race condition 在现实过程中实实际上是挺难挺难，
25:31尤其是你做数据处理很难很难避免。为什么你数据处理不可避免的会有一些写的这样的一个操作，对不对？那这个时候我们怎么办？这个时候我们最理想的情况是什么？就是说我们需要有一个这个系统，
25:45我们定义清楚在什么样的一个系统模型里面不会出现 race condition。然后我们这然后我们提供一个实现，这个实现它是提供了这样的一个特性。那这样的话我应用程序用你基基于我这个特性，对吧？去去写的话，
26:02那么就可以保证什么？你不管有没有 race condition，那么我们就这个系统一定正决 OK。那大家想想在什么样的一个场景下，我们这个系统一定不会出现由并发造成的这个 race condition 造成的各种乱七八糟的这样的一个问题呢？一个核心其实我们在跟我们之前讲这个 leading s rty 很像，
26:23对吧？但是像 EDSB ility，它怎么证明它怎么说，它是一个强的一致性构辑。他说我的这个系统的表现就像是一个单线程的这个表现。各位，
26:32那么对于这个你对于我们这个 riscountion 也是一样。如果我们这个系统它执行一堆并发的这样的操作，然后每个操作里面又有包含了一大堆操这个呃呃操作的时候，如果它等价于实执行操作，如果我个这个这个某一个单线程的程序，它一个挨着一个去执行这样的一个操操作。
26:52大家想想那个叫什么？我们这个系统它肯定是对的对吧？因为你你如果是啊一个接的一个操作的话，它就它它就不会出现啊那种并发的时候，我这个读的人啊被写的啊这样的一个场景 OK。那这种特性的话，
27:07我们就要注意到做这个 before or after 这样的一个 automatic。那在其他领域的话，可能有一些其他的名称，比如说在数据库里面叫 isolation，对吧？然后他们会有一些 CE sibility 或者说其他的这样一个。
27:19那那这个本质质讲讲的是一个都。那么它的核心思想就是说我们人是很难去推导这个单线啊多线程这个并发性的这个各种各样的情况。那所以我们希望的就是我们的这个这个这个程序啊，它虽然是并行执行，虽然是并行执行，但是它的这个执行的效果等价于什么？
27:40等价于一个单程的执行 reconconleo k 好，那么我们现在有了这样的一个效果。但是我们我们第一我们实现 before after 的一种方式是什么？一种方式？就是说啊我可以就用一个单线程对吧？那它肯定是这样一个 before after 的这样的一个事情啊，
27:56或者说那个 CSB 的进行。但是实实际过程中，我们还是希望多个这个线程对吧？去并行的或者多台多台机器，对吧？去并行的做这样一个操作过来框里面这个吞吐实际上是很难提升的那这个又怎么办呢？
28:10我们就需要一个经典叫做做 come control。就是我们需要先 controcontcontrol 的这样一个 method 啊，能够让我这个并发的执行啊，它最后等价于单个执行。那么一种很经典的方法就是 lock 啊， lock lock 它的思想其实很简单，
28:26对吧？他就是说你的我我你之前的问题什么就是我有一个操作，它可能会受到这个 race condition 的这个干扰，导致什么导致你们执行是错的。 OK。那我在这个这个作文某个可能会受到这个 race condition 的操作。
28:42比如说我要读一个变量的时候，那我就去拿一把锁啊，锁是一个数据结构。虽然说它的有个特性什么呢？就是同时同一个时间啊，并并发场下下，
28:51只有一个人能拿到这样一把锁，其他人拿不到 OK。但一旦我拿到这把锁，我在做这个操作的时候，那不就其他的他就不可能跟我有 recondition，因为他们拿不到同样的锁。
29:01那么这样的话，我不就能啊保证这样的一个正确性了嘛啊能保证正源性了吗？那么锁对吧？其实锁大家写程序可能或多或少都遇到了，对个这个东西已经不是数据库独有了，对吧？
29:13还是一个通用的这样数据结构。像这个 peace fad，它都会啊提供这样一个锁的这样一个接口 OK。那么有了这样一个锁的这个接口啊，我们如果去执行之前的那样一个加钱的这样的操作，我们其实就能很方便的把它改成一个这样的一个 before after。
29:32就是为什么呢？我们怎么做呢？其实就是说哎既然我对这个加上等于这个操作啊，它可能有 restcondidition 吧，它可能有 recocondition。那我在做这个加上等于这个操作之前啊，
29:44我就先拿一把锁，拿一把锁啊，后呢我再去放手放锁。 OK 就是这样一个简单的这样一个操作啊，这个操作啊，他叫他在每个操作作前都会加一把锁，
29:55所以我们们会叫叫 global lock。因为他所有的人都会拿这样一个同一把锁 OK，那我们其实很容易的能看到对吧？一个所有人都去拿同一把锁这个操作，实际上是能够啊确保这样的一个这个这个这个这个这 all after 这样的一个特系西。但是大家看它有一个什么关键的问题啊，
30:16它到底能不能实现我们前面说的这个提升吞吐这件事呢？其实是是是实现不了，大家想想原本对吧？我们希望的是什么？是把两个这个操作放在两个线程跑，这样的话我的这个吞吐可以乘乘以两倍，
30:30对吧？但是现在因为我们两个线，两个线程，它都拿了同一把锁，因为什么？第一，
30:36我七零我在执行这个操作之前，我先得是吧，拿一把这个拿锁其实是有开销的对吧？我先把这个打花了，点开销拿了锁，然后呢，
30:44我再做这个操作。然后这个时候 t 一如果他要做并行操作的时候，他能不能做？他其实不能做，他得这个黄色是么？他得等这个七零把锁放了。
30:52对，因为我们就是说锁，你只有一个人能拿到 OK。那么等到七零结束之后，我们有个放锁开销，然后再有个拿锁开销，
30:59最后再执行这个操作。那大家想想这样的一个执行效果它会有什么问题啊？第一，它其实基本上 fall back 到了你一个单线式的这个执行的这样的一个状态，对不对？而且它实际上比单线程执行的会更慢，
31:14为什么？因为你拿锁放锁等锁本身就是有开销的，对不对？这意味着什么意味着什么？就是说我们其实拿锁，这个是不能当然最简单单保证证正性性的放，
31:25我就一开始哎我就全拿一个大锁。但是呢实际上我为了保证这个这个性能的话啊，其实我我我我我要尽其实我要尽可能的什么尽可能的减少不同的这个七零和 t 一，他们之间拿共同锁的这个概念，对不对？因为大家想理论上说，
31:40我们刚刚那个例子，如果七零和 t 一他们是不同的操作。比如说 t 零是给 alice 的这个账号加起，然后 t 一是给 bob 的这个这个账号加钱。那么这两个操作其实他们没必要拿同一把锁，它理论上什么应该是可以进行执行的，
31:56对不对？那所以这就是一个在做并发控制的时候，有一个关键问题，就是我们一定要尽可能的去减少锁的这个 scope。就是我一个线程对吧？他拿了锁，
32:07但这个锁其实会 block 住其他线程或者其他机器的这样的一个访问，对不对？我们要尽可能的减少它 block 住其他机器的这样的一个这个范围。对吧然后第二个其实什么就是说我们要去这个这个加速这个这个锁的这样的一个实现是吧？我这个拿出来很快了。其实我们我们今天会看到，
32:27就是你拿锁这个操作本身其实是非常开销是非常大的啊，它实际上是比其他操作都都有一米的这样的开销 OK。好，那我们先看第一步啊，我们主要会我们这节课主要会看第一个东西啊，因为第二的话话呃呃操系统课可能会讲的更多一点啊，
32:43我们这个总据讲少一点。那么第一个问题就是我们怎么去减少我一个人拿锁它，影响这个范围呢？那么其实一个核心思想什么？就是说我我锁它保护的什么？是保护着对一个数据据的这样的一个这个这个这个这个这个这个 rase condition，
33:01对不对？那其实我没有我如果两个人他访问的数据不同的话，其实我们没有必要用同一把锁去保护。那这样的话，我不同人访问不同的数据，他们其实是没有 resconcondition。
33:13那这个时候他们理论上是什么？就应该要并发进并发执行。那这个的话意味着什么？意味着我们的锁它要变得更加的这个细致进度。也就是说我们的这个锁它得跟着什么跟着你的这个数据来。那么在我们这个银行这个例子对吧？
33:29它的数据其实是很天然的，是一个划分的。因为什么银行它就是一堆账号，对不对？一堆账号，然后它每个账号其实你访问同你如果访问不同操作的话，
33:39它理论来说是没有这样的一个冲突的那这样的话我给每个账号对吧？去分配一把锁 OK。那个就是这时候的话，我对于这个不同账号的这个操作，他们不就可以并发起来。那对同一个账号，
33:51比如说我们当这个啊，对吧？就比如说我们如果是 thread 零和 thread 一，他们访问的账号是不一样的。 OK，那么这个时候 thread 零他拿的，
34:01比如说 thread 他访问 alice，他就拿 alex 走啊， thread 一访问的是 bob，那还是拿 bob 走。那这样其实就可以，什么 paris、
34:09 ts 他他们可以并行起来的。这样的话啊他们就就就就就就我们就可以充分利用这个多线程或者说多机的这样一个人。但如果说 thread 零和 thread 一碰巧啊，很不巧，他们都啊拿到了这样的一个这个这个这个这个同一个账号。怎么说？
34:24这个事没关系系吧，因为他们同一个账号，它们一定是同一把锁。那这个时候我也能通过锁去把它们这个串行起来啊，来保证这样的一个正确性。 OK，
34:33这就是一个很经典思路。就是说啊我我的锁得变的什么细腻度啊，细腻度得去跟着数据走啊，而不是说我一个程序或者说一个应用都有一把锁。那它的这个这个这个我们的思路就是说哎，我每访问一个数据。
34:50好，我就拿这个数据的锁。然后呢这个当我的这个这个这个这个这个这个数据访问结束了啊，我就把这个这个锁给放掉。 OK 这是一个很基本的翻翻罐的这样一个锁的思路。那但是在实际的过程中呢，
35:04这种翻罐的锁啊，它基本上啊它它并不能保证正确性，并不能保证正确性，为什么呢？为什么？因为实际上你很多时候你一个操作本身对吧？
35:14它实际上是会访问很多个这样的数据的。那么大家想想，如果我这个操作要访问两个数据，然后我访问完一个数据，我就把这个锁放掉了。会造成什么情况？
35:25会造成我这个操作，它的中间状态啊，也还是会有可能会被另一个人看到，对吧？如果另一个人看到的时候，那那因为你锁已经放了。
35:34那么它如果看到你的中间状，然后它举你的中间状态去做一个这样的一个计算的话，那它其实还是有可能会出现啊这样一个正确性问题的。我们来举个例子，我们来举个例子，假设我们的这个银行应用对吧？
35:48变得更加的复杂了啊，就是说我的操作它并不是只操作一个，它会操作多个。比如说我们的这样的一个这样的一个这个 transfer 这个函数，对吧？它原本是我们希望在 a 和 b 两个账账户接近转账。
36:04然后呢，我们还有一个更加复杂的这种叫审计的这样的一个功能，对吧？它干什么事呢？它就是对于当前的这个银行的所有的这个账号都去扫一遍，把他们的总和加一下，
36:15对吧？我们说你一个银行对吧？正正常来说，我是需要经常审计，你的钱不能少，对吧？
36:20那么在我们这个银行里面，它的例子，它的它的核心点什么，就是说我不管怎么审计，对吧？那么我的总和应该是不不变的对吧？
36:28因为大家想我们这个银行里面只有一个这个转账的这个操作，它本身是不会增加钱，也不会减少钱的。好，那么大家想想，假设我们用前面这样一个翻关的 knocking 去执行这两个操作会出现什么情况。
36:40有可能会。比如说我们一开始 sread 零假设在做 transfer，然后 sread 一在做这个审计，对吧？然后 sread 零它一开始把这个锁拿了啊，他去读这个 b 的这样的一个数据啊，
36:51这个时候大家想想 sread 一因为它跟 sread 零有类似 connetion，所以它其实是被很好的住了，它没有执行对吧？因为我它在等锁，这个时候哎，我 sread 零为了快速的把锁放了，
37:02为了要尽可能的这个提高并行度啊，我就把这个锁给放了。然后这个时候我 sread 一就可以读这个 sread 零的数据啊，那大家想想这个 thread 零这个操作这个时候做完了没有，他其实没有做完，为什么？
37:16因为它其实还有一个 a 的状况，账号没有转，对不对？但是 sread 零这个时候它的这个这个中间的状态，比如 b 啊已经被 sread 一看到了，就是这个二十。
37:26那大家想这个时候如果我们 thread 零被，比如说被操作系统做了一个 impouve，对吧？它停掉。然后我 thread 一这个时候他先拿到了 a 的锁。这个时候他读到的是什么？
37:38读到的这个 a 其实是 spad 零，它没有做完的这样的一个状态，对不对？那么这个时候做完之后，我们就会发现一个问题，就是我在银行的这个总总的金钱啊，
37:50实际上是二十二十，就假设一开始都是，但是我们这个审计出来的这个结果，它却是三十，对吧？这个其实是一个不对的。
37:58这样的数据它不对的一个根本原因是什么呢？根本原因是我们如果用 final lock，我们所放的太早的话，太早的话意味着什么？意味着说我这个做到一半的这个数据可能会被别人看见。那么这个东西的话，
38:12在一个这个你一个严格串行的执行的这个这个这个这个执行场景里面，其实是不可能出现的对吧？其实会不可能出现这样的一个场景的那所以意味着什么？意味着说我如果用 fregrite lock 的话，我放锁不能太早啊。就是说我需要什么，
38:31我需要得等到我这个东西做完了，对吧？才需要去才能去放锁，才能去放锁，对吧？所以说这意味着说我们在做并行的时候，
38:41如果你要用过 fial lock，你就需要注意一个很很大的问题，就是说你的放锁时机实际上是非常重要重要的。那么一种比较保险的方法就是我在一开始对吧？我把所有的锁全拿了，然后等我这个做完了啊，
38:57我再去把所有的锁放掉。那这个其实就是一个啊最最最简单的啊，能保证正确性的这样的一个方法啊，就是拿锁放锁时机其实非常重要。 ok 但是这种方法大家想想有什么问题，这个我一开始对吧把所有的锁都拿了，
39:16然后我最后去结尾才放，有什么问题呢？会有一个问题，就比如说我这个 a 这个操作对吧？我可能一开始我一开始做完之后，我就对于你的这个 a 完全没有任何的这样的一个操作了，
39:30对吧？但是这个时候为了保证真能性我了，保证我这个 a 的中间状态，不能给其他人看到我这个 a 的锁，他就一直得拿到最后。那如果我这个 transaction 做的很长了，
39:40那不就意味着说我这个锁会答的非常长时间。这个如果有任何一个人要去访问这个 a 的话，那他其实都会被 block 住，对吧？那这个其实不是一个特别好的这样的事情，对吧？
39:54那我们能不能做一个优化呢？有一个优化呢？那么现在我们大家看到的一个很经典的方法叫做 two face lock，对吧？ two fitace lock 实际上是我们前面的一个翻罐的这样的一个翻罐的这样一个 lock 的一个一个优化。那么它的核心优化点是什么呢？
40:10就是说第一啊，我的锁不需要在开始的时候拿啊，它是一个 on demount 啊，就是说我的这个锁啊，它这个这个我碰到访问这个数据，第一次访问这个数据的时候，
40:22 OK 我再去拿锁，然后呢，这是第一点啊。对，就是说我在访问数据前就拿着锁，这是最直观的对吧？
40:29理论来说，它的拿锁时间是最少的。因为比如说我这个 d 对吧？如果是在这个中间点拿的 OK，那我其实就可以这个这个这个往后拿了往后拿了。然后呢呃特别测还有一个可很更重要的点，
40:42就是说你这个穿戴器没做完，也可以放锁啊。它是允许你的这个中间数据啊被其他人看到的。它只要保证一点什么呢？就是保证说一旦我放锁了，你不能再拿新的锁啊，
40:55它就加上这条限制这条限制。然后 t phase lock 做完之后，我们就发现它的拿锁时间，对吧？相比较之前的那个那个叫什么这个这个这个这个这个拿锁时间其实会少很多。因为之前你发光 lock 和你得全把这个这个这个这个锁全拿了，
41:11对吧？但是你 q feace lock 指挥哪一部分？那么它的这个这个时间会非常非常少。但是 tupeace lok 虽然看上去我这个放锁提前了，我拿锁提前。但是这个 TP es lock 它仍然能够保证正确性。
41:25这就是 t phas lock 一个非常有意思的点啊，就是说我们我们这个所谓正能性，就是 cheface ace lock，它能这个这个保证 CCOS rty 就是说我们我我有一堆并行的这个操作，但它最终等执行的结果等这样一个串起来。那够怎么去证明这样一件事呢？
41:42其实我因为我没有想到的是呃特别好的讲 fflok lok，对吧？我也不知道他们怎么想到这一点，就是说我可以提前放锁，对吧？我可以按去拿锁。
41:50我最后还是保证性。但是啊比较有意思的一点，就是说 cheface lock 它确实从这个这个理论上是能够证明它的这样的一个证。那好，那么这这个接下来就是我们就会看到一个很关键的问题了，就是假设对吧？
42:06我有一堆这个 t 一 t 二啊这样的一个 transaction，他们是必发执行的 OK。然后我们可能加了一些这个 concurcy control l 这个方法，比如说 t 个 solpping 对吧？那我们怎么去判断它的执行一定是等价一一串串的。来大家想它跟我们之前讲的 USB 类不一样。
42:23因为我们 VS ability ility 时间很简单，我们就拿一个 server。对吧去单线程的去执行所有的请求。大家想在我们的这样的一个这个并发的这样一个场景里面，它的这个断其实是完全会交错开来的。我们怎么去去证明它是一个这个这个这个严格是一个串行的呢？
42:44那么第一种方式能不能想到的方式就是大一下我们的定义是什么？定义的是说我们就这些 transaction 对吧？它我们假设说 TT 一啊，就就是我们要保证这个串行的这个操作，这个操作虽然是在被执执行的，但是如果他们的执行结果等于于某一个串行执行，
43:02就我们找到一个串行执行，就比如我们找到一个单线程，它先跑 t 一再跑 t 二，再跑 t 三跑出来这个结果。如果这两个结果是完全相等的，那么我们是不是就可以认为这样的一个这个这个这个这个这个我这个执行是符合串行的。
43:20那么怎么定义这两个这个结果是相同的呢？大家想想，那么我们其实其实我们可以把这个东西给给稍微画一下，对吧？这个其实就我们有一堆这样的一个操作，我们叫 t 一 t 二对吧？
43:35然后这些 t 一 t 二它们可能是完全并行的，在跑的都个算的跑。我们希望的是什么呢？它等价于某一个时间线上的一个系统实现。然后我先跑，比如说 t 一再跑 t 二再跑 t 三对吧？
43:48这样的一个直径。那么这个直行我们怎么判断呢？那其实我们无非就是看如果我在这个串行直线里面 t 一是第一个对吧？然后那我就去看一下你在并行直线里的 t 一，它的读的东西是不是跟这个 t 一完全一样，就你读的是不是这个数据的初始状态，
44:04对吧？如果你这个初状态是一样的，那我说明这个这两个执行应该是完全等价，对吧？因为我一个并行执行跟你在串行跑，没有任何区别。
44:11那么同样的道理，我们可以 repressive 的时候，我们可以递归的去跑。比如说我这个 t 二对吧？它在如果串行执行里面，它是排在 t 一，
44:20后面意味什么？意味着它一定读到了 t 一的这个数据，对不对？那我只需要去判断我在这个并行的执行里面 t 一 t 二是不是读完了读的数据和这个 t 一执行完的这样的一个空的状态，执行一模一样就可以了，对不对？
44:34然后我可以全部这样一个 check。然后最后什么最后我判断一下，我这个 TN 执行完之后，我整个数据的修改状态是不是和你的这个这个这个这个这个并行执行的一样。如果我这个修最后我最后我这个并行执行的这个 TTN 他们的这样的一个这个这个最后的数据，最终的只是跟我这个并行一样。
44:56那大家想想，其实站在我们一个观测者角度说，我们其实是没有任何办法去区分。就是说我的这个这个啊我的这个这个这个所谓的这个就是就是说这个这个并行执行和这个串行执行之间的任何的区别，对吧？那么这个就是人们判断的一种方法叫做这个 VCCRST。
45:17就就是我希希望能够找到这样的一个串行的这样的一个执行，串行这个执行。然后它的这个所有的这个每个操作看到的这个结果，以及最终的这个结果，一定是和这个这个并行执行协样，就是对应的这三条这三条 OK。
45:34好，那么这个方法看上去是我们是能够判断对吧？一个并行的执行是不是啊等价于这样的一个这个这个一个并行行，是问等等这一个串行执行行的吧。那大家想想它有一个个什么关键的问题啊，就是说这个判断的方法依赖于什么？
45:51依赖于我找到这样的一个某一个这个串行执行的方案，能够符合这样的一个并行执行的这样一个观测的这样的一个结果，对不对？那这个东西大家想想，我们如果是一个比较哪一步的这个方法，我们去找这个方案的话，
46:05我们怎么去找呢？我们其实只能什么，我们只能去案，对吧？我们枚举。那大家想想我们这个嗯枚举这样一个 TT 二 t 三，
46:15比如到 TM 这个所有的这个过程，它到底有多少种可行的这个调度呢？对吧？大家想这个这个实际上种类是非常非常非常多的。尤其是你比如说你一个 bank service，对吧？
46:27你可能啊一秒钟要跑个几千到几万的这样的一个串造值。那么大家想想，在这种情况下的话，我们去用 UCR sprity 去严格判断这样的一个这个找一个你这个执行是严格等价于创新经营，其实很难很难。目前来看是一个 NP huart 的问题，
46:45没有人找到那那我们怎么办呢？我们怎么办呢？我们能不能去加找找到一些方法，能够是说比如说我有一堆并行的这样的一个执行，对不对？那我能不能去根据这个并情执行，
46:58我能去做一些 index，我能够去方便的找这样的一个这个我可能等价的串行的啊，这个基于这样的话，人们就定一个名方叫 conflicts everyready 啊，他的观察是什么呢？他的观察是呃，
47:13我虽然有一堆这个这个这个这个并行的这样的一个 t 一 t 二的这个执行啊，但是我其实是有办法能够找到呃一些特定符合条件的这个 schedule，而不是说所有的 schedule 什么意思啊？就大家想假设我们有一个比如说 t 一对吧，它跟某一个 t 二 OK 它是并发执行的。然后我们希望的是什么呢？
47:36我们希望是找到是某一个串行的这样调度。比如说要么在 t 一在前，要么 t 二在后，然后它这个两个的结果跟你这个并行执行的结果是一样的。那我们希望找这样一个结果，那么我们怎么找呢？
47:48大家想想我们这个 t 一 t 二它这个并行结果，它其实虽然是并发执行的，但是它有时候会决定了一些你可能的序。比如说如果我 t 二写了一个数据 a 然后我 t 一读了这个数据意味着什么？意味着这个 t 一 t 二它们实际上是有个冲突关系，根据 reace condition 的对吧？
48:09我们就可以画。如果是 t 一在前，就是我 t 二如果读到 t 那我就是可以去去去去画一个箭头。比如说 t 一指向 t 二，这个箭头告诉我们什么呢？告诉我们，
48:20你在一个串行的排序里面， t 一一定得在 t 二之前，对吧？大家想想看，如果我这个 t 一在 t 二之后的话，那么我不可我这两个结果是不可能等价。
48:30因为这个 t 一在 t 二之后的话， t 一是读不到 t 二的这个数据的，那么跟你这个并行执行不就相符，不就不符合吗？ OK，那么这样的一有了这样一个概念之后呢，
48:40我们其实就会发现就是说我当我识别了一个并行执行里面一个 conflict。这样换的时候，我们就对于这个串行执行的可能的这个选项做了一个减枝啊，我就能就能减要很多这个这个这个这个这个这个啊这个这个这个这个不符合的。就比如说我在这个串行程系里面必须得是什么 t 一在前 t 二在前 OK。好，
49:05那么所谓的 confiict LS 边线，就是说我我在这个所有的 b 形里面，我我假设有个并形执形，对不对？那我就能把所所有这个的关系全都画出来。 confiico k 那一旦我把所有的这个的关系全部都画出来之后，
49:21那这个怎么办？这个时候我其实就可以去找到一些符合我这个的关关系的串性调度。那么一旦我找到了，那我就能够什么，我就能够判断说 confiicok 你这个这个职业串行的。 ok 那么我们能不能从一个并行的的关系中快速的去找到一个串行的关系啊，
49:42这个被证明是可行的，怎么可行呢？我们可以用一个图的方法来来判别。那大家想为什么我可以用图的方法来判别呢？大家想我们假设每个操作是一个点，然后它的这个关系作为一条边的话，
49:56大家看我们是不是就能构建出一张图。那么大家想想，我们找一个符合条件的串行关系，它等价于什么？等价于就是我找到一个点的这个排序，它符合你这个边的关系，
50:07对不对？那这个东西它不就是等价于一个图的这个拓扑排序的这样一个问题吗？那么大家想想我们这个图，它你到底能不能找到这样一个符合关系的排序呢？其实可以的，因为我只要这个图什么么的，
50:20这个这个 confiy bloth 它没有还，那么我们一定能找到一个拓扑排序。那么我这个拓扑排序排出来的这样的一个 confiy 个关系，一定什么？就跟你这个病情关系是等价的。 OK。
50:31所以有了这样一个的一个定义之后，我们就能够很快的去找到这样的一个这个这个符合条件的调度。好吧？行，那我们先休息一下，是是。